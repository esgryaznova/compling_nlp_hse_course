{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Использование предобученных трансформеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Большинство SOTA моделей последних лет основаны на 1 нейросетевой архитектуре, которая называется Transformer. Эта архитектура была представлена в 2017 году в статье - [Attention is all you need](https://arxiv.org/abs/1706.03762). \n",
    "\n",
    "На тот момент в обработке последовательностей доминировали рекуррентные нейроные сети, но у них была проблема с \"забыванием\" информации при обработке длинных текстов. Для решения этой проблемы был придуман механизм внимания (attention), который позволял на каждом шаге учитывать информацию от всех предыдущих и последующих элементов. LSTM+Attention некоторое время был sota подходом, но в attention is all you need было показано, что можно получить те же результаты, используя по сути только механизм внимания, без рекуррентности. \n",
    "\n",
    "Отсутствие рекуррентности позволяет гораздо эффективнее распараллеливать вычисления как на 1 gpu/tpu так и на кластере. На тот момент уже было несколько исследований показывающих, что при увеличении количества параметров и данных, модели начинают вести себя неожиданно хорошо (например, у OpenAI была статья в которой они рассказывали, что оставили LSTM на несколько месяцев и потом обнаружили, что она научилась достаточно точно определять тональность текста (без обучения на размеченном датасете) - https://openai.com/blog/unsupervised-sentiment-neuron/). Рекуррентные сети не позволяли серьезно увеличивать размер сетей даже при наличие ресурсов, а трансформеры позволили. \n",
    "\n",
    "Все последующие годы регулярно появлялись (и продолжают появляться) все более и более объемные трансформерные модели (BERT, GPT-1,2,3, Megatron). И каждый раз увеличение размера приводило к новым беспрецедентным результатам. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем чуть более подробно разобрать, как устроен трансформер. Это не простая тема и разбирать её мы будем постепенно.   \n",
    "**В этом семинаре посмотрим в целом на архитектуру и ее ключевые элементы, а также попробуем использовать предобученные трансформерные модели для задачи классификации.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала вернемся к рекуррентным сетям. Их недостатки наиболее серьезно проявились в задаче seq2seq. В seq2seq по входной последовательности нужно сгенерировать целевую последовательность, а длины последовательностей при этом могут отличаться. Самый каноничный пример seq2seq задачи - машинный перевод.\n",
    "\n",
    "Использование LSTM* для машинного перевода можно схематически представить вот так:\n",
    "\n",
    "*_тут и далее когда я говорю LSTM я на самом деле подразумеваю рекуррентные нейроные сети в целом, просто LSTM самый популярный их представитель, но уточнять это каждый раз неудобно_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/XjP2Gmh/Lstm-seq2seq.png\" width=\"700\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/XjP2Gmh/Lstm-seq2seq.png\", width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такой задачи нужно два LSTM слоя: один кодирует входную последовательность (encoder, или кодировщик), другой генерирует целевую последовательность (decoder или декодировщик). Такой подход работает, но есть серьезный недостаток - на вход декодеру подается только 1 вектор, в котором закодирована вся информация о целевой последовательности. Этот вектор - бутылочное горлышко (botleneck), узкое место, в которое все упирается.\n",
    "\n",
    "Если приводить аналогии, это как пытаться первести текст сходу целиком, прочитав его только 1 раз (попробуйте, например, перевести это предложение, не перечитывая). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для устранения бутылочного горлышка стали использовать механизм внимания. Он дает декодирующей LSTM доступ ко всем состояниям энкодера, а не только к последнему. Это уже больше похоже на то, как человек переводит текст - текст прочитывается целиком, но при переводе можно возвращаться к каждому отдельному слову исходного текста.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Схематично LSTM+Attention можно представить вот так. Такая архитектура уже в середине десятых годов позволила Google начать переход к нейронному переводу (до этого использовался статистический и правиловый):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/bzwNqwC/lstm-attention-seq2seq.png\" width=\"600\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/bzwNqwC/lstm-attention-seq2seq.png\",\n",
    "     width=600, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте подробнее посмотрим на механизм внимания. Визуализировать его целиком достаточно сложно, поэтому рассмотрим только 1 шаг (генерацию первого слова в переводе). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/19xB94B/lstm-attention-1-step.png\" width=\"700\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/19xB94B/lstm-attention-1-step.png\",\n",
    "     width=700, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Само внимание (или attention) можно реализовать разными способами. Мы рассмотрим один возможный подход - через скалярное произведение. \n",
    "\n",
    "После прохода энкодера для каждого элемента входной последовательности существует вектор состояния (его можно считать контекстным эмбедингом слова). На каждом шаге декодера между текущим состоянием декодера и всеми состояними энкодера расчитывается скалярное произведение (можно сказать считается близость между переводным словом и всеми словами входного текста). Результатом такого скалярного произведения является набор весов, соответствующих каждому слову входной последовательности. Эти веса показывают, какие слова релеванты для генерации текущего слова в переводе. \n",
    "\n",
    "Далее каждый вес умножается на соотвутсвующий ему вектор состояния энкодера и эти вектора прибавляются к текущему состоянию декодера (то есть происходит взвешенная сумма векторов слов входной последовательности и итоговая сумма прибавляется или конкатенируется к состояние декодера). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention убрал существующий bottleneck, но обучать такие модели было очень тяжело, так как в основе был LSTM. В 2017 был предложен подход без использования LSTM - Transformer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот как схематично решается задача машинного перевода с помощью трансформера. Самим трансформером называется блок с вниманием и полносвязными слоями, то есть и энкодер и декодер состоят из идентичных трансформерных блоков. Как и другие слои - трансформерные блоки можно накладывать друг на друга. Количество таких блоков в энкодере и декодере - настраиваемый гиперпараметр модели. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/XY0GK2R/transformer.png\" width=\"700\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://i.ibb.co/XY0GK2R/transformer.png\", width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трансформерных блоках также есть нормализация и skip-связи, но пока мы их пропустим. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention в трансформере конечно не такой простой как на примере выше. Давайте посмотрим на визуализацию из вот этого поста https://jalammar.github.io/illustrated-transformer/ (его имеет смысл почитать целиком)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention также вычисляется через скалаярное произведение, но оно считается не между векторами напрямую. \n",
    "\n",
    "Каждый эмбединг одтельного слова преобразуется в 3 отдельных вектора с помощью полносвязного слоя (умножения на матрицу). У них есть названия: query вектор, key вектор и value вектор. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jalammar.github.io/images/t/transformer_self_attention_vectors.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://jalammar.github.io/images/t/transformer_self_attention_vectors.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention score вычисляется с помощью скалярного произведения query вектора текущего слова и key векторов всех слов в последовательности. Результат скалярного произведения пропускается через softmax, чтобы получить вероятности (это и есть оценки внимания, attention scores, высокая вероятность означает, что на это слово нужно обратить внимание, а низкий - что слово на текущем шаге не важно). \n",
    "\n",
    "Далее выполняется взвешенная сумма всех value векторов (веса = attention скоры). Полученный вектор уже передается дальше в полносвязный слой. При наслаивании транформерных блоков друг на друга на втором слое вместо эмбединга слова уже будет использоваться вектор полученный из предыдущего блока."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jalammar.github.io/images/t/self-attention-output.png\" width=\"400\" height=\"400\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://jalammar.github.io/images/t/self-attention-output.png\", width=400, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но это еще не все. Это пример того, что называется self-attention - когда внимание расчитыватся между элементами одной последовательности. На схеме выше еще есть cross-attention. Он используется в декодере - query вектор тут получается из эмбедингов слов в целевой последовательности, а key и value вектора получаются из выходных векторов энкодера. Cross-attention связывает энкодер и декодер."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self-attention также присутствует в декодере. При обучении seq2seq моделей на вход подаются сразу две последовательности (текст и его перевод, например), но целевая последовательность подается постепенно (по 1 слову) и задача декодера - по полной входной последовательности и имеющейся на данный момент целевой последовательности сгенерировать продолжение. При использовании обученной модели для перевода текста сначала в декодер передается пустая последовательсть (а точнее не пустая а с тегом SOS или start, можно тут вспомнить семинар по языковым моделям)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Positional embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще одна важная составляющая транформера - positinal encoding (на схеме вместо обычного emded - pos emded), позиционной кодирование. Механизм внимания ничего не знает о позиции слов, он рассматривает последовательность как мешок слов, а от LSTM мы избавились. Поэтому нужно как-то закодировать информацию о последовательности в эмбединги слов. В Attention is all you need это было сделано простым добавлением к эмбедингу слова вектора, который зависит от индекса слова в последовательности. В статье они использовали периодичные функции (синус и косинус), которые не нужно обучать - они просто возвращают какое-то значение на каждый индекс последовательности. Количество уникальных векторов генерируемых таким образом конечно ограничено, но очень большое количество и не требуется, так как транформер сам по себе не очень хорошо масштабируется на длинные последовательности (обычно ограниченивают максимальную длину около 512)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот визуализация позиционных векторов из того же поста (изображено 20 векторов - по строкам, каждый размерности 512 - колонки; видно как вектора меняются при увеличении индекса):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png\" width=\"700\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://jalammar.github.io/images/t/transformer_positional_encoding_large_example.png\", \n",
    "      width=700, height=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В трансформере еще много других технических деталей, но для использования пока будет достаточно интуитивного понимания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование предобученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С появлением предобученных трансформеных моделей развился transfer learning - это использование моделей для задач, решать которые они изначально не обучались. \n",
    "\n",
    "Большинство предобученных моделей - языковые модели, которые обучались просто продолжать текст или заполнять в нем пропуски. Эмбединги, которые генерирует энкодер таких предобученных моделей уже очень хорошо улавливают смысл и их можно напрямую использовать для классифицикаии. А можно еще немного дообучить весь энкодер на доступных размеченных данных и получить еще лучший результат. Так как в модели уже много знаний, для дообучения нужно буквально несколько примеров. \n",
    "\n",
    "Давайте посмотрим на разницу в качестве дообученной модели и обученной с нуля на имеющихся данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.4.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (3.5.1)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.5 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.18.5; platform_machine != \"aarch64\" and platform_machine != \"arm64\" and python_version < \"3.10\" in /usr/local/lib/python3.8/dist-packages (from pandas) (1.22.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (4.29.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib) (3.0.7)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.22.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2022.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 47.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
      "\u001b[K     |████████████████████████████████| 701 kB 41.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.63.0-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 16.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,>=0.10.1\n",
      "  Downloading tokenizers-0.11.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.5 MB 40.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.6.0-py3-none-any.whl (10.0 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 35.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.0.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from sacremoses->transformers) (8.0.3)\n",
      "Installing collected packages: regex, pyyaml, tqdm, tokenizers, filelock, huggingface-hub, sacremoses, transformers\n",
      "Successfully installed filelock-3.6.0 huggingface-hub-0.4.0 pyyaml-6.0 regex-2022.3.2 sacremoses-0.0.47 tokenizers-0.11.6 tqdm-4.63.0 transformers-4.16.2\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.0.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn pandas matplotlib transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# стандартные библиотеки\n",
    "import os, re\n",
    "import numpy as np\n",
    "from time import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from string import punctuation\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "# tf и huggingface \n",
    "import tensorflow as tf\n",
    "from transformers import TFAutoModel\n",
    "from transformers import AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем данные lenta.ru, но не целиком. Fine-tuning больших моделей лучше всего подходит, когда данных совсем мало и стандартным алгоритмам просто не хватает информации, чтобы обучиться. Поэтому возьмем только небольшой процент всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_frac = pd.concat([data[data.topic=='Россия'].sample(frac=0.001),\n",
    "#                       data[data.topic=='Мир'].sample(frac=0.001),\n",
    "#                       data[data.topic=='Экономика'].sample(frac=0.002),\n",
    "#                       data[data.topic=='Спорт'].sample(frac=0.003),\n",
    "#                       data[data.topic=='Наука и техника'].sample(frac=0.005),\n",
    "#                       data[data.topic=='Бывший СССР'].sample(frac=0.005),\n",
    "#                       data[data.topic=='Культура'].sample(frac=0.005),\n",
    "#                       data[data.topic=='Интернет и СМИ'].sample(frac=0.005),\n",
    "#                       data[data.topic=='Из жизни'].sample(frac=0.01),\n",
    "#                       data[data.topic=='Дом'].sample(frac=0.01),\n",
    "#                       data[data.topic=='Силовые структуры'].sample(frac=0.01),\n",
    "#                       data[data.topic=='Ценности'].sample(frac=0.03),\n",
    "#                       data[data.topic=='Бизнес'].sample(frac=0.03),\n",
    "#                       data[data.topic=='69-я параллель'].sample(frac=0.05),\n",
    "#                       data[data.topic=='Крым'].sample(frac=0.05),\n",
    "#                       data[data.topic=='Культпросвет'].sample(frac=0.2),\n",
    "#                       data[data.topic=='Легпром'].sample(frac=0.8),\n",
    "#                       data[data.topic=='Библиотека']]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('lenta_sample.csv')\n",
    "data.dropna(subset=['topic', 'text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Из жизни             55\n",
       "Наука и техника      54\n",
       "Бывший СССР          54\n",
       "Культура             53\n",
       "Ценности             45\n",
       "Дом                  45\n",
       "Бизнес               44\n",
       "Интернет и СМИ       44\n",
       "Силовые структуры    40\n",
       "Спорт                39\n",
       "Россия               32\n",
       "Экономика            32\n",
       "Мир                  27\n",
       "69-я параллель       13\n",
       "Легпром              13\n",
       "Библиотека           10\n",
       "Крым                  7\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем предобученную модель из huggingface transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список всех доступных моделей можно найти тут - https://huggingface.co/models  \n",
    "А вот тут основные с описанием - https://huggingface.co/transformers/pretrained_models.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На HG предпочитают торч, поэтому многие модели не загрузятся в тф. Там есть специальный тэг, по которому можно фильтровать модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Виды моделей мы обсудим на следующем занятии, так как их очень много и они существенно отличаются друг от друга. Пока разберем 3 варианта одной из первых предобученных моделей - BERT. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Можно сказать оригинальный берт\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "# model_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-02 13:24:35.316372: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.319534: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.319920: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.320426: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-02 13:24:35.320767: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.321147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.321519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.620766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.621152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.621516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-03-02 13:24:35.621860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8080 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2022-03-02 13:24:36.138190: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# # # # Мультиязычный берт\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model_bert = TFAutoModel.from_pretrained('bert-base-multilingual-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Rubert который есть на тф от неизвестного пользователя геотренд\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"Geotrend/bert-base-ru-cased\")\n",
    "# model_bert = TFAutoModel.from_pretrained(\"Geotrend/bert-base-ru-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы загружаем не только модель, а еще и токенайзер, т.е. свою предобработку нам писать не нужно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'По факту пожара на\\xa0заводе в\\xa0Югре заведено дело'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[4, 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перевести токены в индексы очень просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101,\n",
       " 10291,\n",
       " 56538,\n",
       " 10236,\n",
       " 10291,\n",
       " 55974,\n",
       " 10185,\n",
       " 10124,\n",
       " 65784,\n",
       " 309,\n",
       " 37873,\n",
       " 14608,\n",
       " 10242,\n",
       " 56615,\n",
       " 26069,\n",
       " 102]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(data.loc[4, 'title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этих моделях как правило используется BPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'по',\n",
       " 'факт',\n",
       " '##у',\n",
       " 'по',\n",
       " '##жар',\n",
       " '##а',\n",
       " 'на',\n",
       " 'заводе',\n",
       " 'в',\n",
       " 'юг',\n",
       " '##ре',\n",
       " 'за',\n",
       " '##ведено',\n",
       " 'дело',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# переводим индекс токена обратно в текст\n",
    "encoded = tokenizer.encode(data.loc[4, 'title'])\n",
    "[tokenizer.decode([x]) for x in encoded]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Индексы можно напрямую передавать в модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.loc[4, 'title']\n",
    "text_ids = tf.constant([tokenizer.encode(text, add_special_tokens=True)])\n",
    "output = model_bert(text_ids, output_attentions=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На выходе мы получим tuple из двух элементов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый элемент - состояния енкодера для каждого из элементов последовательности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 16, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0].shape # в пайторче вместо .shape используется size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй - состояние енкодера на первом элементе, пропущенное через активацию (обычно этот элемент не используют)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно в задачах используют либо состояние первого элемента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Либо усредненное состояние "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 768])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_mean(output[0], axis=1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные эмбеддинги уже можно использовать для какой-нибудь кластеризации или поиска похожих. А если есть разметка, то можно обучить на этих векторах стандартную модель из sklearn или даже дообучить всего Берта под конкретную задачу!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем дообучить (fine-tune) модель на данных lenta ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем обучаться на заголовках, а не на самих текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переводим тексты в последовательности индексов\n",
    "# У берта есть ограничение на максимальную длину последовательности - 512\n",
    "# Для заголовков это не очень актуально, но для других данных пригодится\n",
    "\n",
    "X = []\n",
    "\n",
    "for text in data.title:\n",
    "    ids = tokenizer.encode(text)\n",
    "    \n",
    "    X.append(ids[:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', maxlen=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
    "label2id = {l:i for i, l in id2label.items()}\n",
    "\n",
    "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз добавим стратификацию, т.к. в данных у нас дисбаланс классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index, valid_index = train_test_split(list(range(len(X))), test_size=0.05, stratify=data.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[train_index], y[train_index]\n",
    "X_valid, y_valid = X[valid_index], y[valid_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загруженную модель в tf.keras можно использовать просто как слой в нейронной сети. Давайте сделаем новую модель, которая будет принимать на вход индексы символьных нграмм, пропускать их через берт, и затем брать первый вектор из энкодера и классифицировать его."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У нас есть два варианты дообучения - обучать только последний классификатор, не трогая берт, либо обучать все целиком, используя предобученной состояние энкодера как отправную точку."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дообучение с замораживанием предобученной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_bert = TFAutoModel.from_pretrained('bert-base-multilingual-uncased', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(512,), dtype=tf.int32,\n",
    "                                     name=\"input_ids\")\n",
    "\n",
    "output = model_bert({\"input_ids\":input_word_ids})\n",
    "\n",
    "# добавим дропаут чтобы не переобучалось\n",
    "drop = tf.keras.layers.Dropout(0.1)(output[0][:, 0]) # [0][:, 0] - означает что мы берем первое \n",
    "                                                     # состояние у всех текстов в батче\n",
    "dense = tf.keras.layers.Dense(y.shape[1], activation='softmax')(drop)\n",
    "\n",
    "model_clf = tf.keras.Model(inputs=input_word_ids, outputs=dense)\n",
    "\n",
    "# обычно при дообучении трансформеров нужно ставить очень маленький лосс\n",
    "# но когда мы обучаем только итоговый классификатор то можно ставить побольше\n",
    "model_clf.compile(tf.optimizers.Adam(learning_rate=2e-3), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', \n",
    "                           tf.keras.metrics.RecallAtPrecision(0.80, name='rec_prec')])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С батчсайзом тут приходится уже быть осторожным, т.к. берт занимает очень много места на видеокарте. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "29/29 [==============================] - 14s 303ms/step - loss: 2.8849 - accuracy: 0.0816 - rec_prec: 0.0000e+00 - val_loss: 2.7325 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 2/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.8319 - accuracy: 0.0764 - rec_prec: 0.0000e+00 - val_loss: 2.7668 - val_accuracy: 0.0323 - val_rec_prec: 0.0000e+00\n",
      "Epoch 3/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.8210 - accuracy: 0.0781 - rec_prec: 0.0000e+00 - val_loss: 2.7403 - val_accuracy: 0.0645 - val_rec_prec: 0.0000e+00\n",
      "Epoch 4/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.7993 - accuracy: 0.0764 - rec_prec: 0.0000e+00 - val_loss: 2.7685 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 5/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.8160 - accuracy: 0.0764 - rec_prec: 0.0017 - val_loss: 2.7251 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 6/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.8055 - accuracy: 0.0816 - rec_prec: 0.0000e+00 - val_loss: 2.7445 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 7/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.8278 - accuracy: 0.0764 - rec_prec: 0.0000e+00 - val_loss: 2.7252 - val_accuracy: 0.0645 - val_rec_prec: 0.0000e+00\n",
      "Epoch 8/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.8185 - accuracy: 0.0781 - rec_prec: 0.0000e+00 - val_loss: 2.7170 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 9/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.8014 - accuracy: 0.0799 - rec_prec: 0.0017 - val_loss: 2.7384 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 10/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.7948 - accuracy: 0.1007 - rec_prec: 0.0000e+00 - val_loss: 2.8033 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 11/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.7951 - accuracy: 0.0816 - rec_prec: 0.0000e+00 - val_loss: 2.7328 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 12/20\n",
      "29/29 [==============================] - 7s 255ms/step - loss: 2.7878 - accuracy: 0.0885 - rec_prec: 0.0017 - val_loss: 2.6848 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 13/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7898 - accuracy: 0.0833 - rec_prec: 0.0000e+00 - val_loss: 2.7423 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 14/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7665 - accuracy: 0.1042 - rec_prec: 0.0000e+00 - val_loss: 2.7986 - val_accuracy: 0.0323 - val_rec_prec: 0.0000e+00\n",
      "Epoch 15/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.8075 - accuracy: 0.0833 - rec_prec: 0.0000e+00 - val_loss: 2.6995 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 16/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7989 - accuracy: 0.0938 - rec_prec: 0.0000e+00 - val_loss: 2.7357 - val_accuracy: 0.1290 - val_rec_prec: 0.0000e+00\n",
      "Epoch 17/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7965 - accuracy: 0.0920 - rec_prec: 0.0000e+00 - val_loss: 2.7177 - val_accuracy: 0.1613 - val_rec_prec: 0.0000e+00\n",
      "Epoch 18/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7691 - accuracy: 0.0885 - rec_prec: 0.0000e+00 - val_loss: 2.7593 - val_accuracy: 0.0645 - val_rec_prec: 0.0000e+00\n",
      "Epoch 19/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7937 - accuracy: 0.0990 - rec_prec: 0.0000e+00 - val_loss: 2.7587 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 20/20\n",
      "29/29 [==============================] - 7s 256ms/step - loss: 2.7721 - accuracy: 0.1059 - rec_prec: 0.0000e+00 - val_loss: 2.7181 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3c94563a00>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=20,\n",
    "         epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'rec_prec', 'val_loss', 'val_accuracy', 'val_rec_prec'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model_clf.history.history.keys())\n",
    "plt.plot(model_clf.history.history['accuracy'])\n",
    "plt.plot(model_clf.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_clf.predict(X_valid, batch_size=10).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Наука и техника       0.00      0.00      0.00         3\n",
      "         Культура       0.00      0.00      0.00         3\n",
      "         Ценности       0.00      0.00      0.00         2\n",
      "      Бывший СССР       0.00      0.00      0.00         3\n",
      "       Библиотека       0.00      0.00      0.00         0\n",
      "        Экономика       0.00      0.00      0.00         2\n",
      "         Из жизни       0.10      1.00      0.18         3\n",
      "           Бизнес       0.00      0.00      0.00         2\n",
      "             Крым       0.00      0.00      0.00         0\n",
      "              Дом       0.00      0.00      0.00         2\n",
      "            Спорт       0.00      0.00      0.00         2\n",
      "           Россия       0.00      0.00      0.00         2\n",
      "              Мир       0.00      0.00      0.00         1\n",
      "   Интернет и СМИ       0.00      0.00      0.00         2\n",
      "          Легпром       0.00      0.00      0.00         1\n",
      "   69-я параллель       0.00      0.00      0.00         1\n",
      "Силовые структуры       0.00      0.00      0.00         2\n",
      "\n",
      "        micro avg       0.10      0.10      0.10        31\n",
      "        macro avg       0.01      0.06      0.01        31\n",
      "     weighted avg       0.01      0.10      0.02        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid.argmax(1), pred, labels=list(range(len(label2id))),\n",
    "                            target_names=list(label2id), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучение с замораживанием может не работать, давайте попробуем обучать все сразу"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Дообучение без замораживания "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-multilingual-uncased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_bert = TFAutoModel.from_pretrained('bert-base-multilingual-uncased', trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_word_ids = tf.keras.layers.Input(shape=(512,), dtype=tf.int32,\n",
    "                                     name=\"input_ids\")\n",
    "\n",
    "output = model_bert({\"input_ids\":input_word_ids})\n",
    "drop = tf.keras.layers.Dropout(0.3)(output[0][:, 0]) \n",
    "dense = tf.keras.layers.Dense(y.shape[1], activation='softmax')(drop)\n",
    "\n",
    "model_clf = tf.keras.Model(inputs=input_word_ids, outputs=dense)\n",
    "\n",
    "\n",
    "model_clf.compile(tf.optimizers.Adam(learning_rate=2e-6,\n",
    "                                    ), \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy', \n",
    "                           tf.keras.metrics.RecallAtPrecision(0.80, name='rec_prec')])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Батч сайз нужно поставить еще меньше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
      "288/288 [==============================] - 31s 92ms/step - loss: 2.8437 - accuracy: 0.0851 - rec_prec: 0.0000e+00 - val_loss: 2.7307 - val_accuracy: 0.0968 - val_rec_prec: 0.0000e+00\n",
      "Epoch 2/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.7791 - accuracy: 0.0885 - rec_prec: 0.0000e+00 - val_loss: 2.7410 - val_accuracy: 0.1613 - val_rec_prec: 0.0000e+00\n",
      "Epoch 3/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.7786 - accuracy: 0.0677 - rec_prec: 0.0000e+00 - val_loss: 2.7184 - val_accuracy: 0.1290 - val_rec_prec: 0.0000e+00\n",
      "Epoch 4/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.7647 - accuracy: 0.0747 - rec_prec: 0.0000e+00 - val_loss: 2.6952 - val_accuracy: 0.1935 - val_rec_prec: 0.0323\n",
      "Epoch 5/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.7431 - accuracy: 0.0990 - rec_prec: 0.0017 - val_loss: 2.6651 - val_accuracy: 0.1613 - val_rec_prec: 0.0323\n",
      "Epoch 6/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.6260 - accuracy: 0.1736 - rec_prec: 0.0000e+00 - val_loss: 2.5356 - val_accuracy: 0.2581 - val_rec_prec: 0.0000e+00\n",
      "Epoch 7/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 2.2854 - accuracy: 0.2986 - rec_prec: 0.0104 - val_loss: 2.2169 - val_accuracy: 0.3226 - val_rec_prec: 0.0000e+00\n",
      "Epoch 8/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 1.8590 - accuracy: 0.4410 - rec_prec: 0.0660 - val_loss: 2.0029 - val_accuracy: 0.3871 - val_rec_prec: 0.2581\n",
      "Epoch 9/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 1.4457 - accuracy: 0.5799 - rec_prec: 0.2951 - val_loss: 2.0405 - val_accuracy: 0.4516 - val_rec_prec: 0.0000e+00\n",
      "Epoch 10/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 1.1602 - accuracy: 0.6441 - rec_prec: 0.4983 - val_loss: 1.9882 - val_accuracy: 0.4194 - val_rec_prec: 0.2903\n",
      "Epoch 11/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 1.0250 - accuracy: 0.6892 - rec_prec: 0.5781 - val_loss: 1.8119 - val_accuracy: 0.4516 - val_rec_prec: 0.2581\n",
      "Epoch 12/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.8115 - accuracy: 0.7517 - rec_prec: 0.7326 - val_loss: 1.8814 - val_accuracy: 0.4194 - val_rec_prec: 0.0000e+00\n",
      "Epoch 13/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.7020 - accuracy: 0.7708 - rec_prec: 0.7413 - val_loss: 1.7441 - val_accuracy: 0.4516 - val_rec_prec: 0.3548\n",
      "Epoch 14/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.5759 - accuracy: 0.8351 - rec_prec: 0.8715 - val_loss: 1.8578 - val_accuracy: 0.3871 - val_rec_prec: 0.3226\n",
      "Epoch 15/20\n",
      "288/288 [==============================] - 25s 87ms/step - loss: 0.4750 - accuracy: 0.8767 - rec_prec: 0.9236 - val_loss: 1.8639 - val_accuracy: 0.5484 - val_rec_prec: 0.2581\n",
      "Epoch 16/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.3683 - accuracy: 0.9028 - rec_prec: 0.9653 - val_loss: 1.7511 - val_accuracy: 0.6129 - val_rec_prec: 0.2581\n",
      "Epoch 17/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.3101 - accuracy: 0.9253 - rec_prec: 0.9792 - val_loss: 1.6153 - val_accuracy: 0.5484 - val_rec_prec: 0.4516\n",
      "Epoch 18/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.2567 - accuracy: 0.9358 - rec_prec: 0.9931 - val_loss: 1.9242 - val_accuracy: 0.4516 - val_rec_prec: 0.4194\n",
      "Epoch 19/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.2181 - accuracy: 0.9531 - rec_prec: 0.9931 - val_loss: 1.8727 - val_accuracy: 0.5161 - val_rec_prec: 0.4194\n",
      "Epoch 20/20\n",
      "288/288 [==============================] - 25s 88ms/step - loss: 0.1657 - accuracy: 0.9688 - rec_prec: 0.9983 - val_loss: 2.0603 - val_accuracy: 0.4839 - val_rec_prec: 0.3871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff8800c3b80>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_clf.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=2,\n",
    "         epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'rec_prec', 'val_loss', 'val_accuracy', 'val_rec_prec'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA8oUlEQVR4nO3dd3xUVfr48c+TTkKAAKGFEnpHSiiCrqCggIouIqhYQMRV7Loq/nZddy1b3O/K2gtIcRUEUZFVlCbFpQih9xBqaGmQkARIPb8/zqAhJGFIpiV53q/XvJiZe+feJ8PMfeaec+5zxBiDUkqpqsvP2wEopZTyLk0ESilVxWkiUEqpKk4TgVJKVXGaCJRSqorTRKCUUlWcJgJV5YjIdBF51cl1D4rIQHfHpJQ3aSJQSqkqThOBUi4iIv5e3n+AN/evKi5NBMonOZpknhWRrSKSJSIfi0h9EfleRDJEZImIRBRaf5iI7BCRNBFZLiLtCy3rJiIbHa+bDYQU2ddNIrLZ8drVItLFyRini8j7IrJARLKAASLSSES+FJFkETkgIo8XWt9fRP6fiOxzxLJBRJpcYh9GRB4Xkf0ikiIi/xQRP8eyMSKySkQmiUgq8GcRCRaR/xORwyKSKCIfiEi1Qtu7xfG3nnbEMdiZv1VVcsYYvenN527AQWAtUB+IApKAjUA37IH8R+Alx7ptgCxgEBAIPAfEA0GO2yHgKceyEUAu8Krjtd0c2+4N+AP3OfYdXCiOgSXEOB1IB/phf1SFAhuAPzn22wLYD9zgWP9ZYBvQFhDgCqDOJd4HAywDagNNgTjgAceyMUAe8BgQAFQDJgHzHeuHA/8F/uZYv5cj3kGOeKOAdt7+v9ab929eD0Bveivu5jgAjy70+Evg/UKPHwPmOe6/CMwptMwPOAr0B34DHAOk0PLVhRLB+8ArRfa9B7imUBylJYJPCj3uDRwuss4LwLRC273lMt8HAwwu9HgCsNRxf0zh/TmSSxbQstBzVwIHHPc/BCZ5+/9Wb7530zZF5csSC90/W8zj6o77jbC/+gEwxhSISAL2F28+cNQYU7i64qFC95sB94nIY4WeC3Js0xkJRbbVSETSCj3nD/zkuN8E2Ofkdkvax6EisRVeFonjrEREzj8njhjO739BGfavKjlNBKoyOAZ0Pv9A7FGwCfaswABRIiKFkkFTfj0gJwCvGWNeK+O+CyeYBOyv79YlrJsAtAS2X+Y+mgA7HPebYv/e4vafgk2QHY0xR0vZv1IX0M5iVRnMAW4UketEJBB4BsjGNgGtwbajPy4igSIyHNtWft5k4CER6S1WmIjcKCLhZYhjHZAhIs+LSDVH53AnEenpWD4FeEVEWjv21UVE6jix3WdFJMLRsfwEMLu4lYwxBY6/Z5KI1AMQkSgRucGxysfAWMf75OdY1q4Mf6eqZDQRqArPGLMHuBt4G/ur+GbgZmNMjjEmBxiObU8/CYwCvir02lhgPPAOcArbyTymjHHkAzcBXYEDjlimADUdq7yBTVqLgNPYA3O1izZ0sW+wndCbge8cryvJ89i/Ya2InAaWYDunMcasA8ZiO5TTgRXY5ixVxcmFTadKKV8iIgZobYyJ93YsqvLSMwKllKritLNYKS8SkauB74tbZoypXtzzSrmaNg0ppVQVp01DSilVxbmtaUhEpmJHUCQZYzoVs1yAN4GhwBlgjDFm46W2W7duXRMdHe3iaJVSqnLbsGFDijEmsrhl7uwjmI4dkvdJCcuHAK0dt97YS/17X2qj0dHRxMbGuihEpZSqGkTkUEnL3NY0ZIxZiR23XZJbsHVajDFmLVBLRBq6Kx6llFLF82YfQRQX1kk54njuIiLyoIjEikhscnKyR4JTSqmqokJ0FhtjPjLGxBhjYiIji23iUkopVUbevI7gKLaY1nmNHc9dttzcXI4cOcK5c+dcEpivCgkJoXHjxgQGBno7FKVUJeLNRDAfeFREPsd2EqcbY46XZUNHjhwhPDyc6OhoCpXfrVSMMaSmpnLkyBGaN2/u7XCUUpWIO4ePzsJODFJXRI4AL2FniMIY8wG2LvpQbIGsM9hiWGVy7ty5Sp0EAESEOnXqoH0kSilXc1siMMbceYnlBnjEVfurzEngvKrwNyqlPE9rDSmllA9LO5PD5oQ0NiekMbB9fTpF1bz0iy6TJgIXSEtLY+bMmUyYMOGyXjd06FBmzpxJrVq13BOYUqpCyc7LZ9fxDDYfPsXmhDS2HEnnQEoWACJQp3qwJgJflZaWxnvvvXdRIsjLyyMgoOS3eMECnT5WqarKGMOh1DNsOZLGpsP2F//OY6fJyS8AoF54MF2b1GJEj8Z0a1KLzo1rEh7inhGDmghcYOLEiezbt4+uXbsSGBhISEgIERER7N69m7i4OG699VYSEhI4d+4cTzzxBA8++CDwa7mMzMxMhgwZwlVXXcXq1auJiorim2++oVo1ZyavUkpVBIWbeDYnpLElIY1TZ3IBqBboT+fGNRnbL5ormtSia5NaNKwZ4rF+wUqXCP7y3x3sPHbapdvs0KgGL93cscTlf//739m+fTubN29m+fLl3HjjjWzfvv2XYZ5Tp06ldu3anD17lp49e3LbbbdRp86FU9Xu3buXWbNmMXnyZEaOHMmXX37J3Xff7dK/QynlOUfTzrL+wEnWHTzJ+gMn2ZuUCdgmnjb1wrm+Q4NfDvpt6lcnwN971/dWukTgC3r16nXBWP+33nqLr7/+GoCEhAT27t17USJo3rw5Xbt2BaBHjx4cPHjQU+EqpcqpoMAQn5zJugMnWe848B9Ltxe4hgcH0CM6glu7RdGtaS26NK5F9WDfOvT6VjQuUNovd08JCwv75f7y5ctZsmQJa9asITQ0lP79+xd7BXRwcPAv9/39/Tl79qxHYlVKXb7c/AK2HU0n9uBJ1h04Reyhk6Q5mnkiw4PpFV2bB6Mj6Nm8Nu0a1MDfz7eHfle6ROAN4eHhZGRkFLssPT2diIgIQkND2b17N2vXrvVwdEqp8igoMBxLP8u+5Cw2HDrF+gMn2ZRwinO5tlO3ed0wru9Qn5jo2vSKrk2zOqEV7pofTQQuUKdOHfr160enTp2oVq0a9evX/2XZ4MGD+eCDD2jfvj1t27alT58+XoxUKVWc/ALD8fSzHEw5w8HULA6mZHEw1d4/fPIMOXn2oO8n0L5hDe7o2ZRezWsTEx1BvfAQL0dffhVuzuKYmBhTdGKaXbt20b59ey9F5FlV6W9VypXyCwzH0s5yKPUMB1KzOJSSZQ/6qWc4nHrml2GbAMEBfkTXCSO6bqjj3zCa1Qmlc5T7hnC6m4hsMMbEFLdMzwiUUpXWyawcftydxKIdJ/hpbwpnc/N/WXb+YN8yMozr2tX75WDfvG4Y9cND8PPxdn1X0kSglKpUDqVmsXhnIot2JhJ78CQFBhrWDOG2HlF0bFTzl1/6Ve1gXxpNBEqpCq2gwLD1aDqLd55g8c5E4hLteP12DcJ5dEArBnVoQKeoGhWuA9eTNBEopSqc7Lx8Vu9LZfHORJbsTCQpIxt/P6FndAQv3tSB6zvUp0ntUG+HWWFoIlBKVQjpZ3JZtieJRTtPsGJPMlk5+YQG+XNNm0gGdajPte3qUSs0yNthVkiaCJRSPutsTj6LdyXyzaajrIhLJq/AEBkezLCuUVzfoT5XtqxDSKC/t8Os8DQReEH16tXJzMz0dhhK+aS8/AJW70tl3uajLNx+gqycfBrUCOH+q5ozuFMDujaupZ28LqaJQCnldcYYth1NZ96mY/x36zGSM7IJDw7gpi6NuKVbI3o3r+PzZRoqMk0ELjBx4kSaNGnCI4/YmTf//Oc/ExAQwLJlyzh16hS5ubm8+uqr3HLLLV6OVCnfcig1i282H2Pe5qPsT84iyN+PAe0iubVrFAPa1dNmHw+pfIng+4lwYptrt9mgMwz5e4mLR40axZNPPvlLIpgzZw4LFy7k8ccfp0aNGqSkpNCnTx+GDRumQ9hUlZeamc13247z9aajbDqcBkDv5rUZf3ULhnZqSM3QinnlbkVW+RKBF3Tr1o2kpCSOHTtGcnIyERERNGjQgKeeeoqVK1fi5+fH0aNHSUxMpEGDBt4OVymPy8svYMH2E3y98Qgr96aQX2Bo1yCc5we3Y1jXRkTV0kmYvKnyJYJSfrm70+23387cuXM5ceIEo0aN4rPPPiM5OZkNGzYQGBhIdHR0seWnlarsVsWn8Mq3O9l9IoOGNUMYf3ULbu3WiHYNang7NOVQ+RKBl4waNYrx48eTkpLCihUrmDNnDvXq1SMwMJBly5Zx6NAhb4eolEcdSMnite92sWRXIo0jqvHe6O4M7thAR/z4IE0ELtKxY0cyMjKIioqiYcOGjB49mptvvpnOnTsTExNDu3btvB2iUh6RfjaXt5fuZcaagwT5+/H84HaM7RetHb8+TBOBC23b9msndd26dVmzZk2x6+k1BKoyyssvYNb6BCYtjuPUmRxGxTTh6evbVIp6/ZWdJgKlVLn9tDeZV77dSVxiJr2b1+ZPN3egY6Oa3g5LOUkTgVKqzPYnZ/LXBbtYsiuJJrWr8cHd3bmhYwMdJl3BVJpEYIyp9B++ijabnKq80s/k8taPe5mx+iAhgf5MHGL7AYIDtB+gIqoUiSAkJITU1FTq1KlTaZOBMYbU1FRCQrS9VXlPXn4Bs9Yd5o3FcaSdzeWOnk14elBbIsODvR2aKodKkQgaN27MkSNHSE5O9nYobhUSEkLjxo29HYaqolbG2X6AvUmZ9GlRmxdv0n6AyqJSJILAwECaN2/u7TCUqpSMMfxrURzvLIunWZ1QPrynB9d3qF9pz76rokqRCJRS7pGTV8DEL7fy1aaj3NGzCX+5paP2A1RCmgiUUsU6fS6Xhz/dwKr4VJ4Z1IZHr22lZwGVlCYCpdRFjqefZey09cQnZfKv26/gth7aN1WZaSJQSl1g94nTjJm6nszsPKaN7cnVrSO9HZJyMz93blxEBovIHhGJF5GJxSxvKiLLRGSTiGwVkaHujEcpVbpV8Snc/v4aDIY5v7tSk0AV4bZEICL+wLvAEKADcKeIdCiy2h+BOcaYbsAdwHvuikcpVbqvNh5hzLR1NKpVja8n9KNDIy0TXVW484ygFxBvjNlvjMkBPgeKztVogPOftprAMTfGo5QqhjGGd5fF8/ScLcQ0q82ch66kkU4UU6W4s48gCkgo9PgI0LvIOn8GFonIY0AYMLC4DYnIg8CDAE2bNnV5oEpVVXn5Bbz4zQ5mrTvMrV0b8fqIKwgKcGuLsfJB3v4fvxOYboxpDAwF/iMiF8VkjPnIGBNjjImJjNQ2S6VcISs7jwf/s4FZ6w4zoX9LJo3qqkmginLnGcFRoEmhx40dzxU2DhgMYIxZIyIhQF0gyY1xKVXlJWdkc//09ew4ls5rv+3E6N7NvB2S8iJ3pv/1QGsRaS4iQdjO4PlF1jkMXAcgIu2BEKByFwxSysv2JWcy/P1VxCdlMvneGE0Cyn1nBMaYPBF5FFgI+ANTjTE7RORlINYYMx94BpgsIk9hO47HGK21rJTbxB48yQOfxBLgJ3z+YB+uaFLL2yEpH+DWC8qMMQuABUWe+1Oh+zuBfu6MQSllLdh2nCdnb6ZxrWpMH9uLpnVCvR2S8hF6ZbFSlVTamRzW7Etl1b4UVsensj8lix7NIphybwwRYUHeDk/5EE0ESlUSZ3LyWH/wFKvjU1i1L4Udx05jDIQF+dOreW3u7tOMu3o3JSRQq4eqC2kiUKqCys0vYEtCGqvi7a/+TYdPkZtvCPQXujWN4Mnr2tCvVR2uaFKLQH8dFqpKpolAqQqioMCw68Rp29wTn8K6AyfJyslHBDo1qsn9/ZrTt1VdekZHEBqkX23lPP20KFUB/Lg7kefmbiMlMxuAFpFhDO/emH6t6tCnRR1qhWqbvyo7TQRK+bjpqw7w8rc7adegBi8MaUffVnVoWFNrASnX0USglI/KLzC88u1Opq8+yKAO9Xnzjq7a5KPcQj9VSvmgzOw8Hp+1iR93J/HAVc15YWh7/P10mkjlHpoIlPIxx9PPcv/0WOISM3jl1k7c00dLQCj30kSglA/ZfjSdcTPWk5Wdz8f3xdC/bT1vh6SqAE0ESvmIJTsTeWzWJiJCA5n78JW0a6AzhCnP0ESglJcZY5i26iCvfLeTzlE1mXJvDPVqhHg7LFWFaCJQyovy8gt4+dudfLLmEDd0rM+kUToySHmefuKU8pLM7DwenbmR5XuSefA3LZg4uB1+OjJIeYEmAqW84FjaWe6fvp69SZk6Q5jyOk0ESnnYtiN2ZNCZnHymjunJNW10Hm7lXZoIlPKgRTtO8MTnm6kdFsSXD/embYNwb4eklCYCpTzBGMPH/zvAawt20SWqJpPvi6FeuI4MUr5BE4FSbnY49Qx/mr+d5XuSGdKpAW+M7Eq1IJ0cRvkOTQRKuUlOXgGTf9rPW0v3EuAnvHhTB8b2jdaRQcrnaCJQyg3W7k/lj/O2E5+UyZBODXjp5o40qKlNQco3aSJQyoVSM7P564LdfLnxCI0jqjF1TAzXtqvv7bCUKpUmAqVcoKDA8MWGBP72/W4yz+UxoX9LHru2tfYFqApBE4FS5bTnRAZ/nLeN9QdP0TM6gtd+25k29XVYqKo4NBEoVUZncvJ4a2k8U37aT3hIAK+P6MKI7o21M1hVOJoIlCqDH3cn8uK8HRxNO8vImMZMHNKe2mE6gbyqmDQRKHUZjqef5S/zd/LDjhO0rled2Q/2oXeLOt4OS6ly0USglBPyCwzTVh1g0uI48o3hucFteeCqFgQF+Hk7NKXKTROBUpdwLjefJz7fxMIdifRvG8krt3SiSe1Qb4ellMtoIlCqFCezchg3Yz2bE9J48aYO3N8vGhHtDFaViyYCpUpwKDWLMdPWcyztLO/d1Z0hnRt6OySl3EITgVLF2JyQxrjp68k3hpnje9OjWW1vh6SU22giUKqIxTsTeWzWRiLDg5k+thctI6t7OySl3EoTgVKF/GfNQV6av4NOUTX5+L6eRIYHezskpdxOx74pha0V9Pfvd/PiNzsY0LYenz/YR5OAL8nPhW1z4Vy6tyOplNyaCERksIjsEZF4EZlYwjojRWSniOwQkZnujEep4mTn5fPk7M18sGIfo3s35cN7ehAapCfLPiM7A2aOhC/HwdQhkH7U2xFVOm5LBCLiD7wLDAE6AHeKSIci67QGXgD6GWM6Ak+6Kx6lipN+Npf7pq5j/pZjPDe4La/e2okAfz1R9hkZJ2DaENi/Avo+DmmH4eNBkLjT25FVKu78xPcC4o0x+40xOcDnwC1F1hkPvGuMOQVgjElyYzxKXeBo2llGvL+aDYdO8e9RXZnQv5VeI+BLkvfAlEGQuh/umg3XvwL3fw+mAKYOhgMrvR1hpXHJRCAij4hIrUKPI0RkghPbjgISCj0+4niusDZAGxFZJSJrRWRwCTE8KCKxIhKbnJzsxK6VKt2OY+n89t1VnEg/x4yxvbi1W9GPpvKqQ6vh4+sh7xyM/Q5aD7LPN+gM4xZDjYbwn+Gw9QvvxllJOHNGMN4Yk3b+gePX+3gX7T8AaA30B+4EJhdOOoX2+ZExJsYYExMZGemiXauqamVcMiM/WIO/nzD34b70bVXX2yGpwnbMg09uhbBIeGAxNOp24fJaTeD+H6BJb/jqAfjfv8EYLwRaeTiTCPyl0Pmyo+3fmXq7R4EmhR43djxX2BFgvjEm1xhzAIjDJgal3OKL2ATun76eJrVD+XpCP9o20AlkfMqa9+CLMdCoK4xbBBHRxa9XLQLu+Qo63QZLXoIFz0JBvgcDrVycGRrxAzBbRD50PP6d47lLWQ+0FpHm2ARwB3BXkXXmYc8EpolIXWxT0X4ntq3UZTHG8NbSeCYtiaNfqzq8f3cPaoQEejssdV5BASz6I6x9F9rfDMMnQ2C10l8TEAzDp0CNRrD6bcg4DrdNufTr1EWcSQTPYw/+DzseLwamXOpFxpg8EXkUWAj4A1ONMTtE5GUg1hgz37HsehHZCeQDzxpjUsvwdyhVqq82HmXSkjiGd4/i78O7aPloX5J7Dr7+HeycB70fghv+Cn5OzvXs5wfXvwo1GsMPE2HGMLjzcwjTOSIuhxgn2tZEpBrQ1Bizx/0hlS4mJsbExsZ6OwxVgWTn5XPt/62gdlgQ3zzST6eS9CVnTsLno+HwantAv/JRKOvIrZ3z4avxUCMK7v4Sajd3bawVnIhsMMbEFLfMmVFDw4DNOJqDRKSriMx3aYRKudGsnw9zNO0sz97QVpOAL0k7bIeBHo2F2z6Gvo+VPQkAdBgG934DZ0/aaw2ObnBdrJWcM+fHL2GvCUgDMMZsBjTVqgrhTE4e7yyLp3fz2lzdWkcH+YzjW2DKQMg8Afd8DZ1HuGa7TfvY4aWB1WD6TRC30DXbreScSQS5xpiiBT50rJaqEKatOkhKZg7PDW6nF4v5ivilMG0o+AXC/Qsh+irXbr9uaxi3xP47607YMN2126+EnEkEO0TkLuww0tYi8jaw2s1xKVVuaWdy+GDFPga2r0ePZhHeDkcBbJ5p6wZFNIcHlkC99u7ZT3h9GLMAWg6A/z4BP76m1xqUwplE8BjQEcgGZgLpaE0gVQF8uHI/mdl5PHN9W2+HooyBFf+EeQ/bM4CxC+zVwe4UXN2OIOp2D6x8HeZNsFVM1UVKHT7quHjsO2PMAOAPnglJqfJLOn2OaasOMOyKRrRvWMPb4ah9S2HZq9BlFAx7BwKcuSbVBfwDYdjbULMJLP8rhNSAIf/wzL4rkFITgTEmX0QKRKRmMf0ESvmsd5bFk5dveGpgG2+HosBe8BXe0LNJ4DwR6P88nD0FP78PzfpCh6L1L6s2Zy4oywS2ichiIOv8k8aYx90WlVLlkHDyDLPWHWZkzyZE1w3zdjjq+FbYvxwG/sXzSaCwQS/DkXXwzaO2eF3tFt6Lxcc400fwFfAisBLYUOimlE+atCQOPxEev1bLVvmENe9AUHXoMca7cQQEwYhpIH4w5z57RbMCnEgExpgZwCxgE7ARmOV4TimfE5eYwdebjnJf32ga1Azxdjgq/Qhs/xK63wfVank7GohoBr/9AE5shYX/z9vR+AxnriweCuwD3gLeAeJFZIi7A1OqLP5v4R7CggJ4+JqW3g5FAfz8gR0x1Ochb0fyq7ZD7FXMsR/bJKWcahp6AxhgjOlvjLkGGABMcm9YSl2+zQlpLNqZyPirWxAR5sW2aGWdS4fY6dDxVqjV1NvRXOi6l+x8BvMfh5R4z+zz1CGfHb7qTCLIMMYUfqf2AxluikepMvvnwt3UCQti3NVaAcUnbPwEcjJsITlf4x8II6aCfxB8cR/knnXfvoyBVW/Cm13gza52Ip2zp9y3vzJwJhHEisgCERkjIvcB/wXWi8hwERnu5viUcsqq+BRWxacyYUArqgc7MxhOuVV+Lqx9H6Kvhqju3o6meDUbw/CPIHE7fP+8e/ZRkA/fPweL/wRth9qKqEtegjc62sl0Uve5Z7+XyZlvTAiQCFzjeJwMVANuxtYc+so9oSnlHGMMry/cQ6OaIYzu7WNNEFXVjq/h9FG4ycdbkVsPgquehv+9Ac36wRWjXLft3LPw5QOw+1vbJzHwZTt/wvGtNknGToN1k22fRZ8J9oprL9XDumQiMMaMLW25iLxgjPmb60JS6vIs2pnIloQ0/nFbZ0ICnZzQRLmPMbD6LajbFloN8nY0lzbgD5DwM3z7pJ0iM9IFJUmyUmHWHXBkPQz+x4Wd5Q27wG/fh4EvwfopEDsV9iyw1zb0ecROv+nh6y1cMU3T7S7YhlJlkl9g+NeiPbSoG8Zt3Rt7OxwFcGAlnNgGfR+1v4B9nX+AnQ8hMNReX5CTdenXlObkAZh6vS21PXJGySOmwhvAtX+Ep3bAzW/a5rR5D8G/O9m6TFmem6zRFf9LWttXec03m48Sl5jJ09e3IcC/Ahx0qoLVb0NYPeg80tuROK9GQ7htMiTvtm33ZXV0o50U50wq3DffuVIWgdXsxXYT1tqZ1ep3snWZJnWwlVOT3T8xpCu+OVrbVXlFTl4Bk5bE0bFRDYZ2cnMlS+WcxJ0Qvxh6PwiBFeyCvpbXwm+ehc2fwabPLv/1cYvsZDiB1eD+RXaSnMshAq0Gwj1fwYSfbYG+LZ/Du73g09vsPA5uKqWtZwSqwpq9/jAJJ8/ye52C0nesedc2scSM83YkZdN/oh3p9N0zNqk5a8MM2ydQt5WdFCeynMUO67WDYW/ZZqMBf7RNbZ8Ot2dbbuCKRPCFC7ah1GU5m5PPWz/G0yu6Nv3bRHo7HAWQcQK2zoauoyG0trejKRs/f9tfEBxury/Izix9fWNg2V/hv4/bSXDGLLCT4rhKWF245ll4chvc+oHrpvQswpkSEzNEpFahxxEiMvX8Y2PMX90SmVKlmL76IMkZ2Tw7uK1OQekrfv4QCvLgygnejqR8wuvDiI8hNR6+fark5pj8XPjmEVjxD+h2t50EJ7i6e2IKCIaud0KNRm7ZvDNnBF2MMWnnHxhjTgHd3BKNUk5IP5vLByv2MaBtJD2jK+gvz8omO9PW7ml/c+Uo79z8N9D/Bdg2BzYWU2MzOwNmjrL9Cf1fsPMs+Ad6Pk4XcSYR+InILxO+ikhtnLsQTSm3mLxyP+lnc3UKSl+y6VNbW6hvJZqm5OpnoMUAWPCcbaM/L+METBtq51gY9o7tV6jgZ6XOJIJ/AWtE5BUReQU7cf3r7g1LqeIlZ2QzddUBburSkE5RNb0djgLIz4O170KTPtCkp7ejcR0/fxg+2fZ3zLkPzp22QzmnDLKlIe6aA93v8XaULuHMlcWfiEgscK3jqeHGmMvoTlfKdd5dFk92XgFPDyrDqIyCfPvlrqrc9ffvmg9ph+GGSlhgoHqk7TyecRPMHm3LQ/gHwdjvoFHlaSF3dtRQbSDLGPMOkCwiWt5RedyRU2eY+fNhbu/RmBaRl9EpZwz89C94rYH9ZZewzn1BFrfvAyth5h3wcl34fDQcWu228eDF7v/Qarvf1xrA6ndcv/3Vb0PtlrZmTmUU3Q+ufdH+P4ZFwgOLK1USACfOCETkJSAGaAtMAwKBT4F+7g1NqQv9e8leEHj8usuYgjI/D75/1tZzadoX9i2DnfOgcU9b6Kv9MFtiwNXysu2kJ2vfs+3LoXXs0L+4H2wRsoZd4cpHoONv3dPJmJ8LO+bZJptjm6BaBDTqDov+YGcNu+E115wdHF4DxzbCjW9U7rOtfk9CnZb2GoOKOjS2FM58A36LHSW0EcAYc0xEwt0alVJFxCdl8NXGI4zt15xGtao596KcLJg7DuK+h6uegmv/BLlnYPNM+Pl9mDsWajaBXg9C93tdM5ViVopNOuunQGYiRLaDm9+CLiPtFac5Z2DLLFt98qvxtjxxr/HQY6xrDjBnTsKG6baqZcYxqNPaHqSvuBMCQmwiWPuerQw6fHL5r/5d/bZNclfcWf7YfZmfn3PlIiooMZc4RRWRdcaYXiKy0RjTXUTCgDXGmC6eCfFCMTExJjY21hu7Vl70yMyNLN+dxMrnBlCnevClX5CZDLNG2V/DQ163B9vCCvIhbqE9KB78CQLD7FjwPg+Vbfhj0m67ra2zIe+cLRXQZ4ItW1DciJKCAohfYn+x718OAdWg613Q52GoexlnPOelxNv9b5llk12L/raSZauBFxd+W/Ouna+36ZVwx8yyJ6CUvfBODFwzEQa8ULZtKI8RkQ3GmJjilpV6RiD2Sp1vReRDoJaIjAfuBya7Pkylirfr+Gm+23qcRwe0ci4JpO6ztVkyTsCoT6HdjRev4+cP7Yba2/EtsOY9+0t+3Ud2ApErH4FmfUsfFmgM7FtqX7tvqf3F3WWUTQD12pUeo58ftLne3k5st2cIm/5jx+K3vsFelNX8mkvv/8BKe2Dfu9B2YnYeaZNJg04lv+7KRyC8IXz9O5h6A4yeayd1v1xr3gH/YOj5wOW/VvkUZ84ItgFPA9dj6wotNMYs9kBsxdIzgqpn/CexrN2fyv+eu5aaoZdoTz8SCzMdVS/vnH15wxkzTtgmldipcPYkNLzC/qru+NsL68PnnoWtc+wv8OTdUL0+9BwPMfdDWJ3L/wPPy0yC9R/bZqUzKbYKZZ8Jtm8hoFACzMuGbXPt/hO3Q2hdezDuOQ6q13N+fwdXweeOJqO75tha/E7HmgyTOtqrXW9+0/nXKa8p7YzAmUQwA3jHGLPeHcFdLk0EVcvWI2kMe2cVTw9qc+lO4t0LYO79ts773V/azr2yyD1rqz6ufR9S9thfzz0fsFfNbptrf7WfSS00kcjwCw/U5ZV7DrZ9YQ/0STttSeeeD9hJ4HfMs4kiKwnqdXAkitvL3taftBs+G2Hn0B05wzYlOWPZX21phUdjy9aUpTyuvIlgN9AKOAT8MmOD9hEoTxgzbR2bE9L46bkBhIeUcjaw/mNY8Hs7GueuOXb8d3kVFMC+H207/r4fHU+K56YWNMb2H6x9D/Yu+vX51tfb/bfo75r9nz4On91uk86wt2xfSWlyztizgaZ94M5Z5d+/8ogy9xE43ODieJRyyoZDJ1m+J5nnB7crOQkYA0tftnPOthkMI6ZCUJhrAvDzg9YD7S1pl00GbQaX/UzjconYipYtB0BynK3z32pQ+UscF1WjIYxdAHPutUXU0o/CNc+VnGS2zLRNZ30fc20cymucubL4UFk3LiKDgTcBf2CKMebvJax3GzAX6GmM0Z/7CoB/LYqjbvUg7utbQkdmXg7Mf9SO1OkxBob+yz3XBADUa29v3hLZxvUJoLCQGjD6C5j/OCz/K6Qn2Inni17jUJBvO6ejethRR6pScFvxOBHxB94FBgFHgPUiMr9oeQrHNQlPAD+7KxZV8azel8Lqfam8eFMHQoOK+ZieS4fZ98CBFfaqz6ufqfCFv7zOPxBufQ9qNoaVr9vO89unX1haec8COLnfPq/vd6XhzkleewHxxpj9xpgc4HOguCsyXgH+AZxzYyyqAjHG8MaiOOrXCGZ076YXr3D6mK3+eGiVnazjN7/Xg5KriMC1f4Cb/m2HxE6/0Y5mOm/121CrGbS72WshKtdzZyKIAhIKPT7ieO4XItIdaGKM+a60DYnIgyISKyKxycnJro9U+ZSVe1OIPXSKRwe0IiSwSNmCxJ0wZSCcOmSbMrpW8itavSVmLNwxC1Li7PudstfWaEr42V6H4K4mOOUV7kwEpRIRP+AN4JlLrWuM+cgYE2OMiYmM1GkJKzN7NrCHqFrVGNmzyYULD/wEUwfbduqxC+xVu8p92g6GMd/aUh0fD4IfXoCQmnYqSlWpuDMRHAUKf5MbO547LxzoBCwXkYNAH2C+iBQ7vElVDUt2JbHlSDqPX9eK4IBCZwPb5trJu2s0hAeWQEOvjF6ueqJ62Gqb1WrD0Vg7Kb27pmNUXuPO87v1QGtHyeqjwB3AXecXGmPSgbrnH4vIcuD3Omqo6iooMLyxOI5mdUIZ3r2xfdIYWP2WLc7WtC/cOdNW0lSeU7sFjFsMG6baK6hVpeO2RGCMyRORR4GF2OGjU40xO0TkZSDWGDPfXftWFdMPO06w6/hpJo26gkB/P9sE9MMLsO5DW+bh1g/KXy1TlU1YHfjNs96OQrmJW3t8jDELgAVFnvtTCev2d2csyrflFxgmLY6jVb3qDLsiypZ5+PIBW7v/ykdh0CsXV9FUSrmEdv0rn/DfLcfYm5TJO3d1w//cKZg5Co6sh8F/t9U0lVJuo4lAeV1efgFvLt1LuwbhDI3Kho9vhrQEe9FSx1u9HZ5SlZ4mAuV1X206yoGULD6/MQi/qYPsNIv3fgPNtISBUp6gja7Kq3LyCnhzyV7G1NtL75X32Zm6xi3WJKCUB+kZgfKqObEJ9MtYwEtBU5H6He1sWeH1vR2WUlWKJgLlNedy8ji36FVeD5yDaXGdnRglONzbYSlV5WjTkPKO/FwOT7ufBwrmkNhyBHLXbE0CSnmJJgLledkZ5H82kjbHv2Fu9dHUv3vKxXXvlVIeo4lAeVbGCZg2FDmwgudyx9NsxKtaQlopL9M+AuU5yXvg0xGYM6k8zvOcbjmAntG1vR2VUlWeJgLlGYfWwKw7wD+I2R0/4Nu1/swb5MapF5VSTtOmIeV+O7+BT26BsLqcHv09r20OZmD7+nRtUsvbkSml0ESg3G3t+zDnPmjUFcYtZvL2fDLO5fG0ng0o5TM0ESj3KCiAhX+AHyZCuxvh3m84aaoz9X8HGNq5AR0a1fB2hEopB+0jUK6Xew7mPQQ7voZev4PBfwM/fz5csoszufk8NVDPBpTyJZoIlGudPQWfj4ZDq+wcAn0fAxGSMs4xY/VBbrmiEa3r64VjSvkSTQTKddIOw6cj4NQBuO1j6Dzil0VvLIojL9/whJ4NKOVzNBEo1zi+FT673c4sdvdX0PzqXxZtO5LO7NgExvVrTvO6YV4MUilVHE0Eqvzil8KceyGkJoxbCPXa/7LIGMOf/7uDOmFBPD6wtReDVEqVREcNqfLZPBNmjoSIaHhgyQVJAOCbzcfYcOgUz93QjhohWk9IKV+kiUCVjTGw8p8w72Fo1g/GLoAajS5YJSs7j799v4sujWsyokdjLwWqlLoUbRpSly8/DxY8AxumQ5dRMOwdCAi6aLV3l8WTeDqb90b3wM9PC8sp5as0EajLk5MFX4yFvQvhqqfhuj8VWz30YEoWU346wPBuUfRoFuGFQJVSztJEoJyXmQwzb4fjW+DGf0HPB0pc9dXvdhHoLzw/pJ0HA1RKlYUmAuWctMMw42bISIRRn0G7oSWuuiIumSW7Epk4pB31a4R4MEilVFloIlCXlpdth4eeOQVjvoXGMSWumpNXwF/+u4PoOqGM7RftuRiVUmWmiUBd2qIX4dgmGPVpqUkA4JM1B9mfnMXUMTEEB/h7KEClVHno8FFVuh3zYN2H0GcCtL+51FWTM7J5c8le+reN5Np29T0Tn1Kq3DQRqJKd3A/zH4OoHjDwL5dc/Z8Ld3MuL58Xb+rggeCUUq6iiUAVL/ecnVBG/OD26cVeJ1DYloQ0vthwhLH9mtMysrpnYlRKuYT2EajiLfx/cGIr3Pk51Gpa6qoFBefrCQXz2LWtPBSgUspV9IxAXWzbXIj9GPo+Dm2HXHL1eZuPsulwGs8Pbku41hNSqsLRRKAulLIX/vsENOltrxq+hMzsPP72/W6uaFKL27prPSGlKiJtGlK/yj0LX4wB/yAYMQ38L/3r/p0f40nOyGbyvTFaT0ipCkoTgfrV989B4nYYPRdqRl1y9QMpWXz8v/2M6NGYrk1quT8+pZRbuLVpSEQGi8geEYkXkYnFLH9aRHaKyFYRWSoizdwZjyrFltmw8RNbSK71IKde8uq3OwkO8Oe5wW3dHJxSyp3clghExB94FxgCdADuFJGiA8w3ATHGmC7AXOB1d8WjSpG8B7590s4rMOAPTr1k2e4klu5O4vHrWlEvXOsJKVWRufOMoBcQb4zZb4zJAT4Hbim8gjFmmTHmjOPhWkB7Gz0tJ8teLxAYaiec9790a2FOXgGvfLuTFnXDGNO3uQeCVEq5kzsTQRSQUOjxEcdzJRkHfF/cAhF5UERiRSQ2OTnZhSFWIFkpsOVzOJfu2u1+93tI3g23TYEaDZ16yfTVB9ifksWLN3cgKEAHnilV0flEZ7GI3A3EANcUt9wY8xHwEUBMTIzxYGi+IXUffHobnDoAQeHQ7W7o/TuoXc5f45s+hS0z4ZrnoeUAp16SlHGOt5bGc127egxoW698+1dK+QR3/pw7CjQp9Lix47kLiMhA4A/AMGNMthvjqZgS1sPHg+yZwPDJdh6A9ZPh7e7w+Wg4tNrOH3y5Enfas4Hmv7GJwEmv/7CH7Lx8/qj1hJSqNNyZCNYDrUWkuYgEAXcA8wuvICLdgA+xSSDJjbFUTLsX2MlggmvAA0ugy0gY/hE8uQ36PQmHVsG0ITB5AGydA/m5zm03OxO+uA+Cw2H4FPBzrlz0psOnmLvhCOOuakHzumFl/7uUUj7FbYnAGJMHPAosBHYBc4wxO0TkZREZ5ljtn0B14AsR2Swi80vYXNWzfgrMHg312sO4xVCn5a/LajSCgS/BUzvhxjfsgf2r8fDvLvDTG3DmZMnbNQa+fQpS42HExxDuXLloW09oJ/XCg3lU6wkpVamIKUuzghfFxMSY2NhYb4fhPgUF8OPL8L9J0GYwjJgKQZf49V1QAPFLYO27sH+5HQF0xZ3Q52Go2/rCdTdMtyUkBvwRrnnW6bDeXLKXSUvieGPkFQzXUhJKVTgissEYU+zMUj7RWawc8nLgm0dg2xzoMQaG/sup4Zz4+UGb6+0tcQesfc92BMd+DK1vgCsnQPNr7FXDC56DltfC1c84HdYHK/YxaUkcw7tFcWvXS19xrJSqWPSMwFnn0iFhnT2gXqI2f5m3P/tuOLASrn3RHqilHLV7MpNtIlg/BbKSoX4nyM6A/Bx46H8QVtepzUz5aT+vfreLYVc0YtKorvhrPSGlKiQ9IyivtMPw6QhI2QPhDaHXeOgxFkJru2b76Ufhs9vt9m/9ALreWf5tVo+E/hNtp/L2ubDmPTh9DO6b73QSmLH6IK9+t4uhnRvwxsgrNAkoVUnpGcGlHN9qD9K5Z+HaP8Ke72w7fEA1e8DuM+HidvjLkbgTPhsB507DqE9ss407GAPZpyGkplOrf/bzIf7w9XYGdajPe6O7E+ivF44pVZHpGUFZxS+FOfdCSC0Yt9CO4On9YJF2+KkXtsNfTnPOgZXw+d0QFAr3fw8NOrvtT0HE6SQwZ30Cf/h6O9e2q8c7d3XTJKBUJaff8JJsngkzR0JENDyw2CaB8+p3hFvehad2wDUT4egG+OQW+OAqmxzynLgubttc+M9wW9Zh3GL3JoHL8NXGIzz/1VZ+0yaS90Z3JzjAuWsMlFIVlyaCooyBFf+EeQ9D9FUw9ns7br841evBgBdsQhj2DpgCO+pnUkdY/nfbYVvc9le9CV+Ogya94P4foFaTi9fzgvlbjvH7L7ZwZYs6fHRPD0ICNQkoVRVoH0Fh+Xmw4Bk71r7LHTDs7csbIWSM7T9Y+x7sXQT+wdDldujzCNTvAAX58MNEWPcRdBwOv/0AAoLd87dcpgXbjvPYrE30aBbB9LE9CQ3SVkOlKhPtI3BGThZ8MRb2LrRDN6998fKHb4rY4m0tB0ByHPz8PmyeZZuLWgywUz/uXQR9H4OBL9vx/z5g0Y4TPD5rE92a1GLaGE0CSlU1+o0HyEyy/QHHt9iSDT3HlX+bkW3gpkk2oWyYBj9/BJmJMPgf0Oeh8m/fRX7cncgjMzfSKaom08b2JCxYPxJKVTX6rU+Jh89ug4xEuGMmtB3i2u2H1rZnGFc+BpknoFZT126/HFbEJfPQfzbSrkENZtzfi/CQS09Wr5SqfKp2IkhYBzNH2SadMd9B4x7u21dAkE8lgdXxKTz4SSwt61XnP+N6UbOaJgGlqirfaKT2ht3f2RLPITXt8E13JgEf8/P+VMbNiCW6ThifPdCbWqFuKJmhlKowqmYiWDfZ1vWp39HW+S9c4rmSiz14krHT1xMVUY3PxvemdpgmAaWquqrVNFRQAEv/Aqv+DW2GOEo8h3o7Ko/ZdPgUY6atp36NEGY+0Ju61X1j6KpSyruqTiLIy3aUeP4CYsbBkNedK/FcCRxNO8v3247z5tK91A4LYub43tSrEeLtsJRSPqJqHAkBVvzDJoHrXoKrnipfiecK4PzB/7ttx9l0OA2AK5rU4r3R3WlYs5p3g1NK+ZSqkwj6PQlRPaDdjcUuNsaQnVdAVnYeZ3LyycrJIys7j6zsfM7k2H8D/IU+LepQ30d/TRd38O/YqAbP3tCWGzs3JFrnGVZKFaPKJIKlB87y9aaGnFm7/oKD/ZnsfHvAz8mjwMlqG+0b1qB/20j6t4mke7MIr1bnPH/w/3brcTYnpAF68FdKXZ4qkwiSM7LZefw0YUEBhAb5ExkeTLOgUPs42J/qwQGEBgUQFuxv/w3yJzTY8W9QANWDA8jIzmVlXArL9yQxeeV+3l++j/DgAK5qXZf+bSO5pk09GtR0/9nCkVNn+H7bCb7bduHB/7nBbRnaSQ/+SqnLo0Xnyuj0uVxWx6ewfE8yy/ckc+L0OQDaNQinf9t69G8bSY9yni3kFxhOZuWQnJFNUsY54hIzWLDtxC8H/05RNRjauaEe/JVSl1Ra0TlNBC5gjGFPYoYjKSQRe/AUeQWG8OAA+rWyZwv92/56tpCVnUdyRjbJmdkknc4mOePcr/czsx0H/mxSM7Mvaq46f/C/sXNDmtXRg79SyjmaCDws41wuq+JTWRGXxPI9yRxPt2cLDWuGcPpsLlk5+Re9xt9PiKweTGS4vdULv/h+VK1QjzQ9KaUqHy1D7WHhIYEM7tSAwZ0aYIwhLjGT5XuS2HX8NLXDij/QR4QG4aeTwyulvEATgZuJCG0bhNO2Qbi3Q1FKqWJVzVpDSimlfqGJQCmlqjhNBEopVcVpIlBKqSpOE4FSSlVxmgiUUqqK00SglFJVnCYCpZSq4ipciQkRSQYOlfHldYEUF4bjahpf+Wh85efrMWp8ZdfMGBNZ3IIKlwjKQ0RiS6q14Qs0vvLR+MrP12PU+NxDm4aUUqqK00SglFJVXFVLBB95O4BL0PjKR+MrP1+PUeNzgyrVR6CUUupiVe2MQCmlVBGaCJRSqoqrlIlARAaLyB4RiReRicUsDxaR2Y7lP4tItAdjayIiy0Rkp4jsEJEnilmnv4iki8hmx+1PnorPsf+DIrLNse+L5gUV6y3H+7dVRLp7MLa2hd6XzSJyWkSeLLKOx98/EZkqIkkisr3Qc7VFZLGI7HX8G1HCa+9zrLNXRO7zUGz/FJHdjv+/r0WkVgmvLfWz4OYY/ywiRwv9Pw4t4bWlft/dGN/sQrEdFJHNJbzWI+9huRhjKtUN8Af2AS2AIGAL0KHIOhOADxz37wBmezC+hkB3x/1wIK6Y+PoD33rxPTwI1C1l+VDge0CAPsDPXvy/PoG9UMar7x/wG6A7sL3Qc68DEx33JwL/KOZ1tYH9jn8jHPcjPBDb9UCA4/4/iovNmc+Cm2P8M/B7Jz4DpX7f3RVfkeX/Av7kzfewPLfKeEbQC4g3xuw3xuQAnwO3FFnnFmCG4/5c4DoR8ciEwcaY48aYjY77GcAuIMoT+3ahW4BPjLUWqCUiDb0Qx3XAPmNMWa80dxljzErgZJGnC3/OZgC3FvPSG4DFxpiTxphTwGJgsLtjM8YsMsbkOR6uBRq7cp+Xq4T3zxnOfN/LrbT4HMeOkcAsV+/XUypjIogCEgo9PsLFB9pf1nF8GdKBOh6JrhBHk1Q34OdiFl8pIltE5HsR6ejZyDDAIhHZICIPFrPcmffYE+6g5C+fN9+/8+obY4477p8A6hezji+8l/djz/CKc6nPgrs96mi+mlpC05ovvH9XA4nGmL0lLPf2e3hJlTERVAgiUh34EnjSGHO6yOKN2OaOK4C3gXkeDu8qY0x3YAjwiIj8xsP7vyQRCQKGAV8Us9jb799FjG0j8Lmx2iLyByAP+KyEVbz5WXgfaAl0BY5jm1980Z2Ufjbg89+nypgIjgJNCj1u7Hiu2HVEJACoCaR6JDq7z0BsEvjMGPNV0eXGmNPGmEzH/QVAoIjU9VR8xpijjn+TgK+xp9+FOfMeu9sQYKMxJrHoAm+/f4Uknm8yc/ybVMw6XnsvRWQMcBMw2pGoLuLEZ8FtjDGJxph8Y0wBMLmEfXv1s+g4fgwHZpe0jjffQ2dVxkSwHmgtIs0dvxrvAOYXWWc+cH50xgjgx5K+CK7maE/8GNhljHmjhHUanO+zEJFe2P8njyQqEQkTkfDz97GdituLrDYfuNcxeqgPkF6oCcRTSvwV5s33r4jCn7P7gG+KWWchcL2IRDiaPq53POdWIjIYeA4YZow5U8I6znwW3Blj4X6n35awb2e+7+40ENhtjDlS3EJvv4dO83ZvtTtu2FEtcdjRBH9wPPcy9kMPEIJtUogH1gEtPBjbVdgmgq3AZsdtKPAQ8JBjnUeBHdgREGuBvh6Mr4Vjv1scMZx//wrHJ8C7jvd3GxDj4f/fMOyBvWah57z6/mGT0nEgF9tOPQ7b77QU2AssAWo71o0BphR67f2Oz2I8MNZDscVj29bPfwbPj6JrBCwo7bPgwffvP47P11bswb1h0Rgdjy/6vnsiPsfz089/7gqt65X3sDw3LTGhlFJVXGVsGlJKKXUZNBEopVQVp4lAKaWqOE0ESilVxWkiUEqpKk4TgVIe5KiM+q2341CqME0ESilVxWkiUKoYInK3iKxz1JD/UET8RSRTRCaJnUdiqYhEOtbtKiJrC9X2j3A830pEljiK320UkZaOzVcXkbmO+QA+81TlW6VKoolAqSJEpD0wCuhnjOkK5AOjsVc0xxpjOgIrgJccL/kEeN4Y0wV7Jez55z8D3jW2+F1f7JWpYCvOPgl0wF552s/Nf5JSpQrwdgBK+aDrgB7AeseP9WrYgnEF/Fpc7FPgKxGpCdQyxqxwPD8D+MJRXybKGPM1gDHmHIBje+uMozaNY1araOB/bv+rlCqBJgKlLibADGPMCxc8KfJikfXKWp8lu9D9fPR7qLxMm4aUuthSYISI1INf5h5uhv2+jHCscxfwP2NMOnBKRK52PH8PsMLY2eeOiMitjm0Ei0ioJ/8IpZylv0SUKsIYs1NE/oidVcoPW3HyESAL6OVYloTtRwBbYvoDx4F+PzDW8fw9wIci8rJjG7d78M9QymlafVQpJ4lIpjGmurfjUMrVtGlIKaWqOD0jUEqpKk7PCJRSqorTRKCUUlWcJgKllKriNBEopVQVp4lAKaWquP8PyM6Y3pvWCrcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model_clf.history.history.keys())\n",
    "plt.plot(model_clf.history.history['accuracy'])\n",
    "plt.plot(model_clf.history.history['val_accuracy'])\n",
    "plt.title('model rec_prec')\n",
    "plt.ylabel('rec_prec')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_clf.predict(X_valid, batch_size=5).argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Силовые структуры       0.00      0.00      0.00         2\n",
      "        Экономика       0.00      0.00      0.00         2\n",
      "      Бывший СССР       1.00      0.33      0.50         3\n",
      "   Интернет и СМИ       0.00      0.00      0.00         2\n",
      "         Ценности       0.50      1.00      0.67         2\n",
      "          Легпром       0.00      0.00      0.00         1\n",
      "  Наука и техника       1.00      0.33      0.50         3\n",
      "              Мир       0.00      0.00      0.00         1\n",
      "         Культура       1.00      1.00      1.00         3\n",
      "              Дом       0.67      1.00      0.80         2\n",
      "           Бизнес       0.25      0.50      0.33         2\n",
      "         Из жизни       0.25      0.33      0.29         3\n",
      "            Спорт       1.00      0.50      0.67         2\n",
      "   69-я параллель       0.50      1.00      0.67         1\n",
      "           Россия       0.50      1.00      0.67         2\n",
      "             Крым       0.00      0.00      0.00         0\n",
      "       Библиотека       0.00      0.00      0.00         0\n",
      "\n",
      "        micro avg       0.48      0.48      0.48        31\n",
      "        macro avg       0.39      0.41      0.36        31\n",
      "     weighted avg       0.52      0.48      0.44        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid.argmax(1), pred, labels=list(range(len(label2id))),\n",
    "                            target_names=list(label2id), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ф-мера выглядит не очень, но нужно помнить, что мы обучились на 600 примерах. Для сравнения можно попробовать обучить лстм на тех же данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "for text in data.title:\n",
    "    vocab.update(preprocess(text))\n",
    "\n",
    "# индексируем слова\n",
    "word2id = {'PAD':0}\n",
    "\n",
    "for word in vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "\n",
    "id2word = {i:word for word, i in word2id.items()}\n",
    "\n",
    "X = []\n",
    "\n",
    "for text in data.title:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id[token] for token in tokens]\n",
    "    X.append(ids)\n",
    "\n",
    "MAX_LEN = max(len(x) for x in X)\n",
    "\n",
    "\n",
    "# паддинг\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, padding='post', maxlen=MAX_LEN)\n",
    "\n",
    "\n",
    "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
    "label2id = {l:i for i, l in id2label.items()}\n",
    "\n",
    "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])\n",
    "\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=data.topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(128, return_sequences=False)(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 13)]              0         \n",
      "                                                                 \n",
      " embedding_2 (Embedding)     (None, 13, 30)            93060     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 128)               81408     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 17)                2193      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 176,661\n",
      "Trainable params: 176,661\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "18/18 [==============================] - 1s 14ms/step - loss: 2.8162 - accuracy: 0.0729 - val_loss: 2.7711 - val_accuracy: 0.0968\n",
      "Epoch 2/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.7351 - accuracy: 0.0642 - val_loss: 2.6892 - val_accuracy: 0.0968\n",
      "Epoch 3/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.6613 - accuracy: 0.0851 - val_loss: 2.6483 - val_accuracy: 0.0968\n",
      "Epoch 4/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.3986 - accuracy: 0.1128 - val_loss: 2.5514 - val_accuracy: 0.1613\n",
      "Epoch 5/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.2006 - accuracy: 0.1458 - val_loss: 2.6177 - val_accuracy: 0.1290\n",
      "Epoch 6/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 2.0251 - accuracy: 0.2049 - val_loss: 2.7911 - val_accuracy: 0.0968\n",
      "Epoch 7/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.8497 - accuracy: 0.2917 - val_loss: 3.2586 - val_accuracy: 0.1613\n",
      "Epoch 8/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.7228 - accuracy: 0.3177 - val_loss: 3.8721 - val_accuracy: 0.0645\n",
      "Epoch 9/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.5600 - accuracy: 0.3924 - val_loss: 3.8411 - val_accuracy: 0.0645\n",
      "Epoch 10/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.3515 - accuracy: 0.4635 - val_loss: 4.1551 - val_accuracy: 0.0645\n",
      "Epoch 11/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.1789 - accuracy: 0.5521 - val_loss: 4.9646 - val_accuracy: 0.0323\n",
      "Epoch 12/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 1.0983 - accuracy: 0.5538 - val_loss: 4.9894 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9929 - accuracy: 0.6059 - val_loss: 5.0363 - val_accuracy: 0.0323\n",
      "Epoch 14/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.9389 - accuracy: 0.6389 - val_loss: 5.1786 - val_accuracy: 0.0323\n",
      "Epoch 15/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.7653 - accuracy: 0.7431 - val_loss: 5.3990 - val_accuracy: 0.0645\n",
      "Epoch 16/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.8368 - val_loss: 5.7955 - val_accuracy: 0.0323\n",
      "Epoch 17/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.8611 - val_loss: 6.1752 - val_accuracy: 0.0323\n",
      "Epoch 18/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3884 - accuracy: 0.8837 - val_loss: 6.5543 - val_accuracy: 0.0323\n",
      "Epoch 19/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3799 - accuracy: 0.8872 - val_loss: 6.7627 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.9028 - val_loss: 6.8807 - val_accuracy: 0.0323\n",
      "Epoch 21/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2932 - accuracy: 0.9219 - val_loss: 7.0021 - val_accuracy: 0.0323\n",
      "Epoch 22/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2937 - accuracy: 0.9167 - val_loss: 7.4604 - val_accuracy: 0.0645\n",
      "Epoch 23/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2315 - accuracy: 0.9271 - val_loss: 7.1362 - val_accuracy: 0.0645\n",
      "Epoch 24/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1477 - accuracy: 0.9688 - val_loss: 7.1336 - val_accuracy: 0.0323\n",
      "Epoch 25/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9705 - val_loss: 7.5310 - val_accuracy: 0.0645\n",
      "Epoch 26/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9792 - val_loss: 7.1313 - val_accuracy: 0.0323\n",
      "Epoch 27/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9844 - val_loss: 7.5880 - val_accuracy: 0.0323\n",
      "Epoch 28/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9878 - val_loss: 7.6163 - val_accuracy: 0.0645\n",
      "Epoch 29/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0674 - accuracy: 0.9931 - val_loss: 7.6164 - val_accuracy: 0.0645\n",
      "Epoch 30/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0618 - accuracy: 0.9965 - val_loss: 7.6558 - val_accuracy: 0.0645\n",
      "Epoch 31/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 0.9948 - val_loss: 7.7527 - val_accuracy: 0.0645\n",
      "Epoch 32/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9983 - val_loss: 7.7974 - val_accuracy: 0.0323\n",
      "Epoch 33/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 7.7886 - val_accuracy: 0.0645\n",
      "Epoch 34/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 7.9705 - val_accuracy: 0.0645\n",
      "Epoch 35/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 1.0000 - val_loss: 7.9637 - val_accuracy: 0.0645\n",
      "Epoch 36/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 8.0197 - val_accuracy: 0.0645\n",
      "Epoch 37/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 1.0000 - val_loss: 8.0520 - val_accuracy: 0.0645\n",
      "Epoch 38/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 8.0837 - val_accuracy: 0.0645\n",
      "Epoch 39/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 8.1199 - val_accuracy: 0.0645\n",
      "Epoch 40/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 8.1520 - val_accuracy: 0.0645\n",
      "Epoch 41/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 8.1884 - val_accuracy: 0.0645\n",
      "Epoch 42/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 8.2208 - val_accuracy: 0.0645\n",
      "Epoch 43/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 8.2496 - val_accuracy: 0.0645\n",
      "Epoch 44/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 8.2885 - val_accuracy: 0.0645\n",
      "Epoch 45/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 8.3067 - val_accuracy: 0.0645\n",
      "Epoch 46/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 8.3418 - val_accuracy: 0.0645\n",
      "Epoch 47/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 8.3619 - val_accuracy: 0.0645\n",
      "Epoch 48/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 8.3884 - val_accuracy: 0.0645\n",
      "Epoch 49/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 8.4162 - val_accuracy: 0.0645\n",
      "Epoch 50/50\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 8.4390 - val_accuracy: 0.0645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7ff7c485aa00>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model rec_prec')\n",
    "plt.ylabel('rec_prec')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Силовые структуры       0.00      0.00      0.00         2\n",
      "        Экономика       0.25      0.50      0.33         2\n",
      "      Бывший СССР       0.00      0.00      0.00         3\n",
      "   Интернет и СМИ       0.00      0.00      0.00         2\n",
      "         Ценности       0.00      0.00      0.00         2\n",
      "          Легпром       0.00      0.00      0.00         1\n",
      "  Наука и техника       0.00      0.00      0.00         3\n",
      "              Мир       0.00      0.00      0.00         1\n",
      "         Культура       0.00      0.00      0.00         3\n",
      "              Дом       0.00      0.00      0.00         2\n",
      "           Бизнес       0.08      0.50      0.14         2\n",
      "         Из жизни       0.00      0.00      0.00         3\n",
      "            Спорт       0.00      0.00      0.00         2\n",
      "   69-я параллель       0.00      0.00      0.00         1\n",
      "           Россия       0.00      0.00      0.00         2\n",
      "             Крым       0.00      0.00      0.00         0\n",
      "       Библиотека       0.00      0.00      0.00         0\n",
      "\n",
      "        micro avg       0.06      0.06      0.06        31\n",
      "        macro avg       0.02      0.06      0.03        31\n",
      "     weighted avg       0.02      0.06      0.03        31\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_valid, batch_size=5).argmax(1)\n",
    "\n",
    "print(classification_report(y_valid.argmax(1), pred, labels=list(range(len(label2id))),\n",
    "                            target_names=list(label2id), zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель очень сильно переобучается. Она полностью выучивает обучающую выборку, но с предсказанием новых данных все очень плохо (разрыв в качестве с предобученной моделью огромный). Увеличение количества параметров не поможет - будет точно такая же картина. Для того, чтобы увеличить качество необходимо больше данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
