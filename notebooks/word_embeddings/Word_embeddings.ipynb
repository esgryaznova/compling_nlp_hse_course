{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d4afc86",
   "metadata": {},
   "source": [
    "## Векторные представления слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aecffe8",
   "metadata": {},
   "source": [
    "Векторные представления слов (или embeddings) - это наборы чисел, которые должны как-то отражать смысл/значение слов. Формально значение определить очень сложно, поэтому в NLP используются очень упрощенные и утилитарные подходы к пониманию значения. Например, можно считать, что векторные представления хорошо передают смысл слов, если близость (по какой-то выбранной метрике) между похожими словами большая, а между противоположными - большая. Другой пример - с помощью векторных представлений получается хорошо решить задачу, которая требует понимания смысла (т.е. почти любую NLP задачу), значит эти векторные представления хорошо кодируют смысл. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113ce347",
   "metadata": {},
   "source": [
    "Есть еще такие тонкости как многозначность и зависимость смысла от контекста, но это уже сильно сложнее и мы оставим их на следующие семинары, а пока просто полностью проигнорируем. К тому же, как и с мешком слов, часто упрощенного подхода будет достаточно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad148a50",
   "metadata": {},
   "source": [
    "Единственная окололингвистическая теоретическая часть, о которой стоит сказать это дистрибутивная гипотеза. Она состоит в том, что лингвистические единицы, встречающиеся в схожих контекстах, имеют близкие значения. Обычно в научных статьях цитируют John Firth (Ферс) - '*You shall know a word by the company it keeps*' (Firth, J. R. 1957:11) \n",
    "Также в \"Филосовских исследованиях\" Витгенштейна есть такое -  *“For a large class of cases—though not for all—in which we employ the word ‘meaning’ it can be defined thus: **the meaning of a word is its use in the language.**”* (1951)\n",
    "\n",
    "Саму область иногда называют дистрибутивная семантика."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f39810",
   "metadata": {},
   "source": [
    "Давайте посмотрим, как можно строить векторные представления слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "952c8c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee85cb52",
   "metadata": {},
   "source": [
    "### Матричные выражения "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069eaa65",
   "metadata": {},
   "source": [
    "Для начала вспомним матричные разложения. В двух методах, которые мы использовали для тематического моделирования одна из матриц была размерности (количество слов в словаре, количество тем), т.е. каждую строчку в этой матрице можно рассматривать как векторное представление слова! Давайте разложим матрицу документы-слова, собранную по википедии и посмотрим на близость векторов слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "f682013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://gcdn.pbrd.co/images/YcZxyZhQGrUC.png?o=1\" width=\"1000\" height=\"900\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# на картинке TruncatedSVD\n",
    "Image(url=\"https://gcdn.pbrd.co/images/YcZxyZhQGrUC.png?o=1\",\n",
    "     width=1000, height=900)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "b036f980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в нашем корпусе 20к текстов\n",
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "65bb2fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20003"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4b97780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=10000)\n",
    "svd = TruncatedSVD(200)\n",
    "\n",
    "X = cv.fit_transform(wiki)\n",
    "X_svd = svd.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8779634",
   "metadata": {},
   "source": [
    "Получившаяся матрица X нас не интересует. Нам нужно вытащить матрицу U, она лежит в svd.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d86a188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# изначально U размерности (темы, слова) и для удобства ее нужно перевернуть - транспонировать\n",
    "embeddings = svd.components_.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "59ecdf45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 200)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda1c46b",
   "metadata": {},
   "source": [
    "Теперь вытаскиваем соответствия слов индексам и наоборот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2f90e0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = cv.get_feature_names_out()\n",
    "word2id = {word:i for i,word in enumerate(id2word)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "f4714f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7070"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2id['птица']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4801087",
   "metadata": {},
   "source": [
    "Напишем простую функцию, которая для заданного слова найдет ближайшие ему слова в матрице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3529ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_similar(word, embeddings):\n",
    "    similar = [id2word[i] for i in \n",
    "               cosine_distances(embeddings[word2id[word]].reshape(1, -1), embeddings).argsort()[0][:10]]\n",
    "    return similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebab8e9c",
   "metadata": {},
   "source": [
    "Испытаем ее на нескольких рандомных словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a1adc3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'самцы',\n",
       " 'самцов',\n",
       " 'птицы',\n",
       " 'самки',\n",
       " 'самка',\n",
       " 'самок',\n",
       " 'длины',\n",
       " 'питается',\n",
       " 'жуки']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6cf967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'чудотворца',\n",
       " 'каменная',\n",
       " 'храм',\n",
       " 'прихожан',\n",
       " 'храма',\n",
       " 'богослужения',\n",
       " 'орла',\n",
       " 'деревянная',\n",
       " 'святителя']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c42970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['москва',\n",
       " 'выставка',\n",
       " 'арт',\n",
       " 'галерея',\n",
       " 'центральный',\n",
       " 'выставке',\n",
       " 'выставках',\n",
       " 'галерее',\n",
       " 'художника',\n",
       " 'постоянная']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('москва', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346ce174",
   "metadata": {},
   "source": [
    "Кажется, что получается неплохо. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08395b4f",
   "metadata": {},
   "source": [
    "Но матричные разложения для этой задачи обычно не применяют. Основной метод для создания векторых представлений слов - это word2vec и его улучшение fastext. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9f4420",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37de9786",
   "metadata": {},
   "source": [
    "Word2Vec был создан в 2013 году в Google командой под руководством Tomas Mikolov. \n",
    "\n",
    "Он был описан в двух статьях: \n",
    "1) https://arxiv.org/abs/1301.3781   \n",
    "2) https://aclanthology.org/N13-1090/\n",
    "\n",
    "Главным достоинством word2vec была его эффективность (и по скорости и по потреблению ресурсов), что с одной строны позволило большим компаниям обучить модели на огромных корпусах, а с другой дало возможность отдельным исследователям строить качественные специфичные модели (например, на корпусе научных статей по математике), используя небольшие сервера или вообще личные компьютеры. \n",
    "\n",
    "Следующие несколько лет конференции были забиты статьями, рассматривающими word2vec со всех возможных сторон.\n",
    "\n",
    "Сейчас word2vec уже конечно устарел, транформерные модели лучше. Но бейзлайн все еще очень хороший. К тому же с развитием процессоров он стал еще быстрее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd3f2f",
   "metadata": {},
   "source": [
    "В Word2Vec очень много деталей и оптимизаций, поэтому использовать лучше готовую реализацию (ниже мы это сделаем через gensim). Но для понимания мы попробуем его воспроизвести на tensorflow, параллельно разобрав базовые вещи в deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d6286",
   "metadata": {},
   "source": [
    "Для начала нам нужно построить словарь."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248f8ae",
   "metadata": {},
   "source": [
    "Предобработка нам не так важна. Главное - получить из текстов токены."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "17f8648d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    tokens = text.lower().split()\n",
    "    tokens = [token.strip(punctuation) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964e652",
   "metadata": {},
   "source": [
    "Лучше сразу посчитать количество упоминаний, чтобы отсеять самые редкие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "6a7314a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in wiki:\n",
    "    vocab.update(preprocess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2289def",
   "metadata": {},
   "source": [
    "почти 300к слов - это многовато"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "f175e7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "533408"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba6655d",
   "metadata": {},
   "source": [
    "Возьмем только те, что встретились больше 30 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "334cdb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 30:\n",
    "        filtered_vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "78bbe728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16310"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc18a6ee",
   "metadata": {},
   "source": [
    "~15к - уже нормальная цифра"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec88f467",
   "metadata": {},
   "source": [
    "Теперь нам нужно заменить в каждом тексте слова на числа (индексы в словаре). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ae638",
   "metadata": {},
   "source": [
    "Создадим для этого специальный словарь с индексами. В этот словарь нам нужно положить дополнительный токен - PAD (чуть ниже станет понятнее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "1ad31ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "3b797373",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84373999",
   "metadata": {},
   "source": [
    "Заменяем слова на индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "2f115901",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sentences = []\n",
    "\n",
    "for text in wiki:\n",
    "    tokens = preprocess(text)\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    sentences.append(ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68ae26a",
   "metadata": {},
   "source": [
    "Далее нужно преобразовать токенизированные тексты в формат для обучения. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f254a38",
   "metadata": {},
   "source": [
    "### Skip Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "db2a735c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://leimao.github.io/images/article/2019-08-23-Word2Vec-Classic/word2vec.png\" width=\"600\" height=\"600\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url=\"https://leimao.github.io/images/article/2019-08-23-Word2Vec-Classic/word2vec.png\",\n",
    "     width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d45db6",
   "metadata": {},
   "source": [
    "Word2Vec состоит из двух моделей skip gram и CBOW (continuos bag of words). В обоих алгоритмах происходит итерирование по кусочкам текстов фиксированной длинны (окнам). В каждом окне выбирается центральное целевое слово (target), а слова слева и справа от него считаются контекстом (context). В Skip-gram модель обучается по целевому слову предсказывать контекстные слова, а в CBOW по контексту предсказывается целевое слово. \n",
    "\n",
    "Давайте соберем датасет для skip gram. Датасетом будут просто пары - (целевое слово, контекстное слово). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "56e6e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 5\n",
    "for sent in sentences[:1000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i] # target\n",
    "        # слова до и после целевого\n",
    "        # в начале и в конце окно будет неполным, но это не страшно\n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window] \n",
    "\n",
    "        for context_word in context:\n",
    "            X.append(word)\n",
    "            y.append(context_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "ae28a5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11605, 12656)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1], y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8030c45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1683454, 1683454)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ec4b0",
   "metadata": {},
   "source": [
    "Как и в любой задаче машинниого обучения нужно тестироваться на отложенной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d71be564",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c201693",
   "metadata": {},
   "source": [
    "### Создаем нейронную сеть"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c0b1ef",
   "metadata": {},
   "source": [
    "Для введения в нейронные сети посмотрите:\n",
    "1) серию видео на канале 3blue1brown - https://www.youtube.com/watch?v=aircAruvnKk  \n",
    "2) лекцию курса dlcoure.ai - https://www.youtube.com/watch?v=kWTC1NvL894"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b91edc",
   "metadata": {},
   "source": [
    "Word2Vec можно рассматривать как очень маленькую нейронную сеть - тут всего 1 слой. Сама задача сводится к многоклассой классификации. На вход мы получаем индекс слова, преобразуем его в векторное представление, \n",
    "\n",
    "В tf.keras два способа построения моделей: Sequential и Functional. В первом мы как будто создаем список и добавляем в него слои, а во втором вручную применяем каждый слой к результату предыдущего слоя.\n",
    "\n",
    "Соберем нейронную сеть первым способом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4921a30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 11:59:46.595279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:46.613799: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:46.614564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:46.615993: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-12 11:59:46.617370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:46.618106: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:46.618812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:47.177895: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:47.178441: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:47.178941: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-01-12 11:59:47.179435: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9631 MB memory:  -> device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:07:00.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.8/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# инициализируем модель\n",
    "# это что-то типа model = [] \n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# первым добавляем эмбединг слой\n",
    "# он каждому слову (его индексу) сопоставит вектор заданой размерности\n",
    "# также нам нужно передать параметры нашей выборки - размер словаря (input_dim) и длину текста (input_length)\n",
    "# в нашем случае мы подаем только 1 слово поэтому длина - 1\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(word2id), \n",
    "                                    input_length=1, \n",
    "                                    output_dim=100)) # также указываем желаемый размер эмбединга\n",
    "\n",
    "# на выходе из Embedding мы получим массив размерности (1, 100)\n",
    "# единичная размерность нам не нужна и ее можно схлопнуть\n",
    "# это можно сделать специальным слоем которые называется Flatten\n",
    "# чтобы было понятнее, вот пример на списках\n",
    "# флаттен делает что-то такое\n",
    "# [[1], [2], [3]] -> [1, 2, 3]\n",
    "model.add(tf.keras.layers.Flatten()) \n",
    "\n",
    "# И теперь 1 реальный слой, который называется полносвязным\n",
    "# Полносвязный слой это матрица, применение полносвязного слоя - это умножение на эту матрицу\n",
    "# В полносвязном слое нужно указать количество чисел которое мы хотим получить на выходе\n",
    "# в нашем случае мы хотим получить по 1 числу на 1 слово в словаре\n",
    "# это число будет соответствовать вероятности предсказания этого слова\n",
    "# На входе у нас вектор 1 слова, а умножение вектора на матрицу можно интепретировать как нахождение близости\n",
    "# с каждым элементом матрицы; т.е. мы берем эмбединг и находим близость с эмбедингами всех других слов в словаре\n",
    "\n",
    "# По умолчанию полносвязный слой не выдает вероятности, чтобы их получить нужно использовать softmax\n",
    "# Софтмакс - это одна из функций активации\n",
    "# Функции аквтивации преобразуют числа каким-то нелинейным способом, которого не добьешься обычным умножением на матрицу\n",
    "# сочетание линейных операций с матрицами и векторами и нелинейных функций - это то что делает нейронные сети такими мощными\n",
    "model.add(tf.keras.layers.Dense(len(word2id), activation='softmax'))\n",
    "\n",
    "# компилируем модель\n",
    "# выбираем лосс - функция, по которой модель будет оценивать качество и обновлять веса\n",
    "# для классификации стандартно используется categorical_crossentropy\n",
    "# У нас стоит sparse_categorical_crossentropy потому что мы подаем индексы, а по умолчанию нужно подавать \n",
    "# one-hot векторы или вероятности\n",
    "\n",
    "# выбираем оптимизатор - он влияет на то, как будет обновляться модель \n",
    "# (подробнее вот тут - \n",
    "# https://medium.com/datadriveninvestor/overview-of-different-optimizers-for-neural-networks-e0ed119440c3 ).\n",
    "# По умолчанию можно ставить adam и менять только learning_rate\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              \n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e6bf7",
   "metadata": {},
   "source": [
    "Можно посмотреть на размерности, которые будут получаться после каждого слоя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b57cd8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 1, 100)            1631100   \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16311)             1647411   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,278,511\n",
      "Trainable params: 3,278,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ea7f9",
   "metadata": {},
   "source": [
    "Осталось только обучить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6410a849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1600/1600 [==============================] - 8s 5ms/step - loss: 7.8727 - val_loss: 7.5314\n",
      "Epoch 2/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 7.4530 - val_loss: 7.4054\n",
      "Epoch 3/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 7.3080 - val_loss: 7.3006\n",
      "Epoch 4/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 7.1780 - val_loss: 7.2240\n",
      "Epoch 5/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 7.0605 - val_loss: 7.1654\n",
      "Epoch 6/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 6.9522 - val_loss: 7.1200\n",
      "Epoch 7/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 6.8514 - val_loss: 7.0869\n",
      "Epoch 8/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 6.7579 - val_loss: 7.0638\n",
      "Epoch 9/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 6.6715 - val_loss: 7.0516\n",
      "Epoch 10/10\n",
      "1600/1600 [==============================] - 7s 4ms/step - loss: 6.5930 - val_loss: 7.0469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12b4048d30>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# нейронные сети обучаются не на всех данных сразу\n",
    "# а по кусочкам (батчам)\n",
    "# размер батча зависит от размера нейронной сети и ресурсов\n",
    "# обычно это значение от 4 до нескольких тысяч\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000, \n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a8313",
   "metadata": {},
   "source": [
    "Посмотрим на графики функции потерь. Она должна уменьшаться и на трейне и на тесте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "27b3bb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['loss'])\n",
    "plt.plot(model.history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d65d78",
   "metadata": {},
   "source": [
    "Но нас интересует не сама задача классификации, а получившиеся векторные представления."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1793a448",
   "metadata": {},
   "source": [
    "У нас есть два слоя с матрицами размера (длина словаря, 100). Можно взять векторные представления из любого из этих слоев или взять усредненный вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b903e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.embeddings.Embedding at 0x7f12b41c71f0>,\n",
       " <keras.layers.core.flatten.Flatten at 0x7f12b41c7340>,\n",
       " <keras.layers.core.dense.Dense at 0x7f12b41a45b0>]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "879f2852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16311, 100)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# веса embedding слоя\n",
    "model.layers[0].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c789439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16311)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# веса полносвязного слоя\n",
    "model.layers[2].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b10b6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.layers[0].get_weights()[0]\n",
    "embeddings_2 = model.layers[2].get_weights()[0].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb1a3248",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b6d5cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16311, 100)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f19673bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'небольшая',\n",
       " 'влажных',\n",
       " 'многолетнее',\n",
       " 'травянистое',\n",
       " 'высотой',\n",
       " 'семенами',\n",
       " 'длиной',\n",
       " 'коротким',\n",
       " 'бутоны']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fe05034b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'иисуса',\n",
       " 'деревянная',\n",
       " 'устроена',\n",
       " 'собор',\n",
       " 'построенная',\n",
       " 'значительным',\n",
       " 'петра',\n",
       " 'павла',\n",
       " 'башня']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c84ed4f",
   "metadata": {},
   "source": [
    "### CBOW\n",
    "\n",
    "\n",
    "Теперь попробуем CBOW. В нем нужно по контексту предсказать целевое слово. В отличие от skip-gram тут сразу используется весь контекст, а векторы слов в контексте усредняются в 1 вектор контекста."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449ee211",
   "metadata": {},
   "source": [
    "Собрать датасет очень просто."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "b79059e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "window = 5\n",
    "for sent in sentences[:10000]:\n",
    "    for i in range(len(sent)-1):\n",
    "        word = sent[i]\n",
    "        context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "        \n",
    "        X.append(context)\n",
    "        y.append(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2358400",
   "metadata": {},
   "source": [
    "Но нужно его немного поправить. В начале и конце текстов окна будут не полные и соответственно длина контекста будет не одинаковая. Но для преобразования в массив, длины должны быть одинаковыми. Решение этой проблемы - паддинг, добавление недостающего количества нулей  (может быть и другой индекс, но чаще всего именно 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "8bf10994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6444, 12656, 7765, 2950],\n",
       " [11605, 12656, 7765, 2950, 7540],\n",
       " [11605, 6444, 7765, 2950, 7540, 3322],\n",
       " [11605, 6444, 12656, 2950, 7540, 3322, 12438],\n",
       " [11605, 6444, 12656, 7765, 7540, 3322, 12438, 7765],\n",
       " [11605, 6444, 12656, 7765, 2950, 3322, 12438, 7765, 11689],\n",
       " [6444, 12656, 7765, 2950, 7540, 12438, 7765, 11689, 1881],\n",
       " [12656, 7765, 2950, 7540, 3322, 7765, 11689, 1881, 7765],\n",
       " [7765, 2950, 7540, 3322, 12438, 11689, 1881, 7765, 2200],\n",
       " [2950, 7540, 3322, 12438, 7765, 1881, 7765, 2200, 12905]]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# оригинальные контексты\n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8091932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnefedov/.pyenv/versions/3.7.2/lib/python3.7/site-packages/ipykernel_launcher.py:1: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([list([6444, 12656, 7765, 2950]),\n",
       "       list([11605, 12656, 7765, 2950, 7540]),\n",
       "       list([11605, 6444, 7765, 2950, 7540, 3322]),\n",
       "       list([11605, 6444, 12656, 2950, 7540, 3322, 12438]),\n",
       "       list([11605, 6444, 12656, 7765, 7540, 3322, 12438, 7765]),\n",
       "       list([11605, 6444, 12656, 7765, 2950, 3322, 12438, 7765, 11689]),\n",
       "       list([6444, 12656, 7765, 2950, 7540, 12438, 7765, 11689, 1881]),\n",
       "       list([12656, 7765, 2950, 7540, 3322, 7765, 11689, 1881, 7765]),\n",
       "       list([7765, 2950, 7540, 3322, 12438, 11689, 1881, 7765, 2200]),\n",
       "       list([2950, 7540, 3322, 12438, 7765, 1881, 7765, 2200, 12905])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b44ae6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "a423d7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=10, padding='post')\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "993b116b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6444, 12656,  7765, ...,     0,     0,     0],\n",
       "       [11605, 12656,  7765, ...,     0,     0,     0],\n",
       "       [11605,  6444,  7765, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [13508,  5846, 13204, ...,  5200,     0,     0],\n",
       "       [ 5846, 13204,  7765, ...,     0,     0,     0],\n",
       "       [13204,  7765,  5045, ...,     0,     0,     0]], dtype=int32)"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# контексты после паддинга\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "41d5dc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4639c",
   "metadata": {},
   "source": [
    "Сама модель почти полностью совпадает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21f963c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# 1 отличие - то что на вход подается не 1 слово а целое окно контекста\n",
    "# но на уровне embedding слоя нужно изменить только input_length\n",
    "# она будет равна числу до которого мы делали паддинг\n",
    "model.add(tf.keras.layers.Embedding(input_dim=len(word2id), \n",
    "                                    input_length=10, \n",
    "                                    output_dim=100))\n",
    "\n",
    "# 2 отличие - нужно усреднить контекст в 1 вектор\n",
    "model.add(tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1)))\n",
    "\n",
    "model.add(tf.keras.layers.Dense(len(word2id), activation='softmax'))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(lr=0.001), loss='sparse_categorical_crossentropy',\n",
    "              \n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "864e36f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 10, 100)           1631100   \n",
      "                                                                 \n",
      " lambda_3 (Lambda)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16311)             1647411   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,278,511\n",
      "Trainable params: 3,278,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "34d67f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1653/1653 [==============================] - 8s 5ms/step - loss: 7.1693 - val_loss: 6.6003\n",
      "Epoch 2/5\n",
      "1653/1653 [==============================] - 7s 5ms/step - loss: 6.2509 - val_loss: 6.1478\n",
      "Epoch 3/5\n",
      "1653/1653 [==============================] - 7s 5ms/step - loss: 5.8232 - val_loss: 5.9535\n",
      "Epoch 4/5\n",
      "1653/1653 [==============================] - 8s 5ms/step - loss: 5.5460 - val_loss: 5.8524\n",
      "Epoch 5/5\n",
      "1653/1653 [==============================] - 8s 5ms/step - loss: 5.3367 - val_loss: 5.8009\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12a0025190>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=1000,\n",
    "         epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9873dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_1 = model.layers[0].get_weights()[0]\n",
    "embeddings_2 = model.layers[2].get_weights()[0].T\n",
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a2896c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.mean([embeddings_1, embeddings_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7b8f0da5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16311, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b7f2dbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['птица',\n",
       " 'рыба',\n",
       " 'жук',\n",
       " 'обыкновенная',\n",
       " 'чёрная',\n",
       " 'кустарников',\n",
       " 'растениями',\n",
       " 'птиц',\n",
       " 'змея',\n",
       " 'дерево']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('птица', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96b7ef8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40dac186",
   "metadata": {},
   "source": [
    "### Negative sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637385f3",
   "metadata": {},
   "source": [
    "Одна из основных оптимизаций в word2vec - negative sampling. Задача из многоклассовой классификации преобразуется в бинарную классификацию. На вход подается сразу и целевое слово и контекст, а на выходе ожидается вероятность того, что они употребляются вместе. Положительные примеры просто берутся из корпуса, а для того, чтобы собрать негативные примеры, из словаря просто случайно выбираются слова. Возможна ситуация, когда для контекста случайно выбранное слово на самом деле может встретиться в этом контексте, но за счет большого количества примеров, такие неточности не повлияют на итоговый результат."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8312ee",
   "metadata": {},
   "source": [
    "В этот раз не будем сразу генерировать весь датасет. Он получается очень большой и эффективнее генерировать примеры на ходу (т.е. использовать генератор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1928254d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0663f708",
   "metadata": {},
   "source": [
    "Эта функция просто генерирует обучающее примеры батчами. В tf генераторы можно напрямую модавать в fit модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e850e1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip gram\n",
    "def gen_batches_sg(sentences, window = 5, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "                for context_word in context:\n",
    "                    X_target.append(word)\n",
    "                    X_context.append(context_word)\n",
    "                    y.append(1)\n",
    "                    \n",
    "                    X_target.append(word)\n",
    "                    X_context.append(np.random.randint(vocab_size))\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if len(X_target) >= batch_size:\n",
    "                        X_target = np.array(X_target)\n",
    "                        X_context = np.array(X_context)\n",
    "                        y = np.array(y)\n",
    "                        yield ((X_target, X_context), y)\n",
    "                        X_target = []\n",
    "                        X_context = []\n",
    "                        y = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "33541b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cbow \n",
    "def gen_batches_cbow(sentences, window = 5, batch_size=1000):\n",
    "    while True:\n",
    "        X_target = []\n",
    "        X_context = []\n",
    "        y = []\n",
    "\n",
    "        for sent in sentences:\n",
    "            for i in range(len(sent)-1):\n",
    "                word = sent[i]\n",
    "                context = sent[max(0, i-window):i] + sent[i+1:i+window]\n",
    "\n",
    "                X_target.append(word)\n",
    "                X_context.append(context)\n",
    "                y.append(1)\n",
    "                \n",
    "                X_target.append(np.random.randint(vocab_size))\n",
    "                X_context.append(context)\n",
    "                y.append(0)\n",
    "\n",
    "                if len(X_target) == batch_size:\n",
    "                    X_target = np.array(X_target)\n",
    "                    X_context = tf.keras.preprocessing.sequence.pad_sequences(X_context, maxlen=window*2)\n",
    "                    y = np.array(y)\n",
    "                    yield ((X_target, X_context), y)\n",
    "                    X_target = []\n",
    "                    X_context = []\n",
    "                    y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b09b8a",
   "metadata": {},
   "source": [
    "Саму модель нужно уже задать через Functional API, т.к. у нас будет два входа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6e086b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Flatten()(embeddings_context)\n",
    "\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "952c5ab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.4739 - accuracy: 0.7793 - val_loss: 0.5272 - val_accuracy: 0.7593\n",
      "Epoch 2/2\n",
      "10000/10000 [==============================] - 36s 4ms/step - loss: 0.4507 - accuracy: 0.7962 - val_loss: 0.4690 - val_accuracy: 0.7889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f128c6e5a30>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_sg(sentences[:19000], window=5),\n",
    "          validation_data=gen_batches_sg(sentences[19000:],  window=5),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=10000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1a56360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f06af355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'храм',\n",
       " 'построена',\n",
       " 'монастыря',\n",
       " 'монастырь',\n",
       " 'святого',\n",
       " 'каменный',\n",
       " 'собора',\n",
       " 'деревянная',\n",
       " 'николая']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c539e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7255ae35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cbow negative sampling\n",
    "inputs_target = tf.keras.layers.Input(shape=(1,))\n",
    "inputs_context = tf.keras.layers.Input(shape=(10,))\n",
    "\n",
    "\n",
    "embeddings_target = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_target, )\n",
    "embeddings_context = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=300)(inputs_context, )\n",
    "\n",
    "target = tf.keras.layers.Flatten()(embeddings_target)\n",
    "context = tf.keras.layers.Lambda(lambda x: tf.keras.backend.sum(x, axis=1))(embeddings_context)\n",
    "dot = tf.keras.layers.Dot(1)([target, context])\n",
    "\n",
    "# полученную близость нужно преобразовать в вероятность\n",
    "# когда она одна используется не софтмакс и сигмоида\n",
    "outputs = tf.keras.layers.Activation(activation='sigmoid')(dot)\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs_target, inputs_context], \n",
    "                       outputs=outputs)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "36a09425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "5000/5000 [==============================] - 22s 4ms/step - loss: 0.3447 - accuracy: 0.8503 - val_loss: 0.2899 - val_accuracy: 0.8804\n",
      "Epoch 2/2\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 0.2521 - accuracy: 0.8954 - val_loss: 0.2626 - val_accuracy: 0.8925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f128c478be0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(gen_batches_cbow(sentences[:19000], window=5),\n",
    "          validation_data=gen_batches_cbow(sentences[19000:],  window=5),\n",
    "          batch_size=1000,\n",
    "          steps_per_epoch=5000,\n",
    "          validation_steps=30,\n",
    "         epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "778836d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "953fe0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['семья',\n",
       " 'переехала',\n",
       " 'родители',\n",
       " 'уехала',\n",
       " 'жила',\n",
       " 'рос',\n",
       " 'сестра',\n",
       " 'мать',\n",
       " 'проживала',\n",
       " 'едет']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('семья', embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "07e6b428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['церковь',\n",
       " 'храм',\n",
       " 'церкви',\n",
       " 'храма',\n",
       " 'монастыря',\n",
       " 'собор',\n",
       " 'часовня',\n",
       " 'здание',\n",
       " 'колокольня',\n",
       " 'святого']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar('церковь', embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dc9cac",
   "metadata": {},
   "source": [
    "Другая значимая оптимизация в word2vec - это иерархический софтмакс. Когда мы считали модель без негативного семплирования, то у нас был большой полносвязный слой с софтмаксом. Иерархический софтмакс упрощает расчеты в этом слое, но его уже так просто не воспроизведешь.\n",
    "\n",
    "На этом месте уже лучше перейти к готовой реализации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af3bf3",
   "metadata": {},
   "source": [
    "## Word2Vec в gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b28433",
   "metadata": {},
   "source": [
    "В gensim есть питоновская обертка к оригинальному ворд2веку, которой очень удобно пользоваться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "d916424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414972b",
   "metadata": {},
   "source": [
    "На вход нужно подавать список списков (токенизированный текст)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "28b573f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki = open('wiki_data.txt').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "912f3adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [preprocess(text) for text in wiki]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "ce4b4186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = open('corpus.txt', 'w')\n",
    "# for text in texts:\n",
    "#     f.write(' '.join(text) + '\\n')\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "118e3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# corpus = gensim.models.word2vec.LineSentence('corpus.txt', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91051ba2",
   "metadata": {},
   "source": [
    "В саму модель нужно передать корпус для обучения, для остальных параметров есть значения по умолчанию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "71504b2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.5 s, sys: 207 ms, total: 39.7 s\n",
      "Wall time: 15.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "524499f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8743033409118652),\n",
       " ('построена', 0.8359026312828064),\n",
       " ('богородицы', 0.8297877311706543),\n",
       " ('православная', 0.8275739550590515),\n",
       " ('деревянная', 0.8258281946182251),\n",
       " ('храм', 0.8068298697471619),\n",
       " ('икона', 0.8052462339401245),\n",
       " ('пресвятой', 0.8045442700386047),\n",
       " ('божией', 0.7889246940612793),\n",
       " ('успения', 0.7842323184013367)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3363b11e",
   "metadata": {},
   "source": [
    "Давайте теперь разберемся с параметрами:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6128bdd",
   "metadata": {},
   "source": [
    "**vector_size** - размер вектора, обычно используют значение 100-1000  \n",
    "\n",
    "**min_count** - минимальная частота слова в корпусе (выше мы тоже фильтровали по частототе 30)  \n",
    "\n",
    "**max_vocab_size** - максимальный размер словаря\n",
    "\n",
    "**window** - размер окна (выше мы использовали значение 10)\n",
    "\n",
    "**epochs** - количество эпох (полных итераций по корпусу)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6ea31ac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.6 s, sys: 248 ms, total: 24.9 s\n",
      "Wall time: 9.36 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=5,\n",
    "                             epochs=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "304b59ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храм', 0.7513039112091064),\n",
       " ('собор', 0.6645839214324951),\n",
       " ('храма', 0.6581066846847534),\n",
       " ('церкви', 0.6571823358535767),\n",
       " ('монастырь', 0.644494354724884),\n",
       " ('монастыря', 0.6430743336677551),\n",
       " ('святого', 0.6364166736602783),\n",
       " ('святой', 0.6202442049980164),\n",
       " ('собора', 0.6182669401168823),\n",
       " ('николая', 0.5432458519935608)]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004aa64a",
   "metadata": {},
   "source": [
    "CBOW или Skip-gram выбираются через параметр **sg** - 1 это skip-gram, а 0 - cbow (по умолчанию всегда cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "6982b4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 23s, sys: 581 ms, total: 1min 23s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=5,\n",
    "                             epochs=7,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a516ad01",
   "metadata": {},
   "source": [
    "Скип-грам обучается значительно дольше "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "240d2fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храм', 0.6266138553619385),\n",
       " ('храма', 0.5525968074798584),\n",
       " ('собор', 0.5485511422157288),\n",
       " ('церкви', 0.5410593152046204),\n",
       " ('монастыря', 0.5160554647445679),\n",
       " ('монастырь', 0.5113397836685181),\n",
       " ('собора', 0.4808449149131775),\n",
       " ('здание', 0.4742560088634491),\n",
       " ('святого', 0.4521041512489319),\n",
       " ('николая', 0.4474599063396454)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5180b31b",
   "metadata": {},
   "source": [
    "Увеличения window на cbow практически не влияет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a6b81c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 s, sys: 252 ms, total: 29.1 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=10,\n",
    "                             epochs=7,\n",
    "                             \n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a6dc5",
   "metadata": {},
   "source": [
    "А вот skip-gram сильно замедляется с увеличением окна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6cef32e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 491 ms, total: 2min 25s\n",
      "Wall time: 49.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             vector_size=300, \n",
    "                             min_count=30, \n",
    "                             max_vocab_size=10000,\n",
    "                             window=10,\n",
    "                             epochs=7,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79d046d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a9ec418",
   "metadata": {},
   "source": [
    "Выбор между negative_sampling и hierarchical softmax осуществляется через 2 параметра **hs** и **negative**:   \n",
    "1) **hs=0, negative=0** - ни то ни другое не используется  \n",
    "2) **hs=1** - используется hierarchical softmax  \n",
    "3) **hs=0, negative > 0** - используется negative_sampling и число в negative указывает сколько негативных примеров семплировать (в документации советуют значения от 5 до 20)  (по умолчанию)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6fa3ed28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.99 s, sys: 185 ms, total: 9.18 s\n",
      "Wall time: 9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts,\n",
    "                             hs=0,\n",
    "                             negative=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab7c517",
   "metadata": {},
   "source": [
    "Работает быстрее, но качество сильно страдает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "6868493d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('спрятан', 0.42304709553718567),\n",
       " ('железную', 0.4164682626724243),\n",
       " ('краёв', 0.4125758111476898),\n",
       " ('жизненную', 0.40853172540664673),\n",
       " ('интерфейсом', 0.4083697497844696),\n",
       " ('понижении', 0.4059951603412628),\n",
       " ('откладывать', 0.3957667648792267),\n",
       " ('ленинградскую', 0.3870789408683777),\n",
       " ('36', 0.381250262260437),\n",
       " ('архангельского', 0.37584179639816284)]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4008e899",
   "metadata": {},
   "source": [
    "Иерархический софтмакс работает сильно дольше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b9c0725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 342 ms, total: 1min 25s\n",
      "Wall time: 33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ea742df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.7753229141235352),\n",
       " ('храм', 0.7011154890060425),\n",
       " ('колокольня', 0.6815000772476196),\n",
       " ('деревянная', 0.6767951250076294),\n",
       " ('построенная', 0.6744670271873474),\n",
       " ('церкви', 0.6732568740844727),\n",
       " ('икона', 0.6712637543678284),\n",
       " ('храма', 0.6560209393501282),\n",
       " ('построена', 0.6511436700820923),\n",
       " ('монастыре', 0.6485512852668762)]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c3a389",
   "metadata": {},
   "source": [
    "Дефолтная настройка работает достаточно быстро и хорошо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "bbc7b815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 s, sys: 238 ms, total: 40.9 s\n",
      "Wall time: 15.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=0,\n",
    "                             negative=5\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "266440a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8404061794281006),\n",
       " ('православная', 0.8251654505729675),\n",
       " ('построена', 0.8183906674385071),\n",
       " ('деревянная', 0.8111212849617004),\n",
       " ('богородицы', 0.8039596676826477),\n",
       " ('храм', 0.8038241267204285),\n",
       " ('икона', 0.7885087132453918),\n",
       " ('пресвятой', 0.7846370339393616),\n",
       " ('монастырь', 0.7819284796714783),\n",
       " ('чудотворца', 0.7770885229110718)]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1da5a8c",
   "metadata": {},
   "source": [
    "Повышение negative влияет на время обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "ee61c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 39s, sys: 348 ms, total: 1min 40s\n",
      "Wall time: 35.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             hs=0,\n",
    "                             negative=20\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c297b275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.857257604598999),\n",
       " ('деревянная', 0.8246216177940369),\n",
       " ('построена', 0.8122153282165527),\n",
       " ('храм', 0.8049266934394836),\n",
       " ('богородицы', 0.7839708924293518),\n",
       " ('построенная', 0.772368848323822),\n",
       " ('православная', 0.7637260556221008),\n",
       " ('храме', 0.7629793882369995),\n",
       " ('монастырь', 0.7567533254623413),\n",
       " ('каменная', 0.7556505799293518)]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a7e24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6b5357b",
   "metadata": {},
   "source": [
    "Есть еще несколько параметров, но уже не таких влиятельных:\n",
    "\n",
    "1) **sample** - отвечает за downsampling частотных слов; чем меньше, тем сильнее штрафуются частотные слова (по умолчанию стоит 1e-3, но можно поставить 1e-4, 1e-5). Для sg это будет значительно влиять на скорость (1e-5 будет быстрее)  \n",
    "2) **ns_exponent** -  регулирет downsampling частотных слов в negative sampling; 0 - никакого штрафа за частотность (как у нас выше с полным рандомом), 1 - штрафует пропорционально частотности, значения 0-1 что-то посередине (по умолчанию стоит 0.75)  \n",
    "3) **cbow_mean** - отвечает за функцию агрегации в cbow; 1 - это среднее, 0 - сумма (у нас выше среднее, оно же стоит по умолчанию)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0d1a5345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 345 ms, total: 1min 29s\n",
      "Wall time: 32.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             sample=1e-5,\n",
    "                             sg=1\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1c3928c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('храм', 0.9693702459335327),\n",
       " ('часовня', 0.9608985781669617),\n",
       " ('храма', 0.9532955884933472),\n",
       " ('храме', 0.9456794261932373),\n",
       " ('деревянная', 0.9453122615814209),\n",
       " ('рождества', 0.9441068172454834),\n",
       " ('монастыря', 0.9335580468177795),\n",
       " ('чудотворца', 0.9319661855697632),\n",
       " ('богородицы', 0.9289035201072693),\n",
       " ('деревянный', 0.9278043508529663)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a6e9b5e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.7 s, sys: 254 ms, total: 40.9 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             ns_exponent=0.84\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "29ad129d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('часовня', 0.8298123478889465),\n",
       " ('храм', 0.8118749856948853),\n",
       " ('построена', 0.7992591261863708),\n",
       " ('деревянная', 0.7960627675056458),\n",
       " ('монастыря', 0.7658997774124146),\n",
       " ('монастырь', 0.7656899094581604),\n",
       " ('богородицы', 0.7621358036994934),\n",
       " ('православная', 0.76121985912323),\n",
       " ('церкви', 0.7610598802566528),\n",
       " ('собор', 0.7493856549263)]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb2fda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fd8c2eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.8 s, sys: 232 ms, total: 41 s\n",
      "Wall time: 16 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "w2v = gensim.models.Word2Vec(texts, \n",
    "                             cbow_mean=0\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c08ade15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('православная', 0.9259366393089294),\n",
       " ('деревянная', 0.9255096912384033),\n",
       " ('богородицы', 0.9177859425544739),\n",
       " ('пресвятой', 0.9164575934410095),\n",
       " ('построена', 0.9148902893066406),\n",
       " ('община', 0.9139506220817566),\n",
       " ('икона', 0.9081771969795227),\n",
       " ('часовня', 0.9020712375640869),\n",
       " ('рождества', 0.8993982672691345),\n",
       " ('епархия', 0.8981451988220215)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31490cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f383ad3",
   "metadata": {},
   "source": [
    "## FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a79c3b",
   "metadata": {},
   "source": [
    "В 2015 почти та же команда выпустила улучшение - FastText (статья - https://arxiv.org/abs/1607.04606). Главная доработка в нем - использование символьных нграммов. В оригинальном word2vec словарь обучается вначале и фиксируется, добавлять новые слова к обученной модели нельзя. Соответственно, если слова нет в словаре, то и вектора для него не будет.\n",
    "\n",
    "В FastText каждое слово дополнительно разбивается на символьные нграммы и для каждого символьного нграмма тоже есть свой отдельный эмбеддинг. При предсказании векторы символьных нграммов и целого слова усредняются в 1 вектор. В дальнейшем это позволяет генерировать векторы для слов, которых нет в изначальном словаре. Нужно только чтобы новое слово состояло уже из известных символьных нграмм."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17faa699",
   "metadata": {},
   "source": [
    "Интерфейс обучения и большинство параметров - точно такие же"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ea91a3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 56s, sys: 667 ms, total: 2min 57s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ab1e1",
   "metadata": {},
   "source": [
    "Использование символьных нграммов сразу заметно - близким считаются слова похожие по написанию, а не только по смыслу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b43dc9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('«церковь', 0.9908390641212463),\n",
       " ('церковь»', 0.9904298186302185),\n",
       " ('церковью', 0.9601637125015259),\n",
       " ('церкви»', 0.8868716955184937),\n",
       " ('церкви', 0.8820227980613708),\n",
       " ('церквям', 0.8782130479812622),\n",
       " ('монастыря»', 0.8180803656578064),\n",
       " ('храма', 0.8161970376968384),\n",
       " ('церквях', 0.8152474761009216),\n",
       " ('монастырю', 0.8105190396308899)]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6b70a2",
   "metadata": {},
   "source": [
    "Дополнительные параметры:\n",
    "\n",
    "1) **min_n** - минимальная длина для символьных нграмм (по умолчанию 3)  \n",
    "2) **max_n** - максимальная длина для символьных нграмм, если поставить меньше min_n, то символьные нграммы не будут использоваться (по умолчанию 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "454cde27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 29s, sys: 481 ms, total: 4min 30s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts, min_n=2, max_n=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f0df4504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('церковь»', 0.9192732572555542),\n",
       " ('«церковь', 0.9157706499099731),\n",
       " ('церковью', 0.9103031754493713),\n",
       " ('церкви', 0.7926523089408875),\n",
       " ('монастырь', 0.7874160408973694),\n",
       " ('монастырская', 0.7767997980117798),\n",
       " ('церковно-приходская', 0.770706832408905),\n",
       " ('церкви»', 0.7694923281669617),\n",
       " ('церковная', 0.769381582736969),\n",
       " ('святынь', 0.7627576589584351)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft.wv.most_similar('церковь')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5badb355",
   "metadata": {},
   "source": [
    "### Использование предобученных моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc374a8f",
   "metadata": {},
   "source": [
    "В открытом доступе есть много предобученных моделей. Они как правило обучены на неспецифических, но очень больших корпусах (новостных, википедии). Если в решаемой задаче тексты похожи, то лучше использовать предобученные модели. Свои модели имеет смысл обучать, когда данные очень специфичные.\n",
    "\n",
    "Для русского готовые модели можно взять на сайте https://rusvectores.org/ru/models/ \n",
    "\n",
    "Нужно скачать какую-то модели, распаковать и открыть в генсиме.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5e2684a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mnefedov/.pyenv/versions/3.6.5/lib/python3.6/site-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "# я скачал вот эту tayga_upos_skipgram_300_2_2019 \n",
    "# и распаковал архив в папку taiga_w2v_model\n",
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "bb122eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('март_NOUN', 0.9567033052444458),\n",
       " ('ноябрь_NOUN', 0.9523458480834961),\n",
       " ('декабрь_NOUN', 0.9509049654006958),\n",
       " ('апрель_NOUN', 0.949961245059967),\n",
       " ('январь_NOUN', 0.9472224712371826),\n",
       " ('октябрь_NOUN', 0.937659740447998),\n",
       " ('май_NOUN', 0.911928117275238),\n",
       " ('июнь_NOUN', 0.9011650681495667),\n",
       " ('сентябрь_NOUN', 0.899361252784729),\n",
       " ('июль_NOUN', 0.8842827677726746)]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('февраль_NOUN')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f36dd",
   "metadata": {},
   "source": [
    "Слова в модели хранятся в нормализованном виде с прибавленной частью речи. Для пребобработки там использовался udpipe, вызывать его в тетрадке неудобно, поэтому можно заменить его на майстем (по большей части все будет совпадать). На сайте есть ссылка на файл с соответствием тэгов майстема тэгам Udpipe (https://github.com/akutuzov/universal-pos-tags/blob/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "2d5dcca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {}\n",
    "\n",
    "for line in open('ru-rnc.map.txt'):\n",
    "    ms, ud = line.strip('\\n').split()\n",
    "    mapping[ms] = ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a590f675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'ADJ',\n",
       " 'ADV': 'ADV',\n",
       " 'ADVPRO': 'ADV',\n",
       " 'ANUM': 'ADJ',\n",
       " 'APRO': 'DET',\n",
       " 'COM': 'ADJ',\n",
       " 'CONJ': 'SCONJ',\n",
       " 'INTJ': 'INTJ',\n",
       " 'NONLEX': 'X',\n",
       " 'NUM': 'NUM',\n",
       " 'PART': 'PART',\n",
       " 'PR': 'ADP',\n",
       " 'S': 'NOUN',\n",
       " 'SPRO': 'PRON',\n",
       " 'UNKN': 'X',\n",
       " 'V': 'VERB'}"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "d09b0994",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a189810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_mystem(text):\n",
    "    tokens = []\n",
    "    norm_words = m.analyze(text)\n",
    "    for norm_word in norm_words:\n",
    "        if 'analysis' not in norm_word:\n",
    "            continue\n",
    "            \n",
    "        if not len(norm_word['analysis']):\n",
    "            lemma = norm_word['text']\n",
    "            pos = 'UNKN'\n",
    "        else:\n",
    "            lemma = norm_word[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = norm_word[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "        pos = mapping[pos]\n",
    "        tokens.append(lemma+'_'+pos)\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5490ed",
   "metadata": {},
   "source": [
    "Эту функцию можно применять к любому тексты и получать на выходе токены, по которым можно обращаться к модели напрямую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "fd4cbd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['обучать_VERB',\n",
       " 'классификатор_NOUN',\n",
       " 'парафраз_NOUN',\n",
       " 'на_ADP',\n",
       " 'предобученный_ADJ',\n",
       " 'модель_NOUN',\n",
       " 'вы_PRON',\n",
       " 'нужно_ADV',\n",
       " 'быть_VERB',\n",
       " 'дома_ADV']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize_mystem('Обучить классификатор парафразов на предобученной модели вам нужно будет дома')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "2e4f1b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['обучать_VERB'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d61b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9295afc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1ff00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38dee586",
   "metadata": {},
   "source": [
    "## Использование для классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecfe1f",
   "metadata": {},
   "source": [
    "До этого мы почти никак не оценивали качество эмбедингов, только смотрели на ближайшие по нескольким словам. На практике нужно всегда ориентироваться на задачу, которую нужно решить. Давайте возьмем датасет для классификации и обучим несколько моделей с использованием векторных представлений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "df109f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f85b7d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['norm_text'] = data.comment.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "a9ae9e6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "      <th>norm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[верблюдов-то, за, что, дебилы, бл]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[хохлы, это, отдушина, затюканого, россиянина,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[собаке, , собачья, смерть]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[страницу, обнови, дебил, это, тоже, не, оскор...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[тебя, не, убедил, 6-страничный, пдф, в, том, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14407</th>\n",
       "      <td>Вонючий совковый скот прибежал и ноет. А вот и...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[вонючий, совковый, скот, прибежал, и, ноет, а...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14408</th>\n",
       "      <td>А кого любить? Гоблина тупорылого что-ли? Или ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[а, кого, любить, гоблина, тупорылого, что-ли,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14409</th>\n",
       "      <td>Посмотрел Утомленных солнцем 2. И оказалось, ч...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[посмотрел, утомленных, солнцем, 2, и, оказало...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14410</th>\n",
       "      <td>КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[крымотред, нарушает, правила, раздела, т.к, в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14411</th>\n",
       "      <td>До сих пор пересматриваю его видео. Орамбо кст...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[до, сих, пор, пересматриваю, его, видео, орам...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14412 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  toxic  \\\n",
       "0                   Верблюдов-то за что? Дебилы, бл...\\n    1.0   \n",
       "1      Хохлы, это отдушина затюканого россиянина, мол...    1.0   \n",
       "2                              Собаке - собачья смерть\\n    1.0   \n",
       "3      Страницу обнови, дебил. Это тоже не оскорблени...    1.0   \n",
       "4      тебя не убедил 6-страничный пдф в том, что Скр...    1.0   \n",
       "...                                                  ...    ...   \n",
       "14407  Вонючий совковый скот прибежал и ноет. А вот и...    1.0   \n",
       "14408  А кого любить? Гоблина тупорылого что-ли? Или ...    1.0   \n",
       "14409  Посмотрел Утомленных солнцем 2. И оказалось, ч...    0.0   \n",
       "14410  КРЫМОТРЕД НАРУШАЕТ ПРАВИЛА РАЗДЕЛА Т.К В НЕМ Н...    1.0   \n",
       "14411  До сих пор пересматриваю его видео. Орамбо кст...    0.0   \n",
       "\n",
       "                                               norm_text  \n",
       "0                    [верблюдов-то, за, что, дебилы, бл]  \n",
       "1      [хохлы, это, отдушина, затюканого, россиянина,...  \n",
       "2                            [собаке, , собачья, смерть]  \n",
       "3      [страницу, обнови, дебил, это, тоже, не, оскор...  \n",
       "4      [тебя, не, убедил, 6-страничный, пдф, в, том, ...  \n",
       "...                                                  ...  \n",
       "14407  [вонючий, совковый, скот, прибежал, и, ноет, а...  \n",
       "14408  [а, кого, любить, гоблина, тупорылого, что-ли,...  \n",
       "14409  [посмотрел, утомленных, солнцем, 2, и, оказало...  \n",
       "14410  [крымотред, нарушает, правила, раздела, т.к, в...  \n",
       "14411  [до, сих, пор, пересматриваю, его, видео, орам...  \n",
       "\n",
       "[14412 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801380ad",
   "metadata": {},
   "source": [
    "Также как и в начале собираем словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "5e6f3dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7232"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = Counter()\n",
    "\n",
    "for text in data['norm_text']:\n",
    "    vocab.update(text)\n",
    "    \n",
    "filtered_vocab = set()\n",
    "\n",
    "for word in vocab:\n",
    "    if vocab[word] > 5:\n",
    "        filtered_vocab.add(word)\n",
    "\n",
    "len(filtered_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "5600572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = { 'PAD':0}\n",
    "\n",
    "for word in filtered_vocab:\n",
    "    word2id[word] = len(word2id)\n",
    "id2word = {i:word for word, i in word2id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce34a3b8",
   "metadata": {},
   "source": [
    "Переводим слова в индексы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "de33c88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "\n",
    "for tokens in data['norm_text']:\n",
    "    ids = [word2id[token] for token in tokens if token in word2id]\n",
    "    X.append(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ecbca663",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=100)\n",
    "y = data.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5703e724",
   "metadata": {},
   "source": [
    "Разбиваем на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "0997f420",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c169d9b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "435e8ed5",
   "metadata": {},
   "source": [
    "Теперь мы можем уже обучать модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "90385246",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs, )\n",
    "# embedding слой возвращает последовательность векторов\n",
    "# а нам нужно классифицировать сразу весь текст\n",
    "# стандартный подход в этом случае - усреднить единичные вектора в 1 вектор текста\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "# к усредненному вектору мы уже применяем полносвязный слой, который вернет вероятность токсичности\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "84de337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.3124 - accuracy: 0.8854 - val_loss: 0.4030 - val_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2851 - accuracy: 0.8947 - val_loss: 0.3988 - val_accuracy: 0.8488\n",
      "Epoch 3/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.9027 - val_loss: 0.3972 - val_accuracy: 0.8433\n",
      "Epoch 4/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2437 - accuracy: 0.9091 - val_loss: 0.3991 - val_accuracy: 0.8419\n",
      "Epoch 5/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2269 - accuracy: 0.9167 - val_loss: 0.4018 - val_accuracy: 0.8405\n",
      "Epoch 6/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2128 - accuracy: 0.9219 - val_loss: 0.4095 - val_accuracy: 0.8516\n",
      "Epoch 7/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.2012 - accuracy: 0.9251 - val_loss: 0.4138 - val_accuracy: 0.8530\n",
      "Epoch 8/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.1891 - accuracy: 0.9298 - val_loss: 0.4187 - val_accuracy: 0.8447\n",
      "Epoch 9/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.1804 - accuracy: 0.9324 - val_loss: 0.4242 - val_accuracy: 0.8419\n",
      "Epoch 10/10\n",
      "428/428 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9349 - val_loss: 0.4340 - val_accuracy: 0.8460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15a823470>"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "         epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d4fc1c",
   "metadata": {},
   "source": [
    "В этой модели векторные представления обучаются с нуля. Можно подставить в Embedding слой уже готовые вектора из word2vec/fastext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c346a1a4",
   "metadata": {},
   "source": [
    "Обучаем fastext. Можно обучать на размеченных данных, можно использовать другой более объемный корпус (например, вики, который мы использовали выше), а можно и на том и на другом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "b664e3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 53s, sys: 1.77 s, total: 9min 55s\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ft = gensim.models.FastText(texts + data['norm_text'].values.tolist(), window=10, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e45c8d",
   "metadata": {},
   "source": [
    "Теперь нам нужно сделать матрицу с векторами. Индексы строчек в этой матрице должны совпадать с индексами слов в словаре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "098485ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.zeros((len(word2id), 100))\n",
    "\n",
    "for word, i in word2id.items():\n",
    "    # вектор паддинга оставим нулевым\n",
    "    if word == 'PAD':\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        weights[i] = ft.wv[word]\n",
    "    \n",
    "    \n",
    "    except KeyError:\n",
    "        # для слов, которых нет в модели тоже возьмем какой-то  рандомный вектор\n",
    "        continue\n",
    "        weights[i] = ft.wv['опрагпллирао']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "e703d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(100,))\n",
    "\n",
    "# передаем матрицу в эмбединг слой\n",
    "# указываем параметр trainable=False, чтобы вектора не обучались\n",
    "# Пояснение: кажется, что обучение векторов отключать не стоит, так как модель должна взять готовые \n",
    "# эмбединги и подогнать их к нашей задаче. На практитке это однако не работает - эмбединги просто \n",
    "# обучатся заново\n",
    "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100, \n",
    "                                       trainable=False,\n",
    "                                       weights=[weights])(inputs, )\n",
    "mean = tf.keras.layers.Lambda(lambda x: tf.keras.backend.mean(x,  axis=1))(embeddings)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(mean)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8459b5",
   "metadata": {},
   "source": [
    "Так как слой с эмбедингами не обучается, вся модель обучается сильно быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "0e7f4630",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "428/428 [==============================] - 1s 933us/step - loss: 0.6706 - accuracy: 0.5838 - val_loss: 0.5857 - val_accuracy: 0.6699\n",
      "Epoch 2/30\n",
      "428/428 [==============================] - 0s 742us/step - loss: 0.5922 - accuracy: 0.6755 - val_loss: 0.5588 - val_accuracy: 0.6824\n",
      "Epoch 3/30\n",
      "428/428 [==============================] - 0s 739us/step - loss: 0.5723 - accuracy: 0.6850 - val_loss: 0.5434 - val_accuracy: 0.7087\n",
      "Epoch 4/30\n",
      "428/428 [==============================] - 0s 740us/step - loss: 0.5563 - accuracy: 0.6992 - val_loss: 0.5331 - val_accuracy: 0.7157\n",
      "Epoch 5/30\n",
      "428/428 [==============================] - 0s 744us/step - loss: 0.5492 - accuracy: 0.7092 - val_loss: 0.5249 - val_accuracy: 0.7171\n",
      "Epoch 6/30\n",
      "428/428 [==============================] - 0s 746us/step - loss: 0.5354 - accuracy: 0.7166 - val_loss: 0.5188 - val_accuracy: 0.7309\n",
      "Epoch 7/30\n",
      "428/428 [==============================] - 0s 744us/step - loss: 0.5415 - accuracy: 0.7208 - val_loss: 0.5129 - val_accuracy: 0.7323\n",
      "Epoch 8/30\n",
      "428/428 [==============================] - 0s 739us/step - loss: 0.5169 - accuracy: 0.7344 - val_loss: 0.5091 - val_accuracy: 0.7420\n",
      "Epoch 9/30\n",
      "428/428 [==============================] - 0s 743us/step - loss: 0.5148 - accuracy: 0.7375 - val_loss: 0.5053 - val_accuracy: 0.7351\n",
      "Epoch 10/30\n",
      "428/428 [==============================] - 0s 736us/step - loss: 0.5193 - accuracy: 0.7322 - val_loss: 0.5019 - val_accuracy: 0.7323\n",
      "Epoch 11/30\n",
      "428/428 [==============================] - 0s 736us/step - loss: 0.5099 - accuracy: 0.7433 - val_loss: 0.5001 - val_accuracy: 0.7490\n",
      "Epoch 12/30\n",
      "428/428 [==============================] - 0s 739us/step - loss: 0.5018 - accuracy: 0.7519 - val_loss: 0.4979 - val_accuracy: 0.7476\n",
      "Epoch 13/30\n",
      "428/428 [==============================] - 0s 742us/step - loss: 0.5018 - accuracy: 0.7537 - val_loss: 0.4956 - val_accuracy: 0.7434\n",
      "Epoch 14/30\n",
      "428/428 [==============================] - 0s 742us/step - loss: 0.5107 - accuracy: 0.7483 - val_loss: 0.4928 - val_accuracy: 0.7420\n",
      "Epoch 15/30\n",
      "428/428 [==============================] - 0s 741us/step - loss: 0.4997 - accuracy: 0.7535 - val_loss: 0.4914 - val_accuracy: 0.7434\n",
      "Epoch 16/30\n",
      "428/428 [==============================] - 0s 740us/step - loss: 0.4932 - accuracy: 0.7583 - val_loss: 0.4903 - val_accuracy: 0.7490\n",
      "Epoch 17/30\n",
      "428/428 [==============================] - 0s 803us/step - loss: 0.4958 - accuracy: 0.7617 - val_loss: 0.4908 - val_accuracy: 0.7559\n",
      "Epoch 18/30\n",
      "428/428 [==============================] - 0s 748us/step - loss: 0.4916 - accuracy: 0.7658 - val_loss: 0.4876 - val_accuracy: 0.7490\n",
      "Epoch 19/30\n",
      "428/428 [==============================] - 0s 743us/step - loss: 0.4977 - accuracy: 0.7629 - val_loss: 0.4873 - val_accuracy: 0.7545\n",
      "Epoch 20/30\n",
      "428/428 [==============================] - 0s 787us/step - loss: 0.4919 - accuracy: 0.7644 - val_loss: 0.4855 - val_accuracy: 0.7531\n",
      "Epoch 21/30\n",
      "428/428 [==============================] - 0s 745us/step - loss: 0.4882 - accuracy: 0.7644 - val_loss: 0.4865 - val_accuracy: 0.7545\n",
      "Epoch 22/30\n",
      "428/428 [==============================] - 0s 751us/step - loss: 0.4919 - accuracy: 0.7680 - val_loss: 0.4836 - val_accuracy: 0.7545\n",
      "Epoch 23/30\n",
      "428/428 [==============================] - 0s 744us/step - loss: 0.4889 - accuracy: 0.7668 - val_loss: 0.4821 - val_accuracy: 0.7545\n",
      "Epoch 24/30\n",
      "428/428 [==============================] - 0s 746us/step - loss: 0.4925 - accuracy: 0.7641 - val_loss: 0.4815 - val_accuracy: 0.7545\n",
      "Epoch 25/30\n",
      "428/428 [==============================] - 0s 738us/step - loss: 0.4784 - accuracy: 0.7724 - val_loss: 0.4806 - val_accuracy: 0.7559\n",
      "Epoch 26/30\n",
      "428/428 [==============================] - 0s 759us/step - loss: 0.4913 - accuracy: 0.7625 - val_loss: 0.4800 - val_accuracy: 0.7559\n",
      "Epoch 27/30\n",
      "428/428 [==============================] - 0s 759us/step - loss: 0.4877 - accuracy: 0.7648 - val_loss: 0.4792 - val_accuracy: 0.7559\n",
      "Epoch 28/30\n",
      "428/428 [==============================] - 0s 761us/step - loss: 0.4878 - accuracy: 0.7691 - val_loss: 0.4789 - val_accuracy: 0.7573\n",
      "Epoch 29/30\n",
      "428/428 [==============================] - 0s 744us/step - loss: 0.4840 - accuracy: 0.7698 - val_loss: 0.4800 - val_accuracy: 0.7601\n",
      "Epoch 30/30\n",
      "428/428 [==============================] - 0s 747us/step - loss: 0.4800 - accuracy: 0.7726 - val_loss: 0.4787 - val_accuracy: 0.7587\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1593b9160>"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          batch_size=32,\n",
    "         epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5d9d51",
   "metadata": {},
   "source": [
    "Качество получается хуже, но скорее всего это из-за того, что обучающих данных слишком мало для fastext'а"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "afaaac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(model.history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(model.history.history['accuracy'])\n",
    "plt.plot(model.history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
