{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разбиение текста на предложения (Определение границ предложений)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сегментация предложений - базовая задача в NLP. Даже самые сложные модели пока плохо работают с длинными последовательностями, поэтому если нужно решать что-то сложнее сентимент анализа (например, выделять сущности), то первым делом текст нужно поделить на предложения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "От того, в какой форме у нас текст, зависит сложность задачи. Она может быть либо почти тривиальной, либо крайне сложной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Текст в стандартной форме"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если в тексте есть знаки препинания, соблюдается регистр и мало ошибок -  найти границы предложений для большинства случаев будет достаточно просто. Большинство предложений заканчиваются на точку, вопросительный или восклицательные знаки, после которых идет какой-то отступ и другое слово с заглавной буквы. \n",
    "\n",
    "Да иногда будут попадаться аббревиатуры и сокращения или случаи, когда пробела после точки не стоит, но для задач, где не нужна точность - это не будет сильной проблемой."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, как оно работает на небольшом корпусе новостных текстов. Скачайте его отсюда - https://github.com/mannefedov/ru_kw_eval_datasets/blob/master/data/ng_0.jsonlines.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# у меня данные лежат на уровень выше в папке data\n",
    "files= ['../data/'+file for file in os.listdir('../data')]\n",
    "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)['content'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для примера возьмем совсем немного текстов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждая статья - просто какой-то текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Многие интересуются, зачем нужна «Яблоку» молодежная фракция? Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах. Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.\\nМы ведем борьбу с обязательным воинским призывом. Военный – это профессия, а не обязанность. Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали. По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.\\nТакже на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.\\nРасскажу о московских активистах. Виктору Петрунину – 19 лет, он пришел к нам больше чем '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала давайте просто попробуем разбить предложения простой регуляркой, которая будет делить предложения по **.?!**, последующему пробелу и заглавной букве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '' # напишите регулярку тот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Многие интересуются, зачем нужна «Яблоку» молодежная фракция?',\n",
       " 'Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии. «Молодежное «Яблоко» работает более чем в 10 регионах.',\n",
       " 'Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.',\n",
       " 'Мы ведем борьбу с обязательным воинским призывом.',\n",
       " 'Военный – это профессия, а не обязанность.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(regex, data[0])[:5] # вот так должно работать"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что даже таким простым способом правильно разбивается бОльшая часть текста. Ошибку появляются, когда текст начинается с числа или слова в кавычках. Их, конечно, можно добавить в регулярку, но, скорее всего, это приведет к появлению других ошибок (`руб. 2`). Да и для того, что мы написали несложно придумать контрпример. Поэтому если уж решили усложнять, то нужно подойди к этому более подробно и разобраться с сокращениями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну или не разбираться, а взять уже готовое!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В nltk как раз есть такая штука. Так как в русском и английском знаки препинания по большей части одинаковые - можно смело ей пользоваться прямо из коробки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Многие интересуются, зачем нужна «Яблоку» молодежная фракция?',\n",
       " 'Основной задачей «Молодежного «Яблока» является привлечение молодых людей к участию в выборах и деятельности партии.',\n",
       " '«Молодежное «Яблоко» работает более чем в 10 регионах.',\n",
       " 'Единого руководства у нас нет, но мы стараемся координировать свою деятельность и периодически проводим акции на федеральном уровне.',\n",
       " 'Мы ведем борьбу с обязательным воинским призывом.',\n",
       " 'Военный – это профессия, а не обязанность.',\n",
       " 'Молодые люди вправе сами распоряжаться своей жизнью и не терять целый год, отдавая государству «долг», который они у него не занимали.',\n",
       " 'По мнению одного из ведущих специалистов в области оборонной политики Алексея Арбатова, переход на контрактную армию будет стоить лишь 2% военного бюджета.',\n",
       " 'Также на федеральном уровне «Молодежное «Яблоко» проводило акции за освобождение политзаключенных и против вмешательства России во внутреннюю политику Украины.',\n",
       " 'Расскажу о московских активистах.',\n",
       " 'Виктору Петрунину – 19 лет, он пришел к нам больше чем полтора года назад, когда только переехал в Москву.',\n",
       " 'Вся его семья придерживается демократических взглядов, а Виктора с раннего детства интересовала политика.',\n",
       " 'Виктор всегда очень критически относился к власти, но после Крыма, войны в Украине и убийства Бориса Немцова понял, что не может оставаться в стороне.',\n",
       " 'Заканчивая школу, он решил для себя, что должен присоединиться к близкой ему идеологически силе и добиваться смены власти в России.',\n",
       " '17-летняя Дарья Новичкова рассказывает, что огромное влияние на нее оказал ее преподаватель по обществознанию, который всегда трезво оценивал политическую ситуацию в стране.',\n",
       " 'Его искренность и неподдельная заинтересованность во многих злободневных вопросах помогли Дарье научиться фильтровать материал, который публикуется в различных СМИ.',\n",
       " 'Через некоторое время она поняла, что пассивное наблюдение за всем происходящим – самая невыгодная позиция из всех возможных, а потому необходимо каким-то образом действовать, лучше всего в команде единомышленников.',\n",
       " 'Затем, вдохновившись примером своего ровесника, который рассказал Дарье про «Молодежное «Яблоко», она решила к нам вступить.',\n",
       " 'В московском «Молодежном «Яблоке» действует дискуссионный клуб, в рамках него проходят лекции и кинопоказы на самые разные темы – от наступления консерватизма, обсуждения социально-либеральной альтернативы до ситуации в российской экономике.',\n",
       " 'Недавно один из участников круглого стола сказал нам, что никогда не присутствовал на мероприятиях, где имеет место столь открытая дискуссия, в которой может принять участие любой гость.',\n",
       " 'Петербургское «Молодежное «Яблоко» серьезно работает по городской повестке.',\n",
       " 'А в ноябре прошлого года они отправились в Карелию, чтобы провести акцию за свободу Ильдара Дадина рядом с колонией, где он тогда содержался, за что были задержаны, а судебный процесс по административному правонарушению, в котором обвинили активистов, до сих пор не завершился.',\n",
       " 'Ставропольцы недавно провели акции против декриминализации домашнего насилия, фотографии которой облетели Интернет.',\n",
       " '8 марта они организовали театрализованную акцию, чтобы напомнить, что этот «праздник» изначально появился как день борьбы за права женщин, но сегодня в России это пародия на его истинный смысл – женщин поздравляют с тем, что они «украшение» и «слабый пол».',\n",
       " 'Североосетинское отделение выступает против деятельности завода «Электроцинк», который наносит тяжелый ущерб окружающей среде.',\n",
       " 'Мы участвуем и в общепартийных мероприятиях, становимся кандидатами на выборах различного уровня.',\n",
       " 'В 2018 году наши активисты намерены участвовать в главной предвыборной кампании страны – выборах президента.',\n",
       " 'У «Яблока» есть свой кандидат – основатель партии Григорий Явлинский.',\n",
       " 'Его последовательность и неготовность разменивать принципы на проценты заслуживают уважения и поддержки.',\n",
       " 'Есть и проблемы.']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x) for x in sent_tokenize(data[0])[:30]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ни одной ошибки!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если уточнить разбиения все-таки нужно, есть способ обучить токенизатор на имеющихся текстах или даже добавить туда спорные случаи вручную.\n",
    "\n",
    "Про то как алгоритм обучается можно почитать тут  - http://www.aclweb.org/anthology/J06-4003  \n",
    "В двух словах: считаются частотные аббревиатуры, которые потом не используются как разделители.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "trainer.train('\\n'.join(data))\n",
    " \n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Список выученных сокращений можно достать вот так:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'долл', 'т.д', 'ю.н', 'см', 's', 'с.г', 'аэс', 'д', 'г', 'б', 'кв', 'пер', 'н.а', 'пл', 'др', 'куб', 'тыс', 'руб', 'стр', 'я»', 'м»', 'н.к'}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer._params.abbrev_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удобнее просматривать окончания можно отрезать все до последних 10 символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['е (Техас).',\n",
       " 'оехали 15.',\n",
       " 'ить заезд.',\n",
       " ' Росберга.',\n",
       " 'Риккъярдо.',\n",
       " 'е удалась.',\n",
       " 'це заезда.',\n",
       " ' досрочно.',\n",
       " ' Marussia.',\n",
       " ' Абу-Даби.',\n",
       " 'авершению.',\n",
       " 'ио Переса.',\n",
       " 'айкконена.',\n",
       " 'до боксов.',\n",
       " 'щей гонки.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x)[-10:] for x in tokenizer.tokenize(data[5])[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и в него же напрямую можно что-то добавить (без учета регистра и без точки на конце)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# можно сразу добавить все числа и сокращения имен и отчеств\n",
    "tokenizer._params.abbrev_types.add('15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['е (Техас).',\n",
       " 'ить заезд.',\n",
       " ' Росберга.',\n",
       " 'Риккъярдо.',\n",
       " 'е удалась.',\n",
       " 'це заезда.',\n",
       " ' досрочно.',\n",
       " ' Marussia.',\n",
       " ' Абу-Даби.',\n",
       " 'авершению.',\n",
       " 'ио Переса.',\n",
       " 'айкконена.',\n",
       " 'до боксов.',\n",
       " 'щей гонки.',\n",
       " 'кий сход).']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[re.sub('[\\n\\t]', ' ', x)[-10:] for x in tokenizer.tokenize(data[5])[:15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После нескольких итераций ручной подкрутки может возникнуть желание более точно измерить качество разбиений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как это можно измерить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно взять какой-то текст и разбить его руками. А потом разбить этот ж текст моделью и сравнить длины полученных списков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = tokenizer.tokenize(data[3]) # руками мы разбивать конечно не будем, а просто проверим, что все правильно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['В Ленинском районном суде продолжаются слушания по делу экс-депутата Думы Владивостока Зинаиды Ким и бывшего председателя избирательного участка № 522 Елены Футиной, которых обвиняют в сговоре и фальсификациях результатов на выборах на сентябрьских выборах 2016 года.',\n",
       " 'Напомним, 18 сентября 2017 года местные журналисты сняли на видео, как Ким, будучи кандидатом по спискам в Законодательное Собрание Приморского края, выдавала молодым людям открепительные, возила их голосовать на участок, где уже знали о предстоящем визите.',\n",
       " 'В качестве вознаграждения избирателям предлагалось по 500 рублей.',\n",
       " 'Перед началом судебного процесса Зинаида Ким разговаривала с журналистами на повышенных тонах и обзывая, доказывала, что видео – монтаж.',\n",
       " 'Адвокаты представили вниманию участников процесса характеристику подсудимой, составленную руководителями Всероссийской общественной организации «Боевое братство (Приморье)», членом которого является подсудимая.',\n",
       " 'Выяснилось, что у Зинаиды Ким – богатый наградной список: есть, например, памятные знаки к 65 – и 70-летию Победы в Великой Отечественной войне, к 25-летию вывода советских войск из Афганистана, 20-летию МЧС и многие другие.',\n",
       " 'В ходе заседания адвокат Алексей Клецкин попросил судью назначить дополнительную комплексную экспертизу видео – и аудиозаписей, представленных в процессе в качестве основных доказательств вины Ким и Футиной, хотя прежде защитники не высказывали сомнений в подлинности экспертизы.',\n",
       " 'Государственный обвинитель прошение защитников назвал необоснованным, судья поддержал позицию представителя прокуратуры.',\n",
       " 'На предшествующих судебных заседаниях по делу Зинаиды Ким и Елены Футиной были допрошены свидетели – бывший главный редактор издания VL.RU Иван Федотов, бывший журналист Маргарита Бабченко.',\n",
       " 'Зинаида Ким заявила в суде, что журналист, выявивший противоправные действия, предлагал ей закрыть дело за вознаграждение в 500 000 рублей.',\n",
       " 'Иван Федотов объяснил ситуацию: он отправил на разговор вместо себя своего коллегу.',\n",
       " 'То, что она встречалась с другим сотрудником редакции, Зинаида Ким поняла только на судебном заседании.',\n",
       " 'Свидетель, внештатный видеограф информационного агентства Даниила Губарев, рассказал суду о работе на сайте, о своих профессиональных обязанностям.',\n",
       " 'Он подтвердил, что никаких манипуляций с видео на мобильном телефоне он не проводил.',\n",
       " 'На компьютере, из отснятых корреспондентами материалов, он смонтировал ролик: весь монтаж заключался в склейке фрагментов и наложении субтитров.',\n",
       " 'По словам свидетеля, в итоговом видео убрали только «грязные» кадры – то есть те, на которых ничего не происходит.',\n",
       " 'На экспертизу видеодоказательств и другие следственные процедуры понадобилось почти девять месяцев и пять депутатских запросов в СУ СК по Приморью.',\n",
       " 'За фальсификацию избирательных документов или документов референдума Ким грозит штраф в размере от 100 тыс. до 300 тыс. рублей или в размере заработной платы, или иного дохода за период до двух лет, либо принудительные работы на срок до четырех лет, либо лишение свободы на тот же срок.',\n",
       " 'Владивосток']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_split = sent_tokenize(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold length -  19\n",
      "My split -  21\n"
     ]
    }
   ],
   "source": [
    "print('Gold length - ', len(gold))\n",
    "print('My split - ', len(my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятно, что это не очень хороший способ (его можно обмануть), но что-то он покажет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также можно привести списки к множествам и посчитать пересечения - одинаковые предложения будут считать совпадающими элементами.\n",
    "\n",
    "Тут нужно быть аккуратным, так как модель может отрезать один лишний символ и это уже будет считаться промахом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8181818181818182"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# добавим нормировку на длину объединения\n",
    "len(set(gold) & set(my_split)) / len(set(gold) | set(my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть ещё такая метрика - берем идеальное предложение и пробуем разбить его нашей моделью - если  разбивается, считает этой ошибкой, если нет - правильным ответом. \n",
    "Потом берем два идеальных предложения - склеиваем их пробельным символом и пробуем разбить нашей моделью. Если разбивает на два нужных предложения - все правильно.\n",
    "\n",
    "Таким образом мы вычисляем tp fp fn для расчета точности, полноты и f1 меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision -  0.9714285714285714\n",
      "Recall -  0.9444444444444444\n",
      "F1 -  0.9577464788732395\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for sent in gold:\n",
    "    if len(sent_tokenize(sent)) == 1:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "for i in range(len(gold)-1):\n",
    "    sent1, sent2 = gold[i], gold[i+1]\n",
    "    sent = ' '.join([sent1, sent2])\n",
    "    if len(sent_tokenize(sent)) == 2:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "precision = (tp/(tp+fp))\n",
    "recall = (tp/(tp+fn))\n",
    "f1 = 2*(precision*recall)/(precision+recall)\n",
    "print('Precision - ', precision)\n",
    "print('Recall - ', recall)\n",
    "print('F1 - ', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такую метрики использовали авторы вот этого токенизатора для русского - https://github.com/deepmipt/ru_sentence_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно придумать и что-то посложнее. \n",
    "\n",
    "Перейдем к индексам символов в тексте. Теперь нам нужно для каждого символа предсказать является ли он разбивающим или нет. Потом можно применять стандартные метрики качества классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 267),\n",
       " (268, 525),\n",
       " (526, 591),\n",
       " (592, 728),\n",
       " (729, 939),\n",
       " (940, 1164),\n",
       " (1166, 1445),\n",
       " (1446, 1566),\n",
       " (1568, 1757),\n",
       " (1758, 1897),\n",
       " (1898, 1981),\n",
       " (1982, 2085),\n",
       " (2086, 2233),\n",
       " (2234, 2318),\n",
       " (2319, 2463),\n",
       " (2464, 2578),\n",
       " (2579, 2726),\n",
       " (2727, 3013),\n",
       " (3015, 3026)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.span_tokenize(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = [0 for i in range(len(data[3]))]\n",
    "for span in tokenizer.span_tokenize(data[3]):\n",
    "    gold[span[1]-1] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tokenize(data[3])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_split = [0 for i in range(len(data[3]))]\n",
    "index = 0\n",
    "for sent in sent_tokenize(data[3]):\n",
    "    index += len(sent)\n",
    "    my_split[index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3007\n",
      "           1       0.05      0.05      0.05        19\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      3026\n",
      "   macro avg       0.52      0.52      0.52      3026\n",
      "weighted avg       0.99      0.99      0.99      3026\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(gold, my_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ещё можно выписать индексы всех разбивающих символов и рассматривать это как строку. Между двумя строками (идеальной и той, что выдала модель) можно посчитать edit distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval([1,2,3], [1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold = []\n",
    "my_split = []\n",
    "for span in tokenizer.span_tokenize(data[3]):\n",
    "    gold.append(span[1])\n",
    "\n",
    "index = 0\n",
    "for sent in sent_tokenize(data[3]):\n",
    "    index += len(sent)\n",
    "    my_split.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editdistance.eval(gold, my_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот тут можно почитать про другие метрики (и их сравнение) - http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.417.8097&rep=rep1&type=pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Нестандартный текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бывает, что текст приходит откуда-то ещё (например, с speech2text модуля) сплошняком без каких-либо знаков препинания и регистров. Либо в нём столько неточностей, что стандартные методы ошибаются на каждом втором слове (например, при переводе пдфа в текст)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом случае нужно как-то учитывать смысл написанного. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для этого хорошо подойдут рекурентные нейронные сети. \n",
    "\n",
    "Обучающую выборку (если её нет) можно попробовать собрать из обычных текстов, разделенных вручную или автоматически, убрав всю пунктуацию и приведя их к нижнему регистру. Ну или сделать то же самое с предложениями из какого-нибудь синтагруса.\n",
    "\n",
    "Саму задачу можно рассматривать как задачу классификации. К целым предложениям можно приписать положительный класс (т.е. после последнего слова нужно поставить разделитель), а для подбора отрицательного класса, можно нарезать предложения на части и каждой из них приписать отрицательный класс (т.е. разделителя не нужно). \n",
    "\n",
    "Например, предложение \"вчера кажется бы снег\" преборазуется в:\n",
    "\n",
    "\"вчера кажется был снег\" - 1\n",
    "\"вчера кажется был\" - 0\n",
    "\"кажется был\" - 0\n",
    "\"вчера кажется\" - 0\n",
    "\n",
    "Вообще можно и положительный класс пополнить таким методом (выбрость первое слово, например), но лучше этого не делать. Потому что предложения бывают разные и не всегда можно что-то обросить без потери смысла. В нулевой класс тоже по идее могут попасть нормальные предложения (был снег, например). Но можно предположить, что такое будет случаться не часто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте попробуем на небольшом количестве предложений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Если вы ещё ничего не знаете про нейронные сети или знаете очень мало, не пугайтесь.** Попробуйте запустить мой код и посмотреть, что он делает. Попробуйте что-то поменять и посмотреть что изменится. Ну и потом уже можете пойти почитать про то, как оно устроено. Такой top-down (от практики к теории) используют в fast.ai для обучения нейронным сетям и это работает!  \n",
    "  https://www.fast.ai/2016/10/08/teaching-philosophy/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Главное, что нужно знать про рекуррентные нейронные сети (LSTM в нашем случае) - то, что они работают с последовательностью. На каждом шаге учитывается накопленная информация с предыдущих шагов и текущий шаг. На последнем шаге получается сжатое представление всей последовательности, по которому уже и делается предсказание. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если у вас нет нужных библиотек (keras) - установите их через pip. Если они не устанавливаются - попробуйте открыть тетрадку в Colab (там все установлено сразу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from keras.layers import LSTM, Embedding, Dense, Dropout\n",
    "from keras import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "punct=punctuation+'«…»'\n",
    "def normalize(text):\n",
    "    tokens = [word.strip(punct) for word in text.lower().split()]\n",
    "    tokens = [word for word in tokens if word]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['в',\n",
       " 'ленинском',\n",
       " 'районном',\n",
       " 'суде',\n",
       " 'продолжаются',\n",
       " 'слушания',\n",
       " 'по',\n",
       " 'делу',\n",
       " 'экс-депутата',\n",
       " 'думы']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalize(tokenizer.tokenize(data[3])[0])[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь возьмем все данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "files= ['../data/'+file for file in os.listdir('../data')]\n",
    "data = pd.concat([pd.read_json(file, lines=True) for file in files], axis=0, ignore_index=True)['content'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_sents = []\n",
    "for text in data:\n",
    "    sents = [normalize(sent) for sent in tokenizer.tokenize(text)]\n",
    "    for sent in sents:\n",
    "        if sent:\n",
    "            good_sents.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['многие',\n",
       "  'интересуются',\n",
       "  'зачем',\n",
       "  'нужна',\n",
       "  'яблоку',\n",
       "  'молодежная',\n",
       "  'фракция'],\n",
       " ['основной',\n",
       "  'задачей',\n",
       "  'молодежного',\n",
       "  'яблока',\n",
       "  'является',\n",
       "  'привлечение',\n",
       "  'молодых',\n",
       "  'людей',\n",
       "  'к',\n",
       "  'участию',\n",
       "  'в',\n",
       "  'выборах',\n",
       "  'и',\n",
       "  'деятельности',\n",
       "  'партии'],\n",
       " ['молодежное', 'яблоко', 'работает', 'более', 'чем', 'в', '10', 'регионах']]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sents[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sents = []\n",
    "for sent in good_sents:\n",
    "    not_lust = sent[:-1]\n",
    "    while len(not_lust) >= 1:\n",
    "        bad_sents.append(not_lust)\n",
    "        not_lust = not_lust[:-1]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что нарезалось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['многие', 'интересуются', 'зачем', 'нужна', 'яблоку', 'молодежная']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_sents[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['многие', 'интересуются', 'зачем', 'нужна', 'яблоку', 'молодежная'],\n",
       " ['многие', 'интересуются', 'зачем', 'нужна', 'яблоку'],\n",
       " ['многие', 'интересуются', 'зачем', 'нужна'],\n",
       " ['многие', 'интересуются', 'зачем']]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_sents[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь нам нужно сделать словарик и заменить слово на его индекс."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = good_sents + bad_sents\n",
    "target = [1 for i in range(len(good_sents))] + [0 for i in range(len(bad_sents))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for sent in sents:\n",
    "    vocab.update(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115476"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([x for x in vocab if vocab[x] > 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = {i+2:word for i, word in enumerate(vocab) if vocab[word] > 5}\n",
    "word2id = {word:i for i, word in id2word.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_ids = []\n",
    "\n",
    "for sent in sents:\n",
    "    sents_ids.append([word2id.get(word, 1) for word in sent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[92853, 11199, 48169, 136277, 95231, 76645, 125552],\n",
       " [49529,\n",
       "  3675,\n",
       "  123150,\n",
       "  129445,\n",
       "  64529,\n",
       "  93068,\n",
       "  99540,\n",
       "  92004,\n",
       "  104435,\n",
       "  78303,\n",
       "  66847,\n",
       "  126384,\n",
       "  47361,\n",
       "  44636,\n",
       "  135546],\n",
       " [6110, 136226, 116112, 17094, 79225, 66847, 100479, 125782]]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_ids[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последовательности должны быть одной длины. Стандартный подход - найти максимальную длину и дотянуть все другие предложения до этой длины, подставив, где нужно нули (это называется паддинг)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Но чтобы уменьшить модель можно взять среднюю длинну и обрезать все, что длиннее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.098569722474977"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([len(s) for s in sents_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pad_sequences(sents_ids, 20, truncating='pre') # возьмем 20, чтобы покрытыть побольше случаев"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы готовы обучаться!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(vocab)+2, output_dim=32, input_length=maxlen))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1266048 samples, validate on 422016 samples\n",
      "Epoch 1/10\n",
      "1266048/1266048 [==============================] - 282s 223us/step - loss: 0.1691 - acc: 0.9423 - val_loss: 0.1536 - val_acc: 0.9441\n",
      "Epoch 2/10\n",
      "1266048/1266048 [==============================] - 283s 223us/step - loss: 0.1326 - acc: 0.9491 - val_loss: 0.1486 - val_acc: 0.9448\n",
      "Epoch 3/10\n",
      "1266048/1266048 [==============================] - 302s 238us/step - loss: 0.1123 - acc: 0.9572 - val_loss: 0.1475 - val_acc: 0.9466\n",
      "Epoch 4/10\n",
      "1266048/1266048 [==============================] - 291s 230us/step - loss: 0.0978 - acc: 0.9632 - val_loss: 0.1501 - val_acc: 0.9470\n",
      "Epoch 5/10\n",
      "1266048/1266048 [==============================] - 289s 228us/step - loss: 0.0873 - acc: 0.9675 - val_loss: 0.1512 - val_acc: 0.9468\n",
      "Epoch 6/10\n",
      "1266048/1266048 [==============================] - 287s 227us/step - loss: 0.0793 - acc: 0.9706 - val_loss: 0.1589 - val_acc: 0.9476\n",
      "Epoch 7/10\n",
      "1266048/1266048 [==============================] - 289s 228us/step - loss: 0.0729 - acc: 0.9733 - val_loss: 0.1572 - val_acc: 0.9477\n",
      "Epoch 8/10\n",
      "1266048/1266048 [==============================] - 290s 229us/step - loss: 0.0679 - acc: 0.9753 - val_loss: 0.1675 - val_acc: 0.9492\n",
      "Epoch 9/10\n",
      "1265920/1266048 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9769"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-993ad90d3d54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train, y_train, batch_size=128, epochs=10,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=[X_valid, y_valid])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    210\u001b[0m                         val_outs = test_loop(model, val_f, val_ins,\n\u001b[1;32m    211\u001b[0m                                              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m                                              verbose=0)\n\u001b[0m\u001b[1;32m    213\u001b[0m                         \u001b[0mval_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m                         \u001b[0;31m# Same labels assumed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mtest_loop\u001b[0;34m(model, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m    390\u001b[0m                 \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=10,\n",
    "          validation_data=[X_valid, y_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь попробуем сделать предсказание этой моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "gold = tokenizer.tokenize(data[3])\n",
    "for sent in gold:\n",
    "    sample += normalize(sent)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = []\n",
    "sents = []\n",
    "for word in sample:\n",
    "#     if word not in word2id:\n",
    "#         continue\n",
    "    stack.append(word)\n",
    "    vec = [word2id.get(w, 1) for w in stack]\n",
    "    vec = pad_sequences([vec], maxlen)\n",
    "    pred = model.predict(vec)\n",
    "    if pred[0][0] > 0.6:\n",
    "        sents.append(stack)\n",
    "        stack = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['в',\n",
       "  'ленинском',\n",
       "  'районном',\n",
       "  'суде',\n",
       "  'продолжаются',\n",
       "  'слушания',\n",
       "  'по',\n",
       "  'делу',\n",
       "  'экс-депутата',\n",
       "  'думы',\n",
       "  'владивостока',\n",
       "  'зинаиды',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'бывшего',\n",
       "  'председателя',\n",
       "  'избирательного',\n",
       "  'участка',\n",
       "  '№',\n",
       "  '522',\n",
       "  'елены',\n",
       "  'футиной',\n",
       "  'которых',\n",
       "  'обвиняют',\n",
       "  'в',\n",
       "  'сговоре',\n",
       "  'и',\n",
       "  'фальсификациях',\n",
       "  'результатов',\n",
       "  'на',\n",
       "  'выборах',\n",
       "  'на',\n",
       "  'сентябрьских',\n",
       "  'выборах',\n",
       "  '2016',\n",
       "  'года',\n",
       "  'напомним',\n",
       "  '18',\n",
       "  'сентября',\n",
       "  '2017',\n",
       "  'года'],\n",
       " ['местные',\n",
       "  'журналисты',\n",
       "  'сняли',\n",
       "  'на',\n",
       "  'видео',\n",
       "  'как',\n",
       "  'ким',\n",
       "  'будучи',\n",
       "  'кандидатом',\n",
       "  'по',\n",
       "  'спискам',\n",
       "  'в',\n",
       "  'законодательное',\n",
       "  'собрание',\n",
       "  'приморского',\n",
       "  'края',\n",
       "  'выдавала',\n",
       "  'молодым',\n",
       "  'людям',\n",
       "  'открепительные',\n",
       "  'возила',\n",
       "  'их',\n",
       "  'голосовать',\n",
       "  'на',\n",
       "  'участок',\n",
       "  'где',\n",
       "  'уже',\n",
       "  'знали',\n",
       "  'о',\n",
       "  'предстоящем'],\n",
       " ['визите',\n",
       "  'в',\n",
       "  'качестве',\n",
       "  'вознаграждения',\n",
       "  'избирателям',\n",
       "  'предлагалось',\n",
       "  'по',\n",
       "  '500',\n",
       "  'рублей'],\n",
       " ['перед',\n",
       "  'началом',\n",
       "  'судебного',\n",
       "  'процесса',\n",
       "  'зинаида',\n",
       "  'ким',\n",
       "  'разговаривала',\n",
       "  'с',\n",
       "  'журналистами',\n",
       "  'на',\n",
       "  'повышенных',\n",
       "  'тонах',\n",
       "  'и',\n",
       "  'обзывая',\n",
       "  'доказывала',\n",
       "  'что',\n",
       "  'видео',\n",
       "  '–',\n",
       "  'монтаж',\n",
       "  'адвокаты'],\n",
       " ['представили',\n",
       "  'вниманию',\n",
       "  'участников',\n",
       "  'процесса',\n",
       "  'характеристику',\n",
       "  'подсудимой',\n",
       "  'составленную',\n",
       "  'руководителями',\n",
       "  'всероссийской',\n",
       "  'общественной',\n",
       "  'организации',\n",
       "  'боевое',\n",
       "  'братство',\n",
       "  'приморье',\n",
       "  'членом',\n",
       "  'которого',\n",
       "  'является',\n",
       "  'подсудимая',\n",
       "  'выяснилось',\n",
       "  'что',\n",
       "  'у',\n",
       "  'зинаиды'],\n",
       " ['ким',\n",
       "  '–',\n",
       "  'богатый',\n",
       "  'наградной',\n",
       "  'список',\n",
       "  'есть',\n",
       "  'например',\n",
       "  'памятные',\n",
       "  'знаки',\n",
       "  'к',\n",
       "  '65',\n",
       "  '–',\n",
       "  'и',\n",
       "  '70-летию',\n",
       "  'победы',\n",
       "  'в',\n",
       "  'великой',\n",
       "  'отечественной',\n",
       "  'войне',\n",
       "  'к',\n",
       "  '25-летию',\n",
       "  'вывода',\n",
       "  'советских',\n",
       "  'войск',\n",
       "  'из',\n",
       "  'афганистана',\n",
       "  '20-летию',\n",
       "  'мчс',\n",
       "  'и',\n",
       "  'многие',\n",
       "  'другие'],\n",
       " ['в',\n",
       "  'ходе',\n",
       "  'заседания',\n",
       "  'адвокат',\n",
       "  'алексей',\n",
       "  'клецкин',\n",
       "  'попросил',\n",
       "  'судью',\n",
       "  'назначить',\n",
       "  'дополнительную',\n",
       "  'комплексную',\n",
       "  'экспертизу',\n",
       "  'видео',\n",
       "  '–',\n",
       "  'и',\n",
       "  'аудиозаписей',\n",
       "  'представленных',\n",
       "  'в',\n",
       "  'процессе',\n",
       "  'в',\n",
       "  'качестве',\n",
       "  'основных',\n",
       "  'доказательств',\n",
       "  'вины',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'футиной',\n",
       "  'хотя',\n",
       "  'прежде',\n",
       "  'защитники',\n",
       "  'не',\n",
       "  'высказывали',\n",
       "  'сомнений',\n",
       "  'в',\n",
       "  'подлинности',\n",
       "  'экспертизы',\n",
       "  'государственный',\n",
       "  'обвинитель',\n",
       "  'прошение',\n",
       "  'защитников',\n",
       "  'назвал',\n",
       "  'необоснованным',\n",
       "  'судья',\n",
       "  'поддержал',\n",
       "  'позицию',\n",
       "  'представителя',\n",
       "  'прокуратуры'],\n",
       " ['на',\n",
       "  'предшествующих',\n",
       "  'судебных',\n",
       "  'заседаниях',\n",
       "  'по',\n",
       "  'делу',\n",
       "  'зинаиды',\n",
       "  'ким',\n",
       "  'и',\n",
       "  'елены',\n",
       "  'футиной',\n",
       "  'были',\n",
       "  'допрошены',\n",
       "  'свидетели',\n",
       "  '–',\n",
       "  'бывший',\n",
       "  'главный',\n",
       "  'редактор',\n",
       "  'издания',\n",
       "  'vl.ru',\n",
       "  'иван',\n",
       "  'федотов',\n",
       "  'бывший',\n",
       "  'журналист',\n",
       "  'маргарита',\n",
       "  'бабченко'],\n",
       " ['зинаида',\n",
       "  'ким',\n",
       "  'заявила',\n",
       "  'в',\n",
       "  'суде',\n",
       "  'что',\n",
       "  'журналист',\n",
       "  'выявивший',\n",
       "  'противоправные'],\n",
       " ['действия',\n",
       "  'предлагал',\n",
       "  'ей',\n",
       "  'закрыть',\n",
       "  'дело',\n",
       "  'за',\n",
       "  'вознаграждение',\n",
       "  'в',\n",
       "  '500',\n",
       "  '000',\n",
       "  'рублей',\n",
       "  'иван',\n",
       "  'федотов',\n",
       "  'объяснил',\n",
       "  'ситуацию',\n",
       "  'он',\n",
       "  'отправил',\n",
       "  'на',\n",
       "  'разговор',\n",
       "  'вместо',\n",
       "  'себя',\n",
       "  'своего',\n",
       "  'коллегу']]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается так себе. Видно, что модель переобучается (ошибка на трейне уменьшается, а на валидации нет), то есть просто выучивает трейн, но очень плохо обобщает. Возможно, стоит попробовать добавить побольше данных или нарезать их получше."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
