{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13efba76",
   "metadata": {},
   "source": [
    "# Дисклеймер\n",
    "Эту тетрадку нужно запускать в колабе или в vast.ai. Не мучатесь с установкой библиотек и с обучением на cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d650e9eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.4.2-cp38-cp38-manylinux1_x86_64.whl (10.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.3 MB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (1.19.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp38-cp38-manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 16.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (2.8.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib) (8.1.2)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.9 MB 17.2 MB/s eta 0:00:01     |█████████████████▌              | 13.6 MB 17.2 MB/s eta 0:00:01     |█████████████████████████       | 19.5 MB 17.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 27.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.3-cp38-cp38-manylinux1_x86_64.whl (27.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.2 MB 14.2 MB/s eta 0:00:01    |██▋                             | 2.3 MB 14.2 MB/s eta 0:00:02\n",
      "\u001b[?25hBuilding wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1316 sha256=d2b555d82c2734c6d1df69cc21d9e6d6fc536547b7a5e92e6e9a4a67a77422fd\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "Successfully built sklearn\n",
      "Installing collected packages: tokenizers, kiwisolver, cycler, matplotlib, joblib, threadpoolctl, scipy, scikit-learn, sklearn\n",
      "Successfully installed cycler-0.10.0 joblib-1.0.1 kiwisolver-1.3.1 matplotlib-3.4.2 scikit-learn-0.24.2 scipy-1.6.3 sklearn-0.0 threadpoolctl-2.1.0 tokenizers-0.10.3\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers matplotlib sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac85a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в vast ai или в последних версия jupyter может не работать автозаполнение, установка этой либы и перезагрука кернела помогает\n",
    "# !pip install --upgrade jedi==0.17.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e384bd5c",
   "metadata": {},
   "source": [
    "# Транформеры для решения seq2seq задач"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69baacc",
   "metadata": {},
   "source": [
    "Seq2seq - наверное самая общая формальная постановка задачи в NLP. Нужно из произвольной последовательности получить какую-то другую последовательность. И в отличие от разметки последовательности (sequence labelling) не требуется, чтобы обе последовательности совпадали по длине. Даже стандартную задачу классификации можно решать как seq2seq - можно рассматривать метку класса как последовательность длинны 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2a0525",
   "metadata": {},
   "source": [
    "А трансформеры - sota архитектура для seq2seq задач. Мы не будем подробно разбирать устройство транформеров, если вам интересно вы можете поразбираться вот с этими материалами:\n",
    "\n",
    "Оригинальная статья (сложновато) - https://arxiv.org/pdf/1706.03762.pdf\n",
    "\n",
    "https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/  \n",
    "https://jalammar.github.io/illustrated-transformer/\n",
    "\n",
    "https://www.youtube.com/watch?v=iDulhoQ2pro\n",
    "\n",
    "https://www.youtube.com/watch?v=TQQlZhbC5ps\n",
    "\n",
    "Самый известный туториал (на торче) - https://nlp.seas.harvard.edu/2018/04/03/attention.html\n",
    "\n",
    "\n",
    "\n",
    "Трансформеры будут подробно разбираться на курсе глубокого обучения (по выбору) на втором курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c794a6",
   "metadata": {},
   "source": [
    "Пока просто попробуем обучать модель на задаче машинного перевода. Для таких задач лучше всего использовать предобученные модели, но если у вас будет какая-то специфичная seq2seq задача, то имеет смысл попробовать обучить трансформер с нуля и в этой тертрадке вам нужно будет поменять только часть с загрузкой данных. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "947b3313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "415f5ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# в русскоязычных данных есть \\xa0 вместо пробелов, он может некорректно обрабатываться токенизатором\n",
    "# text = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ')\n",
    "# text = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ')\n",
    "# f = open('opus.en-ru-train.ru.txt', 'w')\n",
    "# f.write(text)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018d83aa",
   "metadata": {},
   "source": [
    "Данные взяты вот отсюда - https://opus.nlpl.eu/opus-100.php (раздел с отдельными языковыми парами)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e110ff04",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sents = open('opus.en-ru-train.en.txt').read().splitlines()\n",
    "ru_sents = open('opus.en-ru-train.ru.txt').read().replace('\\xa0', ' ').splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c009c96e",
   "metadata": {},
   "source": [
    "Пример перевода с английского на русский"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0eb9b498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('So what are you thinking?', 'Ну и что ты думаешь?')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_sents[-1], ru_sents[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39921c4",
   "metadata": {},
   "source": [
    "Как обычно нам нужен токенизатор, а точнее даже 2, т.к. у нас два корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4b79b4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer(BPE())\n",
    "tokenizer_en.pre_tokenizer = Whitespace()\n",
    "trainer_en = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_en.train(files=[\"opus.en-ru-train.en.txt\"], trainer=trainer_en)\n",
    "\n",
    "tokenizer_ru = Tokenizer(BPE())\n",
    "tokenizer_ru.pre_tokenizer = Whitespace()\n",
    "trainer_ru = BpeTrainer(special_tokens=[\"[UNK]\", \"[CLS]\", \"[SEP]\", \"[PAD]\", \"[MASK]\"])\n",
    "tokenizer_ru.train(files=[\"opus.en-ru-train.ru.txt\"], trainer=trainer_ru)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48780b24",
   "metadata": {},
   "source": [
    "### ВАЖНО!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b56d3b",
   "metadata": {},
   "source": [
    "Токенизатор - это неотъемлимая часть модели, поэтому не забывайте сохранять токенизатор вместе с моделью. Если вы забудете про это и переобучите токенизатор, то индексы токенов разойдутся и веса модели будут бесполезны. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd90665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# раскоментируйте эту ячейку при обучении токенизатора\n",
    "# а потом снова закоментируйте чтобы при перезапуске не перезаписать токенизаторы\n",
    "# tokenizer_en.save('tokenizer_en')\n",
    "# tokenizer_ru.save('tokenizer_ru')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0e0f7f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
    "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9fecf3",
   "metadata": {},
   "source": [
    "Переводим текст в индексы вот таким образом. В начало добавляем токен '[CLS]', а в конец '[SEP]'. Если вспомните занятие по языковому моделированию, то там мы добавляли \"\\<start>\" и \"\\<end>\" - cls и sep по сути тоже самое. Вы поймете почему именно cls и sep, а не start и end, если подробнее поразбираетесь с устройством трансформеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dc003758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, max_len):\n",
    "    return [tokenizer.token_to_id('[CLS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[SEP]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96920fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n",
    "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5cc0a376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ограничимся длинной в 30 и 35 (разные чтобы показать что в seq2seq не нужна одинаковая длина)\n",
    "max_len_en, max_len_ru = 30, 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7fc2dae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
    "X_ru = [encode(t, tokenizer_ru, max_len_ru) for t in ru_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0560e01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# миллион примеров \n",
    "X_en.shape, X_ru.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68091524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7655a4ea",
   "metadata": {},
   "source": [
    "Паддинг внутри класса для датасета. Еще обратите внимание, что тут не стоит параметр batch_first=True как раньше\n",
    "\n",
    "В торче принято, что размерность батча идет в конце и пример кода с трансформером расчитан на это. Конечно можно поменять сам код модели, но это сложнее, чем просто изменить тензор с данными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7634853b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, texts_en, texts_ru):\n",
    "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
    "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, padding_value=PAD_IDX)\n",
    "        \n",
    "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
    "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, padding_value=PAD_IDX)\n",
    "\n",
    "        self.length = len(texts_en)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ids_en = self.texts_en[:, index]\n",
    "        ids_ru = self.texts_ru[:, index]\n",
    "\n",
    "        return ids_en, ids_ru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec889a8d",
   "metadata": {},
   "source": [
    "Разбиваем на трейн и тест"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9c9eaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(X_en, X_ru, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f0fcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(X_en_train, X_ru_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=200, shuffle=True, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d0980a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_set = Dataset(X_en_valid, X_ru_valid)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=200, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bb0e70",
   "metadata": {},
   "source": [
    "# Код трансформера"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a83a16",
   "metadata": {},
   "source": [
    "Дальше код модели, он взят вот отсюда (с небольшими изменениями) - https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "\n",
    "Там есть комментарии по каждому этапу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "078605bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import Tensor\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self,\n",
    "                 emb_size: int,\n",
    "                 dropout: float,\n",
    "                 maxlen: int = 150):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer('pos_embedding', pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
    "\n",
    "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "\n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
    "\n",
    "# Seq2Seq Network\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 num_encoder_layers: int,\n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int,\n",
    "                 nhead: int,\n",
    "                 src_vocab_size: int,\n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward: int = 512,\n",
    "                 dropout: float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        self.transformer = Transformer(d_model=emb_size, \n",
    "                                       nhead=nhead,\n",
    "                                       num_encoder_layers=num_encoder_layers,\n",
    "                                       num_decoder_layers=num_decoder_layers,\n",
    "                                       dim_feedforward=dim_feedforward,\n",
    "                                       dropout=dropout)\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            emb_size, dropout=dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                src: Tensor,\n",
    "                trg: Tensor,\n",
    "                src_mask: Tensor,\n",
    "                tgt_mask: Tensor,\n",
    "                src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor,\n",
    "                memory_key_padding_mask: Tensor):\n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "#         print('pos inp')\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "#         print('pos dec')\n",
    "        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n",
    "                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n",
    "#         print('pos out')\n",
    "        x = self.generator(outs)\n",
    "#         print('gen')\n",
    "        return x\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer.encoder(self.positional_encoding(\n",
    "                            self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer.decoder(self.positional_encoding(\n",
    "                          self.tgt_tok_emb(tgt)), memory,\n",
    "                          tgt_mask)\n",
    "# During training, we need a subsequent word mask that will prevent model to look into the future words when making predictions. We will also need masks to hide source and target padding tokens. Below, let’s define a function that will take care of both.\n",
    "\n",
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "\n",
    "def create_mask(src, tgt):\n",
    "    src_seq_len = src.shape[0]\n",
    "    tgt_seq_len = tgt.shape[0]\n",
    "\n",
    "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
    "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
    "\n",
    "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
    "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
    "    \n",
    "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05d7f6",
   "metadata": {},
   "source": [
    "Обратите внимание на то как мы подаем данные в модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dedf9014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, iterator, optimizer, criterion, print_every=500):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    ac = []\n",
    "    \n",
    "    model.train()  \n",
    "\n",
    "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "        texts_en = texts_en.T.to(DEVICE) # чтобы батч был в конце\n",
    "        texts_ru = texts_ru.T.to(DEVICE) # чтобы батч был в конце\n",
    "        \n",
    "        # помимо текста в модель еще нужно передать целевую последовательность\n",
    "        # но не полную а без 1 последнего элемента\n",
    "        # а на выходе ожидаем, что модель сгенерирует этот недостающий элемент\n",
    "        texts_ru_input = texts_ru[:-1, :]\n",
    "        \n",
    "        \n",
    "        # в трансформерах нет циклов как в лстм \n",
    "        # каждый элемент связан с каждым через аттеншен\n",
    "        # чтобы имитировать последовательную обработку\n",
    "        # и чтобы не считать аттеншн с паддингом \n",
    "        # в трансформерах нужно считать много масок\n",
    "        # подробнее про это по ссылкам выше\n",
    "        (texts_en_mask, texts_ru_mask, \n",
    "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
    "        logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
    "                       texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # сравниваем выход из модели с целевой последовательностью уже с этим последним элементом\n",
    "        texts_ru_out = texts_ru[1:, :]\n",
    "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "        \n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {np.mean(epoch_loss)};')\n",
    "        \n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    epoch_loss = []\n",
    "    epoch_f1 = []\n",
    "    \n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "            texts_en = texts_en.T.to(DEVICE)\n",
    "            texts_ru = texts_ru.T.to(DEVICE)\n",
    "\n",
    "            texts_ru_input = texts_ru[:-1, :]\n",
    "\n",
    "            (texts_en_mask, texts_ru_mask, \n",
    "            texts_en_padding_mask, texts_ru_padding_mask) = create_mask(texts_en, texts_ru_input)\n",
    "\n",
    "            logits = model(texts_en, texts_ru_input, texts_en_mask, texts_ru_mask,\n",
    "                           texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "\n",
    "            \n",
    "            texts_ru_out = texts_ru[1:, :]\n",
    "            loss = loss_fn(logits.reshape(-1, logits.shape[-1]), texts_ru_out.reshape(-1))\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b697183c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c4ea391c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "EN_VOCAB_SIZE = tokenizer_en.get_vocab_size()\n",
    "RU_VOCAB_SIZE = tokenizer_ru.get_vocab_size()\n",
    "\n",
    "EMB_SIZE = 256\n",
    "NHEAD = 8\n",
    "FFN_HID_DIM = 512\n",
    "NUM_ENCODER_LAYERS = 2\n",
    "NUM_DECODER_LAYERS = 2\n",
    "\n",
    "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
    "                                 NHEAD, EN_VOCAB_SIZE, RU_VOCAB_SIZE, FFN_HID_DIM)\n",
    "\n",
    "for p in transformer.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)\n",
    "\n",
    "transformer = transformer.to(DEVICE)\n",
    "\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "07f5b3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(transformer, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d39a4011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer = torch.load('model').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5559362d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2070ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 7.781228430747986;\n",
      "Loss: 7.186588780879974;\n",
      "Loss: 6.860238273302714;\n",
      "Loss: 6.62564847111702;\n",
      "Loss: 6.443988226127624;\n",
      "Loss: 6.292388802051544;\n",
      "Loss: 6.162734313011169;\n",
      "Loss: 6.049096729040146;\n",
      "Loss: 5.946791886435615;\n",
      "First epoch - 4.875840034484863, saving model..\n",
      "Epoch: 1, Train loss: 5.899, Val loss: 4.876,            Epoch time=319.964s\n",
      "Loss: 4.939132390975952;\n",
      "Loss: 4.886542227268219;\n",
      "Loss: 4.8369747133255006;\n",
      "Loss: 4.795253774166107;\n",
      "Loss: 4.753978813171387;\n",
      "Loss: 4.712473217805226;\n",
      "Loss: 4.673466671398708;\n",
      "Loss: 4.635904146671296;\n",
      "Loss: 4.598669738239712;\n",
      "Improved from 4.875840034484863 to 4.065413091659546, saving model..\n",
      "Epoch: 2, Train loss: 4.582, Val loss: 4.065,            Epoch time=320.014s\n",
      "Loss: 4.158497625827789;\n",
      "Loss: 4.133895821332931;\n",
      "Loss: 4.111006542841594;\n",
      "Loss: 4.0878082545995715;\n",
      "Loss: 4.066163970184326;\n",
      "Loss: 4.044505736509959;\n",
      "Loss: 4.021677171911512;\n",
      "Loss: 4.000704855918884;\n",
      "Loss: 3.980623606416914;\n",
      "Improved from 4.065413091659546 to 3.6026823797225953, saving model..\n",
      "Epoch: 3, Train loss: 3.971, Val loss: 3.603,            Epoch time=321.332s\n",
      "Loss: 3.692713683128357;\n",
      "Loss: 3.6825199809074403;\n",
      "Loss: 3.6687881762186687;\n",
      "Loss: 3.65787421476841;\n",
      "Loss: 3.645368863773346;\n",
      "Loss: 3.633119265874227;\n",
      "Loss: 3.620401971748897;\n",
      "Loss: 3.6085385599136353;\n",
      "Loss: 3.5968615005281235;\n",
      "Improved from 3.6026823797225953 to 3.32418079662323, saving model..\n",
      "Epoch: 4, Train loss: 3.591, Val loss: 3.324,            Epoch time=321.133s\n",
      "Loss: 3.4002494587898253;\n",
      "Loss: 3.3879706971645356;\n",
      "Loss: 3.38268355512619;\n",
      "Loss: 3.3751385989189147;\n",
      "Loss: 3.369769119358063;\n",
      "Loss: 3.363531561056773;\n",
      "Loss: 3.358153234618051;\n",
      "Loss: 3.3517157178521155;\n",
      "Loss: 3.345509110291799;\n",
      "Improved from 3.32418079662323 to 3.1422921867370603, saving model..\n",
      "Epoch: 5, Train loss: 3.342, Val loss: 3.142,            Epoch time=321.040s\n",
      "Loss: 3.192088939666748;\n",
      "Loss: 3.1885336532592774;\n",
      "Loss: 3.1858157946268717;\n",
      "Loss: 3.1852880063056945;\n",
      "Loss: 3.184478944206238;\n",
      "Loss: 3.1829006917476654;\n",
      "Loss: 3.179227167538234;\n",
      "Loss: 3.176359631359577;\n",
      "Loss: 3.1734080601798165;\n",
      "Improved from 3.1422921867370603 to 3.0180461769104006, saving model..\n",
      "Epoch: 6, Train loss: 3.172, Val loss: 3.018,            Epoch time=322.262s\n",
      "Loss: 3.0461038365364073;\n",
      "Loss: 3.0467356214523313;\n",
      "Loss: 3.046249099254608;\n",
      "Loss: 3.0485892585515977;\n",
      "Loss: 3.0499942443847656;\n",
      "Loss: 3.049580394744873;\n",
      "Loss: 3.049284241267613;\n",
      "Loss: 3.0495966215729715;\n",
      "Loss: 3.0486064960691666;\n",
      "Improved from 3.0180461769104006 to 2.9411085014343263, saving model..\n",
      "Epoch: 7, Train loss: 3.048, Val loss: 2.941,            Epoch time=321.519s\n",
      "Loss: 2.941800519943237;\n",
      "Loss: 2.945572947025299;\n",
      "Loss: 2.9481245185534157;\n",
      "Loss: 2.950700331091881;\n",
      "Loss: 2.950405251789093;\n",
      "Loss: 2.950331940809886;\n",
      "Loss: 2.9516009405681065;\n",
      "Loss: 2.9513929060697555;\n",
      "Loss: 2.952164904753367;\n",
      "Improved from 2.9411085014343263 to 2.8706814184188842, saving model..\n",
      "Epoch: 8, Train loss: 2.953, Val loss: 2.871,            Epoch time=321.504s\n",
      "Loss: 2.855389853954315;\n",
      "Loss: 2.8633140997886657;\n",
      "Loss: 2.865716866652171;\n",
      "Loss: 2.868344077587128;\n",
      "Loss: 2.870818509674072;\n",
      "Loss: 2.873173765977224;\n",
      "Loss: 2.8748561107771735;\n",
      "Loss: 2.8758107160329818;\n",
      "Loss: 2.8776109468142193;\n",
      "Improved from 2.8706814184188842 to 2.8311767568588255, saving model..\n",
      "Epoch: 9, Train loss: 2.878, Val loss: 2.831,            Epoch time=321.833s\n",
      "Loss: 2.791347960948944;\n",
      "Loss: 2.7942649297714235;\n",
      "Loss: 2.7993415242830912;\n",
      "Loss: 2.8015352753400804;\n",
      "Loss: 2.805752013015747;\n",
      "Loss: 2.8085173616409302;\n",
      "Loss: 2.8112885989461627;\n",
      "Loss: 2.8137560175657272;\n",
      "Loss: 2.8153118512365554;\n",
      "Improved from 2.8311767568588255 to 2.785791614532471, saving model..\n",
      "Epoch: 10, Train loss: 2.816, Val loss: 2.786,            Epoch time=320.867s\n",
      "Loss: 2.726197245121002;\n",
      "Loss: 2.7349008193016053;\n",
      "Loss: 2.744852533022563;\n",
      "Loss: 2.7487615008354185;\n",
      "Loss: 2.7528450852394104;\n",
      "Loss: 2.7547248339653017;\n",
      "Loss: 2.75775914648601;\n",
      "Loss: 2.760691510081291;\n",
      "Loss: 2.7634133621851604;\n",
      "Improved from 2.785791614532471 to 2.7557491979599, saving model..\n",
      "Epoch: 11, Train loss: 2.765, Val loss: 2.756,            Epoch time=321.460s\n",
      "Loss: 2.682079964637756;\n",
      "Loss: 2.694269156932831;\n",
      "Loss: 2.698319339911143;\n",
      "Loss: 2.704380501508713;\n",
      "Loss: 2.7080432923316957;\n",
      "Loss: 2.711886295715968;\n",
      "Loss: 2.7137858241626196;\n",
      "Loss: 2.7171170528531077;\n",
      "Loss: 2.7194974163373313;\n",
      "Improved from 2.7557491979599 to 2.7296668767929075, saving model..\n",
      "Epoch: 12, Train loss: 2.721, Val loss: 2.730,            Epoch time=321.549s\n",
      "Loss: 2.6397953271865844;\n",
      "Loss: 2.647549518585205;\n",
      "Loss: 2.6561950319608054;\n",
      "Loss: 2.661842950820923;\n",
      "Loss: 2.6664779673576353;\n",
      "Loss: 2.6714771456718447;\n",
      "Loss: 2.6753903609003338;\n",
      "Loss: 2.678233894109726;\n",
      "Loss: 2.6813832500245836;\n",
      "Improved from 2.7296668767929075 to 2.7045052919387818, saving model..\n",
      "Epoch: 13, Train loss: 2.683, Val loss: 2.705,            Epoch time=321.178s\n",
      "Loss: 2.605199948787689;\n",
      "Loss: 2.618184322834015;\n",
      "Loss: 2.624832442442576;\n",
      "Loss: 2.631345829844475;\n",
      "Loss: 2.633681705093384;\n",
      "Loss: 2.638466450134913;\n",
      "Loss: 2.641467633996691;\n",
      "Loss: 2.6453310636878014;\n",
      "Loss: 2.647829657872518;\n",
      "Improved from 2.7045052919387818 to 2.688055270195007, saving model..\n",
      "Epoch: 14, Train loss: 2.649, Val loss: 2.688,            Epoch time=321.548s\n",
      "Loss: 2.57212699508667;\n",
      "Loss: 2.585165737628937;\n",
      "Loss: 2.5916573832829792;\n",
      "Loss: 2.599021095633507;\n",
      "Loss: 2.6038413692474367;\n",
      "Loss: 2.6079455626010897;\n",
      "Loss: 2.6116580795560562;\n",
      "Loss: 2.6150577673316002;\n",
      "Loss: 2.618559847248925;\n",
      "Improved from 2.688055270195007 to 2.669622594833374, saving model..\n",
      "Epoch: 15, Train loss: 2.620, Val loss: 2.670,            Epoch time=321.020s\n",
      "Loss: 2.5481806678771974;\n",
      "Loss: 2.55310164308548;\n",
      "Loss: 2.5600191837946573;\n",
      "Loss: 2.5675137166976927;\n",
      "Loss: 2.5733836263656618;\n",
      "Loss: 2.5788298904101055;\n",
      "Loss: 2.582993735040937;\n",
      "Loss: 2.5874955283999443;\n",
      "Loss: 2.591316775639852;\n",
      "Improved from 2.669622594833374 to 2.6617342681884764, saving model..\n",
      "Epoch: 16, Train loss: 2.593, Val loss: 2.662,            Epoch time=321.852s\n",
      "Loss: 2.5184385647773744;\n",
      "Loss: 2.5295885388851165;\n",
      "Loss: 2.53777565908432;\n",
      "Loss: 2.5448942432403565;\n",
      "Loss: 2.5509333859443664;\n",
      "Loss: 2.5560625251928966;\n",
      "Loss: 2.559755555970328;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-e2a9f2b151a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-75-1d8d0f20cde5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, print_every)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtexts_ru_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts_ru\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts_ru_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 100\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(transformer, training_generator, optimizer, loss_fn)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(transformer, valid_generator, loss_fn)\n",
    "    \n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}, saving model..')\n",
    "        torch.save(transformer, 'model')\n",
    "    \n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
    "        torch.save(transformer, 'model')\n",
    "    \n",
    "    losses.append(val_loss)\n",
    "        \n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4a21a9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(text):\n",
    "\n",
    "\n",
    "    input_ids = [tokenizer_en.token_to_id('[CLS]')] + tokenizer_en.encode(text).ids[:max_len_en] + [tokenizer_en.token_to_id('[SEP]')]\n",
    "    output_ids = [tokenizer_ru.token_to_id('[CLS]')]\n",
    "\n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)]).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "    (texts_en_mask, texts_ru_mask, \n",
    "    texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "    logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
    "                   texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "    pred = logits.argmax(2).item()\n",
    "\n",
    "    while pred not in [tokenizer_ru.token_to_id('[SEP]'), tokenizer_ru.token_to_id('[PAD]')]:\n",
    "        output_ids.append(pred)\n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)]).to(DEVICE)\n",
    "\n",
    "        (texts_en_mask, texts_ru_mask, \n",
    "        texts_en_padding_mask, texts_ru_padding_mask) = create_mask(input_ids_pad, output_ids_pad)\n",
    "        logits = transformer(input_ids_pad, output_ids_pad, texts_en_mask, texts_ru_mask,\n",
    "                       texts_en_padding_mask, texts_ru_padding_mask, texts_en_padding_mask)\n",
    "        pred = logits.argmax(2)[-1].item()\n",
    "\n",
    "    return (' '.join([tokenizer_ru.id_to_token(i).replace('##', '') for i in output_ids[1:]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db3a19c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Пример'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f284d0f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ты можешь перевести это ?'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Can you translate that?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b234717b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402783c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
