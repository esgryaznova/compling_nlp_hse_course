{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esgryaznova/compling_nlp_hse_course/blob/master/homework_8_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf6f873"
      },
      "source": [
        "# Домашнее задание № 8"
      ],
      "id": "1bf6f873"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b4bd487"
      },
      "source": [
        "## Задание 1 (4 балла) "
      ],
      "id": "3b4bd487"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bf4c4f87"
      },
      "source": [
        "Обучите 8 моделей для задачи классификации текста (датасет - lenta_40k ). А именно:  \n",
        "1) модель с 1 GRU слоем;   \n",
        "2) модель с 1 LSTM слоем    \n",
        "3) модель с 1 GRU и 1 LSTM слоем  \n",
        "4) модель с 1 BIGRU и 2 LSTM слоями  \n",
        "5) модель с 5 GRU слоями и 3 LSTM слоями  \n",
        "6) модель 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались   \n",
        "7) модель, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM  \n",
        "\n",
        "\n",
        "\n",
        "Параметр units и размер эмбединга можете задать любой. Оцените качество каждой модели и определите победителя."
      ],
      "id": "bf4c4f87"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83db6635"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ],
      "id": "83db6635"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50362f6e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "id": "50362f6e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXDvuMVYRZ1c",
        "outputId": "3b2cbad6-d146-4bc6-fe8c-66e69beb292a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/"
      ],
      "id": "XXDvuMVYRZ1c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b6676dab"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('lenta_40k.csv.zip')"
      ],
      "id": "b6676dab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L7mLsrG5RLJQ",
        "outputId": "ef9bd8f1-bab2-49f9-ce64-1ff7b07434fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30300d0f-b14e-488e-92c7-ff8cf5ad7785\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Россия должна сотрудничать с Всемирным антидоп...</td>\n",
              "      <td>Спорт</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Уголовный суд Кувейта 28 июня освободил под за...</td>\n",
              "      <td>Мир</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Французский журнал Charlie Hebdo опубликовал н...</td>\n",
              "      <td>Интернет и СМИ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>В Петербурге в доме № 53 по улице Лени Голиков...</td>\n",
              "      <td>Россия</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>В московском аэропорту \"Домодедово\" задержан г...</td>\n",
              "      <td>Россия</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30300d0f-b14e-488e-92c7-ff8cf5ad7785')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30300d0f-b14e-488e-92c7-ff8cf5ad7785 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30300d0f-b14e-488e-92c7-ff8cf5ad7785');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text           topic\n",
              "0  Россия должна сотрудничать с Всемирным антидоп...           Спорт\n",
              "1  Уголовный суд Кувейта 28 июня освободил под за...             Мир\n",
              "2  Французский журнал Charlie Hebdo опубликовал н...  Интернет и СМИ\n",
              "3  В Петербурге в доме № 53 по улице Лени Голиков...          Россия\n",
              "4  В московском аэропорту \"Домодедово\" задержан г...          Россия"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head(5)"
      ],
      "id": "L7mLsrG5RLJQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_hYGfDGRMBP"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "    tokens = text.lower().split()\n",
        "    tokens = [token.strip(punctuation) for token in tokens]\n",
        "    return tokens"
      ],
      "id": "W_hYGfDGRMBP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh0yN4mLRMRW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        \"\"\"Recall metric.\n",
        "\n",
        "        Only computes a batch-wise average of recall.\n",
        "\n",
        "        Computes the recall, a metric for multi-label classification of\n",
        "        how many relevant items are selected.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        \"\"\"Precision metric.\n",
        "\n",
        "        Only computes a batch-wise average of precision.\n",
        "\n",
        "        Computes the precision, a metric for multi-label classification of\n",
        "        how many selected items are relevant.\n",
        "        \"\"\"\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "id": "Qh0yN4mLRMRW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2xwU2kgTAZI"
      },
      "outputs": [],
      "source": [
        "# словарь\n",
        "vocab = Counter()\n",
        "\n",
        "for text in data.text:\n",
        "    vocab.update(preprocess(text))"
      ],
      "id": "o2xwU2kgTAZI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ia-Dpm2TGdp"
      },
      "outputs": [],
      "source": [
        "# отфильтрованный словарь\n",
        "filtered_vocab = set()\n",
        "\n",
        "for word in vocab:\n",
        "    if vocab[word] > 30:\n",
        "        filtered_vocab.add(word)"
      ],
      "id": "4Ia-Dpm2TGdp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f239n3ClTPQD"
      },
      "outputs": [],
      "source": [
        "# индексируем слова\n",
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in filtered_vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "id": "f239n3ClTPQD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kca4UQHRTQZf"
      },
      "outputs": [],
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "id": "Kca4UQHRTQZf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N51DaTGGTS-k"
      },
      "outputs": [],
      "source": [
        "# переводим тексты в последовательности индексов\n",
        "X = []\n",
        "\n",
        "for text in data.text:\n",
        "    tokens = preprocess(text)\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ],
      "id": "N51DaTGGTS-k"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNJo1dfwTX2u"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = max(len(x) for x in X)"
      ],
      "id": "ZNJo1dfwTX2u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxpLIwtOTcmb"
      },
      "outputs": [],
      "source": [
        "MEAN_LEN = np.median([len(x) for x in X])"
      ],
      "id": "JxpLIwtOTcmb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GfEBCgePTlPu"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = int(MEAN_LEN + 30)"
      ],
      "id": "GfEBCgePTlPu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4ovtAgoTncA"
      },
      "outputs": [],
      "source": [
        "# паддинг\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
      ],
      "id": "V4ovtAgoTncA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96_LdPWQTpw3",
        "outputId": "3449429e-2a71-48a8-f283-149b66bfb590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(44356, 200)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ],
      "id": "96_LdPWQTpw3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOp-Y9qVT30l"
      },
      "outputs": [],
      "source": [
        "id2label = {i:label for i, label in enumerate(set(data.topic.values))}\n",
        "label2id = {l:i for i, l in id2label.items()}"
      ],
      "id": "xOp-Y9qVT30l"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGOL3uKTT7Qw"
      },
      "outputs": [],
      "source": [
        "y = tf.keras.utils.to_categorical([label2id[label] for label in data.topic.values])"
      ],
      "id": "XGOL3uKTT7Qw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcTrYhyKT8I7",
        "outputId": "59b1955c-ef47-4712-c018-3e082bb220f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "19"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(label2id)"
      ],
      "id": "BcTrYhyKT8I7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdn1ushET-Ku"
      },
      "outputs": [],
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ],
      "id": "xdn1ushET-Ku"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXHa-EA9UQ2P"
      },
      "source": [
        "Модель 1 с GRU слоем - ПОБЕДИТЕЛЬ"
      ],
      "id": "KXHa-EA9UQ2P"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "az8FiTfkUCfU"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "gru = tf.keras.layers.GRU(128, return_sequences=False)(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru)\n",
        "\n",
        "model_gru = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_gru.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "az8FiTfkUCfU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ThpIGgjV90S",
        "outputId": "f9f43f4d-4154-486c-e70e-e1b2413d8dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 200)]             0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 200, 30)           722790    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               61440     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 19)                2451      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 786,681\n",
            "Trainable params: 786,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_gru.summary()"
      ],
      "id": "_ThpIGgjV90S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "69fpSAfgV2oZ"
      },
      "outputs": [],
      "source": [
        "model_gru.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "id": "69fpSAfgV2oZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zBS5W47WOLe",
        "outputId": "575ac4bf-9169-41e5-fa0c-081b2ae28631"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9525233507156372\n"
          ]
        }
      ],
      "source": [
        "print(model_gru.history.history['f1'][-1]) #ПОБЕДИТЕЛЬ"
      ],
      "id": "8zBS5W47WOLe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcwugNhsbQbm"
      },
      "source": [
        "Модель 2 с LSTM слоем"
      ],
      "id": "dcwugNhsbQbm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMtt6vbYbW0f"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm = tf.keras.layers.LSTM(128, return_sequences=False)(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm)\n",
        "\n",
        "model_lstm = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_lstm.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "ZMtt6vbYbW0f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byG77WCrb1k2"
      },
      "outputs": [],
      "source": [
        "model_lstm.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "id": "byG77WCrb1k2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1A2QIfrcJqv",
        "outputId": "b54808a6-018c-41cb-82bc-8f46599b7fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9361198544502258\n"
          ]
        }
      ],
      "source": [
        "print(model_lstm.history.history['f1'][-1])"
      ],
      "id": "r1A2QIfrcJqv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zdom4concZoM"
      },
      "source": [
        "Модель 3 с 1 GRU и 1 LSTM слоем"
      ],
      "id": "Zdom4concZoM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZcTWKfcciFF"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
        "gru = tf.keras.layers.GRU(128, return_sequences=False)(lstm)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(gru)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_lstm_gru = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_lstm_gru.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "dZcTWKfcciFF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESFj3xYLc-H0"
      },
      "outputs": [],
      "source": [
        "model_lstm_gru.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "id": "ESFj3xYLc-H0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cvUDsE2ldB-A",
        "outputId": "a03aec17-657b-4401-d808-33ae0dd443e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9129649996757507\n"
          ]
        }
      ],
      "source": [
        "print(model_lstm_gru.history.history['f1'][-1])"
      ],
      "id": "cvUDsE2ldB-A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALg8Uy-do5q"
      },
      "source": [
        "Модель 4 с 1 BIGRU и 2 LSTM слоями"
      ],
      "id": "oALg8Uy-do5q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5oBIf8GeLsh"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(bigru)\n",
        "lstm_2 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_1)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_bigru_lstm = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_bigru_lstm.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "u5oBIf8GeLsh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VP8K40hjefCP"
      },
      "outputs": [],
      "source": [
        "model_bigru_lstm.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "id": "VP8K40hjefCP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvTkocyFekxG",
        "outputId": "62d7573d-070b-4620-c657-3cef1ddbfde0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9070793986320496\n"
          ]
        }
      ],
      "source": [
        "print(model_bigru_lstm.history.history['f1'][-1])"
      ],
      "id": "HvTkocyFekxG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaxI5gYwdy2x"
      },
      "source": [
        "Модель 5 с 5 GRU слоями и 3 LSTM слоями"
      ],
      "id": "HaxI5gYwdy2x"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGvmyjmHfvzz"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(embeddings)\n",
        "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(gru_1)\n",
        "gru_3 = tf.keras.layers.GRU(128, return_sequences=True)(gru_2)\n",
        "gru_4 = tf.keras.layers.GRU(128, return_sequences=True)(gru_3)\n",
        "gru_5 = tf.keras.layers.GRU(128, return_sequences=True)(gru_4)\n",
        "\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(gru_5)\n",
        "lstm_2 = tf.keras.layers.LSTM(128, return_sequences=True)(lstm_1)\n",
        "lstm_3 = tf.keras.layers.LSTM(128, return_sequences=False)(lstm_2)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_3)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_gru_lstm_2 = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model_gru_lstm_2.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "wGvmyjmHfvzz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaTB7l_2gDbt"
      },
      "outputs": [],
      "source": [
        "model_gru_lstm_2.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "id": "EaTB7l_2gDbt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjq41eB9gICv",
        "outputId": "e499b2b5-9943-4d5a-c833-d07c9f1bf4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(model_gru_lstm_2.history.history['f1'][-1])"
      ],
      "id": "mjq41eB9gICv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhTq3WxhdzRv"
      },
      "source": [
        "Модель 6 с 1 BIGRU и 1 BILSTM слоями, причем так чтобы модели для forward и backward прохода отличались"
      ],
      "id": "FhTq3WxhdzRv"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "bigru_bilstm = tf.keras.layers.Bidirectional(\n",
        "                                       tf.keras.layers.GRU(128, return_sequences=False),\n",
        "                        backward_layer=tf.keras.layers.LSTM(128, return_sequences=False, \n",
        "                                                            go_backwards=True))(embeddings)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(bigru_bilstm)\n",
        "model_bigru_bilstm = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model_bigru_bilstm.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "metadata": {
        "id": "1qKku5vhiFvY"
      },
      "id": "1qKku5vhiFvY",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bigru_bilstm.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "F7-oE66visdm"
      },
      "id": "F7-oE66visdm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_bigru_bilstm.history.history['f1'][-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAJPc3LPixsU",
        "outputId": "0eaed872-a50c-4ef3-8063-5e51cb2c56d6"
      },
      "id": "cAJPc3LPixsU",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8379001021385193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CazjBO5Xdzef"
      },
      "source": [
        "Модель 7, где последовательно идут слои: LSTM, GRU, BILSTM, BIGRU, GRU, LSTM"
      ],
      "id": "CazjBO5Xdzef"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "erf1rj4Hdmdn"
      },
      "outputs": [],
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=30)(inputs, )\n",
        "\n",
        "lstm_1 = tf.keras.layers.LSTM(128, return_sequences=True)(embeddings)\n",
        "gru_1 = tf.keras.layers.GRU(128, return_sequences=True)(lstm_1)\n",
        "bilstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(gru_1)\n",
        "bigru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(bilstm)\n",
        "gru_2 = tf.keras.layers.GRU(128, return_sequences=True)(bigru)\n",
        "lstm_2 = tf.keras.layers.LSTM(128, return_sequences=False)(gru_2)\n",
        "\n",
        "dense = tf.keras.layers.Dense(64, activation='relu')(lstm_2)\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(dense)\n",
        "\n",
        "model_all = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model_all.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=[f1, tf.keras.metrics.RecallAtPrecision(0.8, name='rec@prec')])"
      ],
      "id": "erf1rj4Hdmdn"
    },
    {
      "cell_type": "code",
      "source": [
        "model_all.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=1000,\n",
        "          epochs=20)"
      ],
      "metadata": {
        "id": "GjsM_EKwjb_-"
      },
      "id": "GjsM_EKwjb_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_all.history.history['f1'][-1]) #тоже неплохо"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFZQnhcSjhbJ",
        "outputId": "1aa71e7a-bb1d-4b42-c4ec-fbef997dec47"
      },
      "id": "MFZQnhcSjhbJ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9238659143447876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed5d6eea"
      },
      "source": [
        "## Задание 2 (6 баллов)\n"
      ],
      "id": "ed5d6eea"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c2c07cf"
      },
      "source": [
        "На данных википедии (wikiann) обучите 2 модели:  \n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BILSTM слоев. \n",
        "1) модель в которой будут использованы предобученные эмбединги слов и несколько BIGRU слоев. \n",
        "\n",
        "Сравните качество по метрикам. Также придумайте несколько сложных примеров и проверьте, какие сущности определяет каждая из моделей."
      ],
      "id": "5c2c07cf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb704b1b"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ],
      "id": "fb704b1b"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "24b4e4aa"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ],
      "id": "24b4e4aa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8035db14"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"wikiann\", 'ru')"
      ],
      "id": "8035db14"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrtHIykyl8A1",
        "outputId": "410e6593-7f54-4f5c-82eb-96e4f1209652"
      },
      "id": "JrtHIykyl8A1",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs', 'spans'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# словарь\n",
        "vocab = Counter()\n",
        "\n",
        "for sent in dataset['train']['tokens']:\n",
        "    vocab.update([x.lower() for x in sent])"
      ],
      "metadata": {
        "id": "kCWuVSt6l_IB"
      },
      "id": "kCWuVSt6l_IB",
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# индексируем слова\n",
        "word2id = {'PAD':0, 'UNK':1}\n",
        "\n",
        "for word in vocab:\n",
        "    word2id[word] = len(word2id)"
      ],
      "metadata": {
        "id": "tUqNNb_MmF6i"
      },
      "id": "tUqNNb_MmF6i",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "metadata": {
        "id": "A1gZXxn3mIZ9"
      },
      "id": "A1gZXxn3mIZ9",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переводим тексты в последовательности индексов\n",
        "X = []\n",
        "\n",
        "for sent in dataset['train']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X.append(ids)"
      ],
      "metadata": {
        "id": "TZMxdh9JmLVR"
      },
      "id": "TZMxdh9JmLVR",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# переводим тексты в последовательности индексов\n",
        "X_test = []\n",
        "\n",
        "for sent in dataset['test']['tokens']:\n",
        "    tokens = [w.lower() for w in sent]\n",
        "    ids = [word2id.get(token, 1) for token in tokens]\n",
        "    X_test.append(ids)"
      ],
      "metadata": {
        "id": "7cGGutUImN59"
      },
      "id": "7cGGutUImN59",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = max(len(x) for x in X)\n",
        "\n",
        "# паддинг\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN, padding='post')\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=MAX_LEN, padding='post')"
      ],
      "metadata": {
        "id": "3FbKuDSfmYUP"
      },
      "id": "3FbKuDSfmYUP",
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2labels = {0:'O', 1:'B-PER', 2:'I-PER', 3:'B-ORG', 4:'I-ORG', 5: 'B-LOC', 6:'I-LOC', 7:'PAD'}\n",
        "label2id = {v:k for k,v in id2labels.items()}"
      ],
      "metadata": {
        "id": "7GeQaZyZmZGI"
      },
      "id": "7GeQaZyZmZGI",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = tf.keras.preprocessing.sequence.pad_sequences(dataset['train']['ner_tags'], value=7,\n",
        "                                                  maxlen=MAX_LEN,  padding='post')\n",
        "y_test = tf.keras.preprocessing.sequence.pad_sequences(dataset['test']['ner_tags'], value=7,\n",
        "                                                       maxlen=MAX_LEN,  padding='post')"
      ],
      "metadata": {
        "id": "xB9SmBtrmeWD"
      },
      "id": "xB9SmBtrmeWD",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkU9N--Img24",
        "outputId": "2b3b2527-8022-4246-c544-4689e72b8181"
      },
      "id": "wkU9N--Img24",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 54), (10000, 54))"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHMSpGu_mm_b",
        "outputId": "7385f9ef-9e1c-4803-bb31-f10bc27793dc"
      },
      "id": "FHMSpGu_mm_b",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((20000, 54), (10000, 54))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель со слоями BILSTM"
      ],
      "metadata": {
        "id": "VAUwG7fBmtJC"
      },
      "id": "VAUwG7fBmtJC"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
        "\n",
        "lstm_1 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(embeddings)\n",
        "lstm_2 = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True))(lstm_1)\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(lstm_2)\n",
        "\n",
        "model_bilstm = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model_bilstm.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mzL8u9w4moon"
      },
      "id": "mzL8u9w4moon",
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bilstm.fit(X, y, \n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128,\n",
        "          epochs=5)"
      ],
      "metadata": {
        "id": "2-UaBtB6m-Q5"
      },
      "id": "2-UaBtB6m-Q5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "Jo3IJsUGnw1k"
      },
      "id": "Jo3IJsUGnw1k",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_bilstm.predict(X_test).argmax(2)"
      ],
      "metadata": {
        "id": "vJIC4EWln2Ic"
      },
      "id": "vJIC4EWln2Ic",
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOsVvmUDn9af",
        "outputId": "89e911c4-8680-4f21-ecae-3bba87cf5c14"
      },
      "id": "YOsVvmUDn9af",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.96      0.90      0.93     40480\n",
            "       B-PER       0.79      0.89      0.83      3542\n",
            "       I-PER       0.90      0.92      0.91      7544\n",
            "       B-ORG       0.59      0.74      0.66      4074\n",
            "       I-ORG       0.73      0.84      0.78      8008\n",
            "       B-LOC       0.71      0.75      0.73      4560\n",
            "       I-LOC       0.86      0.72      0.78      3060\n",
            "         PAD       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.98    540000\n",
            "   macro avg       0.82      0.85      0.83    540000\n",
            "weighted avg       0.98      0.98      0.98    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель с BIGRU слоями"
      ],
      "metadata": {
        "id": "YCKtYTBxou15"
      },
      "id": "YCKtYTBxou15"
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(word2id), output_dim=100)(inputs)\n",
        "\n",
        "gru_1 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(embeddings)\n",
        "gru_2 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_1)\n",
        "gru_3 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_2)\n",
        "gru_4 = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128, return_sequences=True))(gru_3)\n",
        "\n",
        "\n",
        "outputs = tf.keras.layers.Dense(len(label2id), activation='softmax')(gru_4)\n",
        "\n",
        "model_bigru = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model_bigru.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "f13ouMKno02e"
      },
      "id": "f13ouMKno02e",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bigru.fit(X, y, \n",
        "          validation_data=(X_test, y_test),\n",
        "          batch_size=128,\n",
        "          epochs=5)"
      ],
      "metadata": {
        "id": "ieSpsGBFpN4u"
      },
      "id": "ieSpsGBFpN4u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model_bigru.predict(X_test).argmax(2)"
      ],
      "metadata": {
        "id": "zGNR1xpkph9F"
      },
      "id": "zGNR1xpkph9F",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test.reshape(-1), pred.reshape(-1), labels=list(id2labels.keys()),\n",
        "                                                                     target_names=list(id2labels.values()),\n",
        "                                                                     zero_division=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIVXB19ppqsx",
        "outputId": "56504cc7-5188-4746-bfbd-f9ebf6f3e6c2"
      },
      "id": "yIVXB19ppqsx",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           O       0.95      0.94      0.95     40480\n",
            "       B-PER       0.85      0.87      0.86      3542\n",
            "       I-PER       0.88      0.92      0.90      7544\n",
            "       B-ORG       0.58      0.76      0.66      4074\n",
            "       I-ORG       0.82      0.79      0.80      8008\n",
            "       B-LOC       0.79      0.75      0.77      4560\n",
            "       I-LOC       0.86      0.72      0.78      3060\n",
            "         PAD       1.00      1.00      1.00    468732\n",
            "\n",
            "    accuracy                           0.98    540000\n",
            "   macro avg       0.84      0.84      0.84    540000\n",
            "weighted avg       0.99      0.98      0.98    540000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Кажется, что модели работают практически одинаково, обе модели достигают accuracy 0.98. Плохо предсказывают класс B-ORG, 0.66"
      ],
      "metadata": {
        "id": "CMVujuj7p_BY"
      },
      "id": "CMVujuj7p_BY"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text, word2id):\n",
        "    # токенизирует и переводит в индексы\n",
        "    tokens = re.findall('\\w+|[^\\w\\s]+', text)\n",
        "    ids = [word2id.get(token.lower(), 1) for token in tokens]\n",
        "    return tokens, ids\n",
        "\n",
        "def pred2tags(pred, id2label, length):\n",
        "    # декодирует индексы в части речи\n",
        "    # length нужно чтобы откидывать паддинги или некорректные предсказания\n",
        "    pred = pred.argmax(2)[0, :length]\n",
        "    labels = [id2label[l] for l in pred]\n",
        "    return labels\n",
        "\n",
        "def label_seq(text, word2id, id2label, max_len, model):\n",
        "    tokens, ids = tokenize(text, word2id)\n",
        "    pred = model.predict(tf.keras.preprocessing.sequence.pad_sequences([ids], \n",
        "                                                                       maxlen=max_len, \n",
        "                                                                       padding='post'))\n",
        "    labels = pred2tags(pred, id2label, len(ids))\n",
        "    \n",
        "    return list(zip(tokens, labels))"
      ],
      "metadata": {
        "id": "qVTb7TfuqRZq"
      },
      "id": "qVTb7TfuqRZq",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Мне караты на уши, на мне дорого бусы', word2id, id2labels, MAX_LEN, model_bilstm) #дико извиняюсь\n",
        "#что-то попытался определить, что неправильно"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qO990WyXqVa6",
        "outputId": "b23d5535-b3c9-4f0c-82ce-cbc891da1b44"
      },
      "id": "qO990WyXqVa6",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Мне', 'O'),\n",
              " ('караты', 'B-LOC'),\n",
              " ('на', 'O'),\n",
              " ('уши', 'O'),\n",
              " (',', 'O'),\n",
              " ('на', 'O'),\n",
              " ('мне', 'O'),\n",
              " ('дорого', 'B-LOC'),\n",
              " ('бусы', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Мне караты на уши, на мне дорого бусы', word2id, id2labels, MAX_LEN, model_bigru) #дико извиняюсь\n",
        "#все правильно, сущностей нет"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L43xa5Bmqx8I",
        "outputId": "17b2d0da-92d0-4cf9-d7f4-cec3df55c340"
      },
      "id": "L43xa5Bmqx8I",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Мне', 'O'),\n",
              " ('караты', 'O'),\n",
              " ('на', 'O'),\n",
              " ('уши', 'O'),\n",
              " (',', 'O'),\n",
              " ('на', 'O'),\n",
              " ('мне', 'O'),\n",
              " ('дорого', 'O'),\n",
              " ('бусы', 'O')]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Ты уехал в Петербург, а приехал в Ленинград', word2id, id2labels, MAX_LEN, model_bilstm)\n",
        "#почему-то \"ты\" - Location..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNfuYGMNrZI2",
        "outputId": "015d6ee2-d2a2-43bc-a96e-6ab20101d890"
      },
      "id": "VNfuYGMNrZI2",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ты', 'B-LOC'),\n",
              " ('уехал', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Петербург', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('а', 'O'),\n",
              " ('приехал', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Ленинград', 'B-ORG')]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_seq('Ты уехал в Петербург, а приехал в Ленинград', word2id, id2labels, MAX_LEN, model_bigru)\n",
        "#здесь хорошо выделились города, правда с тегом B :("
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOZ4W2Smrxf5",
        "outputId": "df54c6eb-db8c-4c23-f316-36455a80b8f9"
      },
      "id": "xOZ4W2Smrxf5",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Ты', 'O'),\n",
              " ('уехал', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Петербург', 'B-LOC'),\n",
              " (',', 'O'),\n",
              " ('а', 'O'),\n",
              " ('приехал', 'O'),\n",
              " ('в', 'O'),\n",
              " ('Ленинград', 'B-LOC')]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вердикт - bigru ведет себя лучше"
      ],
      "metadata": {
        "id": "qF4qaPfss3uX"
      },
      "id": "qF4qaPfss3uX"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "homework_8.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}